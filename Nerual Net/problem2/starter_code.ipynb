{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example of gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.49560496  1.97506978  0.50155959  3.9484664 ]\n",
      " [ 1.3776363  -3.27733824  3.006048    4.80752157]\n",
      " [ 0.16320426  0.86774584 -0.91588834 -1.77412661]\n",
      " [ 4.35644407  2.123704    0.33402112  6.75746938]\n",
      " [ 2.37774809 -1.80021958  1.38330244  0.18782212]\n",
      " [-1.35906364  3.12024207 -0.14185344  4.15509574]\n",
      " [-0.75955635  1.62853224 -1.48258275 -1.37454233]\n",
      " [-4.44379565  1.21346864  0.24814847 -0.33948607]\n",
      " [-1.47049807  0.67556003  1.49359384  4.58522823]\n",
      " [ 6.03755185 -1.1127723   1.31176743  4.35677601]]\n",
      "[[-1.49560496  1.97506978  0.50155959  3.9484664 ]\n",
      " [ 1.3776363  -3.27733824  3.006048    4.80752157]\n",
      " [ 0.16320426  0.86774584 -0.91588834 -1.77412661]\n",
      " [ 4.35644407  2.123704    0.33402112  6.75746938]\n",
      " [ 2.37774809 -1.80021958  1.38330244  0.18782212]\n",
      " [-1.35906364  3.12024207 -0.14185344  4.15509574]\n",
      " [-0.75955635  1.62853224 -1.48258275 -1.37454233]\n",
      " [-4.44379565  1.21346864  0.24814847 -0.33948607]\n",
      " [-1.47049807  0.67556003  1.49359384  4.58522823]\n",
      " [ 6.03755185 -1.1127723   1.31176743  4.35677601]]\n"
     ]
    }
   ],
   "source": [
    "# gradient checking: compare the analytical gradient with the numerical gradient\n",
    "# taking the affine layer as an example\n",
    "from gradient_check import eval_numerical_gradient_array\n",
    "import numpy as np\n",
    "from layers import *\n",
    "N = 5\n",
    "D = 10\n",
    "M = 4\n",
    "x = np.random.normal(size=(N, 2,  5))\n",
    "w = np.random.normal(size=(D, M))\n",
    "b = np.random.normal(size=(M, ))\n",
    "dout = np.random.normal(size=(N, M))\n",
    "\n",
    "# do a forward pass first\n",
    "out, cache = affine_forward(x, w, b)\n",
    "# check grad f/grad w, the [0] below gets the output out of the (output, cache) original output\n",
    "\n",
    "f=lambda w: affine_forward(x, w, b)[0]\n",
    "# compute the analytical gradient you wrote, [1] get the dw out of the (dx, dw, db) original output\n",
    "grad = affine_backward(dout, cache)[1]\n",
    "\n",
    "# compute the numerical gradient using the provided utility function\n",
    "ngrad = eval_numerical_gradient_array(f, w, dout)\n",
    "print(grad)\n",
    "print(ngrad)\n",
    "# they should be similar enough within some small error tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example of training a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put the path to your 'hw6_mds189', which should contain a 'trainval' and 'test' directory\n",
    "path = '/Users/alexkern/desktop/cs189/cs189_hw6/resources/trainval'\n",
    "from data_utils import load_mds189\n",
    "\n",
    "# load the dataset\n",
    "debug = False  # OPTIONAL: you can change this to True for debugging *only*. Your reported results must be with debug = False\n",
    "feat_train, label_train, feat_val, label_val = load_mds189(path,debug)\n",
    "from solver import Solver\n",
    "from fc_net import FullyConnectedNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 360000) loss: 0.000000\n",
      "(Epoch 0 / 100) train acc: 0.158000; val_acc: 0.140203\n",
      "(Iteration 101 / 360000) loss: 2339229725.052832\n",
      "(Iteration 201 / 360000) loss: 6545366538.039886\n",
      "(Iteration 301 / 360000) loss: 9703268929.630608\n",
      "(Iteration 401 / 360000) loss: 9047718410.860792\n",
      "(Iteration 501 / 360000) loss: 26832768242.689125\n",
      "(Iteration 601 / 360000) loss: -0.000000\n",
      "(Iteration 701 / 360000) loss: 17960739064.930447\n",
      "(Iteration 801 / 360000) loss: 13983062012.144629\n",
      "(Iteration 901 / 360000) loss: 30134088112.575554\n",
      "(Iteration 1001 / 360000) loss: 28509267292.499569\n",
      "(Iteration 1101 / 360000) loss: 15090944671.568668\n",
      "(Iteration 1201 / 360000) loss: 41522009485.690544\n",
      "(Iteration 1301 / 360000) loss: 34733021017.883102\n",
      "(Iteration 1401 / 360000) loss: 39074684129.170731\n",
      "(Iteration 1501 / 360000) loss: 48689280694.109482\n",
      "(Iteration 1601 / 360000) loss: 48881384369.423866\n",
      "(Iteration 1701 / 360000) loss: 59777855793.090668\n",
      "(Iteration 1801 / 360000) loss: 62092987813.874130\n",
      "(Iteration 1901 / 360000) loss: 58096182282.309570\n",
      "(Iteration 2001 / 360000) loss: 41243662298.785583\n",
      "(Iteration 2101 / 360000) loss: 69474256551.813614\n",
      "(Iteration 2201 / 360000) loss: 81555186368.600845\n",
      "(Iteration 2301 / 360000) loss: 58633218040.903595\n",
      "(Iteration 2401 / 360000) loss: 57765204090.854904\n",
      "(Iteration 2501 / 360000) loss: 88472526139.421341\n",
      "(Iteration 2601 / 360000) loss: 63644679785.748230\n",
      "(Iteration 2701 / 360000) loss: 88150873348.248962\n",
      "(Iteration 2801 / 360000) loss: 82315725734.054077\n",
      "(Iteration 2901 / 360000) loss: 172911268444.759674\n",
      "(Iteration 3001 / 360000) loss: 38237529368.991829\n",
      "(Iteration 3101 / 360000) loss: 100123669160.553146\n",
      "(Iteration 3201 / 360000) loss: 98290685425.094299\n",
      "(Iteration 3301 / 360000) loss: 82731261278.706940\n",
      "(Iteration 3401 / 360000) loss: 67331421523.868156\n",
      "(Iteration 3501 / 360000) loss: 113194713310.909393\n",
      "(Epoch 1 / 100) train acc: 0.104000; val_acc: 0.125000\n",
      "(Iteration 3601 / 360000) loss: 75724200197.631104\n",
      "(Iteration 3701 / 360000) loss: 27720660.930103\n",
      "(Iteration 3801 / 360000) loss: 31360584.312016\n",
      "(Iteration 3901 / 360000) loss: 21139161.240013\n",
      "(Iteration 4001 / 360000) loss: 56780855.584911\n",
      "(Iteration 4101 / 360000) loss: 70101106.685058\n",
      "(Iteration 4201 / 360000) loss: 33415605.085171\n",
      "(Iteration 4301 / 360000) loss: 71424479.344209\n",
      "(Iteration 4401 / 360000) loss: 32147426.805320\n",
      "(Iteration 4501 / 360000) loss: 27225891.748622\n",
      "(Iteration 4601 / 360000) loss: 23807906.974346\n",
      "(Iteration 4701 / 360000) loss: 55874910.575928\n",
      "(Iteration 4801 / 360000) loss: 23973278.320784\n",
      "(Iteration 4901 / 360000) loss: 27430016.530831\n",
      "(Iteration 5001 / 360000) loss: -0.000000\n",
      "(Iteration 5101 / 360000) loss: 22069562.748248\n",
      "(Iteration 5201 / 360000) loss: 4635451.346456\n",
      "(Iteration 5301 / 360000) loss: 7228773.931107\n",
      "(Iteration 5401 / 360000) loss: 40081944.238525\n",
      "(Iteration 5501 / 360000) loss: 18551588.672645\n",
      "(Iteration 5601 / 360000) loss: 34627673.683174\n",
      "(Iteration 5701 / 360000) loss: 28893688.091698\n",
      "(Iteration 5801 / 360000) loss: 34270140.840455\n",
      "(Iteration 5901 / 360000) loss: -0.000000\n",
      "(Iteration 6001 / 360000) loss: -0.000000\n",
      "(Iteration 6101 / 360000) loss: 85094530.204710\n",
      "(Iteration 6201 / 360000) loss: 44388904.519421\n",
      "(Iteration 6301 / 360000) loss: 19597305.527038\n",
      "(Iteration 6401 / 360000) loss: 31793917.795966\n",
      "(Iteration 6501 / 360000) loss: 20191409.375358\n",
      "(Iteration 6601 / 360000) loss: 16701745.381750\n",
      "(Iteration 6701 / 360000) loss: -0.000000\n",
      "(Iteration 6801 / 360000) loss: 40574332.839588\n",
      "(Iteration 6901 / 360000) loss: 40962488.297088\n",
      "(Iteration 7001 / 360000) loss: 25732390.573217\n",
      "(Iteration 7101 / 360000) loss: 34584178.315156\n",
      "(Epoch 2 / 100) train acc: 0.144000; val_acc: 0.150338\n",
      "(Iteration 7201 / 360000) loss: 60632814.790623\n",
      "(Iteration 7301 / 360000) loss: -0.000000\n",
      "(Iteration 7401 / 360000) loss: 32985633.103195\n",
      "(Iteration 7501 / 360000) loss: 65462069.997571\n",
      "(Iteration 7601 / 360000) loss: 19346814.581540\n",
      "(Iteration 7701 / 360000) loss: 48972651.691976\n",
      "(Iteration 7801 / 360000) loss: 37873426.272549\n",
      "(Iteration 7901 / 360000) loss: 61211565.749227\n",
      "(Iteration 8001 / 360000) loss: 356491.406438\n",
      "(Iteration 8101 / 360000) loss: 21194762.296176\n",
      "(Iteration 8201 / 360000) loss: 414605.951401\n",
      "(Iteration 8301 / 360000) loss: 20786089.741750\n",
      "(Iteration 8401 / 360000) loss: 17495365.729697\n",
      "(Iteration 8501 / 360000) loss: 513773.742433\n",
      "(Iteration 8601 / 360000) loss: 28943140.199817\n",
      "(Iteration 8701 / 360000) loss: 363364.566262\n",
      "(Iteration 8801 / 360000) loss: 25248418.660143\n",
      "(Iteration 8901 / 360000) loss: 7894708.283319\n",
      "(Iteration 9001 / 360000) loss: 23259202.118467\n",
      "(Iteration 9101 / 360000) loss: 61098285.900874\n",
      "(Iteration 9201 / 360000) loss: 25504012.142081\n",
      "(Iteration 9301 / 360000) loss: 804448.957005\n",
      "(Iteration 9401 / 360000) loss: 443743.454363\n",
      "(Iteration 9501 / 360000) loss: 19330159.709966\n",
      "(Iteration 9601 / 360000) loss: 26446103.076664\n",
      "(Iteration 9701 / 360000) loss: 19030328.910663\n",
      "(Iteration 9801 / 360000) loss: 13694936.039323\n",
      "(Iteration 9901 / 360000) loss: 25124002.111995\n",
      "(Iteration 10001 / 360000) loss: 364340.840934\n",
      "(Iteration 10101 / 360000) loss: 34428896.490278\n",
      "(Iteration 10201 / 360000) loss: 25094651.916413\n",
      "(Iteration 10301 / 360000) loss: 22689238.213699\n",
      "(Iteration 10401 / 360000) loss: 24672685.039235\n",
      "(Iteration 10501 / 360000) loss: 36477433.184853\n",
      "(Iteration 10601 / 360000) loss: 25005065.979644\n",
      "(Iteration 10701 / 360000) loss: 38662873.128087\n",
      "(Epoch 3 / 100) train acc: 0.131000; val_acc: 0.125000\n",
      "(Iteration 10801 / 360000) loss: 20218213.839244\n",
      "(Iteration 10901 / 360000) loss: -0.000000\n",
      "(Iteration 11001 / 360000) loss: 28539937.001125\n",
      "(Iteration 11101 / 360000) loss: 42412702.180483\n",
      "(Iteration 11201 / 360000) loss: 22965521.283041\n",
      "(Iteration 11301 / 360000) loss: 16010500.278109\n",
      "(Iteration 11401 / 360000) loss: 23300012.904798\n",
      "(Iteration 11501 / 360000) loss: -0.000000\n",
      "(Iteration 11601 / 360000) loss: 12286517.580459\n",
      "(Iteration 11701 / 360000) loss: 3865069.786073\n",
      "(Iteration 11801 / 360000) loss: -0.000000\n",
      "(Iteration 11901 / 360000) loss: 19962235.815982\n",
      "(Iteration 12001 / 360000) loss: 13474607.813722\n",
      "(Iteration 12101 / 360000) loss: 45230350.383517\n",
      "(Iteration 12201 / 360000) loss: -0.000000\n",
      "(Iteration 12301 / 360000) loss: 14545704.059951\n",
      "(Iteration 12401 / 360000) loss: 18862214.158003\n",
      "(Iteration 12501 / 360000) loss: 11907762.464098\n",
      "(Iteration 12601 / 360000) loss: 10479385.858832\n",
      "(Iteration 12701 / 360000) loss: 2360204.768906\n",
      "(Iteration 12801 / 360000) loss: 21125645.099364\n",
      "(Iteration 12901 / 360000) loss: 19125879.375425\n",
      "(Iteration 13001 / 360000) loss: 24382336.296615\n",
      "(Iteration 13101 / 360000) loss: 34767289.831086\n",
      "(Iteration 13201 / 360000) loss: 8839614.752897\n",
      "(Iteration 13301 / 360000) loss: -0.000000\n",
      "(Iteration 13401 / 360000) loss: 19107848.937711\n",
      "(Iteration 13501 / 360000) loss: 8660992.046433\n",
      "(Iteration 13601 / 360000) loss: -0.000000\n",
      "(Iteration 13701 / 360000) loss: 17436061.504616\n",
      "(Iteration 13801 / 360000) loss: 16634362.780226\n",
      "(Iteration 13901 / 360000) loss: 47446408.167154\n",
      "(Iteration 14001 / 360000) loss: 21338232.405975\n",
      "(Iteration 14101 / 360000) loss: 16750221.852238\n",
      "(Iteration 14201 / 360000) loss: -0.000000\n",
      "(Iteration 14301 / 360000) loss: 3563269.597871\n",
      "(Epoch 4 / 100) train acc: 0.127000; val_acc: 0.125000\n",
      "(Iteration 14401 / 360000) loss: 18367743.960920\n",
      "(Iteration 14501 / 360000) loss: 19829452.615813\n",
      "(Iteration 14601 / 360000) loss: 6695371.018057\n",
      "(Iteration 14701 / 360000) loss: 10625083.354474\n",
      "(Iteration 14801 / 360000) loss: 14958557.642542\n",
      "(Iteration 14901 / 360000) loss: 12791623.780876\n",
      "(Iteration 15001 / 360000) loss: 16729397.344616\n",
      "(Iteration 15101 / 360000) loss: 7406692.935201\n",
      "(Iteration 15201 / 360000) loss: 10957383.863259\n",
      "(Iteration 15301 / 360000) loss: 12806859.473681\n",
      "(Iteration 15401 / 360000) loss: 11540354.374724\n",
      "(Iteration 15501 / 360000) loss: 1066515.958988\n",
      "(Iteration 15601 / 360000) loss: -0.000000\n",
      "(Iteration 15701 / 360000) loss: -0.000000\n",
      "(Iteration 15801 / 360000) loss: 28268843.606278\n",
      "(Iteration 15901 / 360000) loss: 10436571.847990\n",
      "(Iteration 16001 / 360000) loss: 11388681.346589\n",
      "(Iteration 16101 / 360000) loss: -0.000000\n",
      "(Iteration 16201 / 360000) loss: 18477007.808572\n",
      "(Iteration 16301 / 360000) loss: -0.000000\n",
      "(Iteration 16401 / 360000) loss: 18114622.469594\n",
      "(Iteration 16501 / 360000) loss: 7562885.559426\n",
      "(Iteration 16601 / 360000) loss: -0.000000\n",
      "(Iteration 16701 / 360000) loss: 6148361.730677\n",
      "(Iteration 16801 / 360000) loss: 5217230.993774\n",
      "(Iteration 16901 / 360000) loss: 14020482.831415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 17001 / 360000) loss: -0.000000\n",
      "(Iteration 17101 / 360000) loss: 17432765.306303\n",
      "(Iteration 17201 / 360000) loss: -0.000000\n",
      "(Iteration 17301 / 360000) loss: 9467361.197399\n",
      "(Iteration 17401 / 360000) loss: 12562927.654758\n",
      "(Iteration 17501 / 360000) loss: 45811911.728605\n",
      "(Iteration 17601 / 360000) loss: -0.000000\n",
      "(Iteration 17701 / 360000) loss: 6982864.539198\n",
      "(Iteration 17801 / 360000) loss: -0.000000\n",
      "(Iteration 17901 / 360000) loss: 5720710.584707\n",
      "(Epoch 5 / 100) train acc: 0.121000; val_acc: 0.125000\n",
      "(Iteration 18001 / 360000) loss: 13510464.310658\n",
      "(Iteration 18101 / 360000) loss: 4934059.194415\n",
      "(Iteration 18201 / 360000) loss: 13982193.283128\n",
      "(Iteration 18301 / 360000) loss: 16197911.252518\n",
      "(Iteration 18401 / 360000) loss: 5888370.490310\n",
      "(Iteration 18501 / 360000) loss: 12575279.701295\n",
      "(Iteration 18601 / 360000) loss: 6032586.302264\n",
      "(Iteration 18701 / 360000) loss: 4784990.562576\n",
      "(Iteration 18801 / 360000) loss: 10599847.949956\n",
      "(Iteration 18901 / 360000) loss: -0.000000\n",
      "(Iteration 19001 / 360000) loss: -0.000000\n",
      "(Iteration 19101 / 360000) loss: 18083098.105877\n",
      "(Iteration 19201 / 360000) loss: 8614359.302659\n",
      "(Iteration 19301 / 360000) loss: -0.000000\n",
      "(Iteration 19401 / 360000) loss: 7660161.006983\n",
      "(Iteration 19501 / 360000) loss: 5408061.944713\n",
      "(Iteration 19601 / 360000) loss: 8904919.977304\n",
      "(Iteration 19701 / 360000) loss: 18222202.799991\n",
      "(Iteration 19801 / 360000) loss: 5189831.134913\n",
      "(Iteration 19901 / 360000) loss: 11051359.501598\n",
      "(Iteration 20001 / 360000) loss: -0.000000\n",
      "(Iteration 20101 / 360000) loss: 2775285.596946\n",
      "(Iteration 20201 / 360000) loss: -0.000000\n",
      "(Iteration 20301 / 360000) loss: 9398669.581342\n",
      "(Iteration 20401 / 360000) loss: 10666043.284878\n",
      "(Iteration 20501 / 360000) loss: 8244291.276820\n",
      "(Iteration 20601 / 360000) loss: 52578880.492890\n",
      "(Iteration 20701 / 360000) loss: 7756102.468066\n",
      "(Iteration 20801 / 360000) loss: 10212757.196011\n",
      "(Iteration 20901 / 360000) loss: 9888998.255931\n",
      "(Iteration 21001 / 360000) loss: 1974353.214456\n",
      "(Iteration 21101 / 360000) loss: 6418034.842231\n",
      "(Iteration 21201 / 360000) loss: 13681592.184201\n",
      "(Iteration 21301 / 360000) loss: 7534275.039099\n",
      "(Iteration 21401 / 360000) loss: 10904987.325096\n",
      "(Iteration 21501 / 360000) loss: 5171810.916535\n",
      "(Epoch 6 / 100) train acc: 0.143000; val_acc: 0.127534\n",
      "(Iteration 21601 / 360000) loss: 9769806.810679\n",
      "(Iteration 21701 / 360000) loss: 4981046.036615\n",
      "(Iteration 21801 / 360000) loss: 11721807.100517\n",
      "(Iteration 21901 / 360000) loss: -0.000000\n",
      "(Iteration 22001 / 360000) loss: 8950252.423720\n",
      "(Iteration 22101 / 360000) loss: 1740000.266041\n",
      "(Iteration 22201 / 360000) loss: 4305388.515863\n",
      "(Iteration 22301 / 360000) loss: 4366483.233623\n",
      "(Iteration 22401 / 360000) loss: -0.000000\n",
      "(Iteration 22501 / 360000) loss: 1547646.153824\n",
      "(Iteration 22601 / 360000) loss: 8641476.398192\n",
      "(Iteration 22701 / 360000) loss: 4288027.134793\n",
      "(Iteration 22801 / 360000) loss: 2987758.034574\n",
      "(Iteration 22901 / 360000) loss: -0.000000\n",
      "(Iteration 23001 / 360000) loss: 9320695.278727\n",
      "(Iteration 23101 / 360000) loss: -0.000000\n",
      "(Iteration 23201 / 360000) loss: 4739884.467477\n",
      "(Iteration 23301 / 360000) loss: 1944034.013392\n",
      "(Iteration 23401 / 360000) loss: 2219401.522463\n",
      "(Iteration 23501 / 360000) loss: 8120557.600042\n",
      "(Iteration 23601 / 360000) loss: 9341437.022318\n",
      "(Iteration 23701 / 360000) loss: 2994201.912815\n",
      "(Iteration 23801 / 360000) loss: 6795021.648052\n",
      "(Iteration 23901 / 360000) loss: 7879380.457877\n",
      "(Iteration 24001 / 360000) loss: 3934630.939190\n",
      "(Iteration 24101 / 360000) loss: 1750783.348815\n",
      "(Iteration 24201 / 360000) loss: 3665862.636352\n",
      "(Iteration 24301 / 360000) loss: 3524327.149571\n",
      "(Iteration 24401 / 360000) loss: -0.000000\n",
      "(Iteration 24501 / 360000) loss: 5051996.875680\n",
      "(Iteration 24601 / 360000) loss: 5855492.725844\n",
      "(Iteration 24701 / 360000) loss: 11255210.808283\n",
      "(Iteration 24801 / 360000) loss: -0.000000\n",
      "(Iteration 24901 / 360000) loss: 2971457.131825\n",
      "(Iteration 25001 / 360000) loss: 8299037.430470\n",
      "(Iteration 25101 / 360000) loss: 6019271.787192\n",
      "(Epoch 7 / 100) train acc: 0.128000; val_acc: 0.125000\n",
      "(Iteration 25201 / 360000) loss: -0.000000\n",
      "(Iteration 25301 / 360000) loss: -0.000000\n",
      "(Iteration 25401 / 360000) loss: 455058.498196\n",
      "(Iteration 25501 / 360000) loss: 3191380.669953\n",
      "(Iteration 25601 / 360000) loss: -0.000000\n",
      "(Iteration 25701 / 360000) loss: 5690746.344679\n",
      "(Iteration 25801 / 360000) loss: 4789723.284559\n",
      "(Iteration 25901 / 360000) loss: 3927428.837713\n",
      "(Iteration 26001 / 360000) loss: 6283238.531677\n",
      "(Iteration 26101 / 360000) loss: 5777363.611869\n",
      "(Iteration 26201 / 360000) loss: 1407843.116689\n",
      "(Iteration 26301 / 360000) loss: 1033230.370374\n",
      "(Iteration 26401 / 360000) loss: 4610883.485902\n",
      "(Iteration 26501 / 360000) loss: 2792537.165402\n",
      "(Iteration 26601 / 360000) loss: 5186868.425189\n",
      "(Iteration 26701 / 360000) loss: 5399167.757797\n",
      "(Iteration 26801 / 360000) loss: 7722381.292086\n",
      "(Iteration 26901 / 360000) loss: 6537788.873427\n",
      "(Iteration 27001 / 360000) loss: 698728.002752\n",
      "(Iteration 27101 / 360000) loss: 5097674.237137\n",
      "(Iteration 27201 / 360000) loss: 2898497.879156\n",
      "(Iteration 27301 / 360000) loss: 4863803.229770\n",
      "(Iteration 27401 / 360000) loss: 1626918.018447\n",
      "(Iteration 27501 / 360000) loss: -0.000000\n",
      "(Iteration 27601 / 360000) loss: 7119977.968521\n",
      "(Iteration 27701 / 360000) loss: 3468508.520742\n",
      "(Iteration 27801 / 360000) loss: 4687120.796689\n",
      "(Iteration 27901 / 360000) loss: 6858242.929706\n",
      "(Iteration 28001 / 360000) loss: 5479241.506711\n",
      "(Iteration 28101 / 360000) loss: 2718886.444976\n",
      "(Iteration 28201 / 360000) loss: 7373714.040057\n",
      "(Iteration 28301 / 360000) loss: -0.000000\n",
      "(Iteration 28401 / 360000) loss: 1132671.095554\n",
      "(Iteration 28501 / 360000) loss: 4841565.866077\n",
      "(Iteration 28601 / 360000) loss: 1916618.768516\n",
      "(Iteration 28701 / 360000) loss: 5072548.663825\n",
      "(Epoch 8 / 100) train acc: 0.120000; val_acc: 0.125000\n",
      "(Iteration 28801 / 360000) loss: 7012555.674078\n",
      "(Iteration 28901 / 360000) loss: -0.000000\n",
      "(Iteration 29001 / 360000) loss: 3287744.944704\n",
      "(Iteration 29101 / 360000) loss: 8341344.564151\n",
      "(Iteration 29201 / 360000) loss: 3595495.153459\n",
      "(Iteration 29301 / 360000) loss: 3467495.514789\n",
      "(Iteration 29401 / 360000) loss: 3839218.295996\n",
      "(Iteration 29501 / 360000) loss: -0.000000\n",
      "(Iteration 29601 / 360000) loss: 1696279.347679\n",
      "(Iteration 29701 / 360000) loss: 5706516.605400\n",
      "(Iteration 29801 / 360000) loss: -0.000000\n",
      "(Iteration 29901 / 360000) loss: 2641810.169798\n",
      "(Iteration 30001 / 360000) loss: 3519128.020357\n",
      "(Iteration 30101 / 360000) loss: 34299.418632\n",
      "(Iteration 30201 / 360000) loss: 2687819.019281\n",
      "(Iteration 30301 / 360000) loss: 2622738.554623\n",
      "(Iteration 30401 / 360000) loss: 2791103.137581\n",
      "(Iteration 30501 / 360000) loss: 4832115.599047\n",
      "(Iteration 30601 / 360000) loss: 3383453.514267\n",
      "(Iteration 30701 / 360000) loss: 3082106.771280\n",
      "(Iteration 30801 / 360000) loss: 2072300.201205\n",
      "(Iteration 30901 / 360000) loss: 3891097.244290\n",
      "(Iteration 31001 / 360000) loss: 2457200.421333\n",
      "(Iteration 31101 / 360000) loss: 768741.432581\n",
      "(Iteration 31201 / 360000) loss: -0.000000\n",
      "(Iteration 31301 / 360000) loss: 1595525.481740\n",
      "(Iteration 31401 / 360000) loss: -0.000000\n",
      "(Iteration 31501 / 360000) loss: 1866767.142125\n",
      "(Iteration 31601 / 360000) loss: 4770888.731563\n",
      "(Iteration 31701 / 360000) loss: 1311963.102959\n",
      "(Iteration 31801 / 360000) loss: 1461686.510930\n",
      "(Iteration 31901 / 360000) loss: 3196653.519184\n",
      "(Iteration 32001 / 360000) loss: 883580.054459\n",
      "(Iteration 32101 / 360000) loss: 2361646.872815\n",
      "(Iteration 32201 / 360000) loss: 3854864.695171\n",
      "(Iteration 32301 / 360000) loss: -0.000000\n",
      "(Epoch 9 / 100) train acc: 0.128000; val_acc: 0.125000\n",
      "(Iteration 32401 / 360000) loss: 4411610.236444\n",
      "(Iteration 32501 / 360000) loss: 973756.142406\n",
      "(Iteration 32601 / 360000) loss: 1955856.208058\n",
      "(Iteration 32701 / 360000) loss: 1460353.008713\n",
      "(Iteration 32801 / 360000) loss: -0.000000\n",
      "(Iteration 32901 / 360000) loss: 1231745.316234\n",
      "(Iteration 33001 / 360000) loss: 4999043.817180\n",
      "(Iteration 33101 / 360000) loss: -0.000000\n",
      "(Iteration 33201 / 360000) loss: 4313989.638261\n",
      "(Iteration 33301 / 360000) loss: 3077607.935081\n",
      "(Iteration 33401 / 360000) loss: 686753.206668\n",
      "(Iteration 33501 / 360000) loss: -0.000000\n",
      "(Iteration 33601 / 360000) loss: 4423642.782892\n",
      "(Iteration 33701 / 360000) loss: 3682736.393888\n",
      "(Iteration 33801 / 360000) loss: 2999241.887862\n",
      "(Iteration 33901 / 360000) loss: 1653188.630899\n",
      "(Iteration 34001 / 360000) loss: 1901880.668756\n",
      "(Iteration 34101 / 360000) loss: 1125702.980136\n",
      "(Iteration 34201 / 360000) loss: 2156448.515346\n",
      "(Iteration 34301 / 360000) loss: 2607119.729036\n",
      "(Iteration 34401 / 360000) loss: 1887684.695558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 34501 / 360000) loss: 2716401.606287\n",
      "(Iteration 34601 / 360000) loss: 1500981.338877\n",
      "(Iteration 34701 / 360000) loss: 155237.415213\n",
      "(Iteration 34801 / 360000) loss: 3243608.211443\n",
      "(Iteration 34901 / 360000) loss: 861873.849686\n",
      "(Iteration 35001 / 360000) loss: 4282955.626787\n",
      "(Iteration 35101 / 360000) loss: -0.000000\n",
      "(Iteration 35201 / 360000) loss: 1607402.295127\n",
      "(Iteration 35301 / 360000) loss: 2294573.158623\n",
      "(Iteration 35401 / 360000) loss: 128903.272478\n",
      "(Iteration 35501 / 360000) loss: 3948926.018095\n",
      "(Iteration 35601 / 360000) loss: 2209504.610347\n",
      "(Iteration 35701 / 360000) loss: 731073.154154\n",
      "(Iteration 35801 / 360000) loss: 394633.731553\n",
      "(Iteration 35901 / 360000) loss: 1771556.025640\n",
      "(Epoch 10 / 100) train acc: 0.108000; val_acc: 0.125000\n",
      "(Iteration 36001 / 360000) loss: 845812.487188\n",
      "(Iteration 36101 / 360000) loss: 2796920.920060\n",
      "(Iteration 36201 / 360000) loss: 1169328.383307\n",
      "(Iteration 36301 / 360000) loss: 70532.816682\n",
      "(Iteration 36401 / 360000) loss: 1259610.237032\n",
      "(Iteration 36501 / 360000) loss: 1120163.033744\n",
      "(Iteration 36601 / 360000) loss: 1722783.304048\n",
      "(Iteration 36701 / 360000) loss: 1750319.907570\n",
      "(Iteration 36801 / 360000) loss: 2290949.246420\n",
      "(Iteration 36901 / 360000) loss: -0.000000\n",
      "(Iteration 37001 / 360000) loss: 2687777.655594\n",
      "(Iteration 37101 / 360000) loss: 1123208.223636\n",
      "(Iteration 37201 / 360000) loss: 395498.761131\n",
      "(Iteration 37301 / 360000) loss: 264251.023404\n",
      "(Iteration 37401 / 360000) loss: -0.000000\n",
      "(Iteration 37501 / 360000) loss: 1106695.720998\n",
      "(Iteration 37601 / 360000) loss: 1113270.866829\n",
      "(Iteration 37701 / 360000) loss: 987435.844286\n",
      "(Iteration 37801 / 360000) loss: -0.000000\n",
      "(Iteration 37901 / 360000) loss: 1903490.367770\n",
      "(Iteration 38001 / 360000) loss: 1809584.275551\n",
      "(Iteration 38101 / 360000) loss: 2397089.629694\n",
      "(Iteration 38201 / 360000) loss: 1152182.241299\n",
      "(Iteration 38301 / 360000) loss: 2356340.042009\n",
      "(Iteration 38401 / 360000) loss: 1260997.102902\n",
      "(Iteration 38501 / 360000) loss: 886761.316743\n",
      "(Iteration 38601 / 360000) loss: 950782.081497\n",
      "(Iteration 38701 / 360000) loss: 1348449.726021\n",
      "(Iteration 38801 / 360000) loss: 633915.918869\n",
      "(Iteration 38901 / 360000) loss: 1962621.695287\n",
      "(Iteration 39001 / 360000) loss: 424326.040540\n",
      "(Iteration 39101 / 360000) loss: 878834.105951\n",
      "(Iteration 39201 / 360000) loss: -0.000000\n",
      "(Iteration 39301 / 360000) loss: -0.000000\n",
      "(Iteration 39401 / 360000) loss: 583226.680604\n",
      "(Iteration 39501 / 360000) loss: -0.000000\n",
      "(Epoch 11 / 100) train acc: 0.129000; val_acc: 0.125000\n",
      "(Iteration 39601 / 360000) loss: 521041.323422\n",
      "(Iteration 39701 / 360000) loss: 208603.476313\n",
      "(Iteration 39801 / 360000) loss: 379207.189546\n",
      "(Iteration 39901 / 360000) loss: 751878.382213\n",
      "(Iteration 40001 / 360000) loss: 1570122.451307\n",
      "(Iteration 40101 / 360000) loss: 1189024.384825\n",
      "(Iteration 40201 / 360000) loss: -0.000000\n",
      "(Iteration 40301 / 360000) loss: 14372.591111\n",
      "(Iteration 40401 / 360000) loss: 1103373.271651\n",
      "(Iteration 40501 / 360000) loss: 793166.459537\n",
      "(Iteration 40601 / 360000) loss: 346702.666343\n",
      "(Iteration 40701 / 360000) loss: 630205.593357\n",
      "(Iteration 40801 / 360000) loss: -0.000000\n",
      "(Iteration 40901 / 360000) loss: 421651.026204\n",
      "(Iteration 41001 / 360000) loss: 872155.145622\n",
      "(Iteration 41101 / 360000) loss: -0.000000\n",
      "(Iteration 41201 / 360000) loss: 2929217.392808\n",
      "(Iteration 41301 / 360000) loss: 1048671.002433\n",
      "(Iteration 41401 / 360000) loss: 841895.688151\n",
      "(Iteration 41501 / 360000) loss: 1069104.920977\n",
      "(Iteration 41601 / 360000) loss: 486893.316495\n",
      "(Iteration 41701 / 360000) loss: 1511417.529558\n",
      "(Iteration 41801 / 360000) loss: 1953067.469174\n",
      "(Iteration 41901 / 360000) loss: 882112.857182\n",
      "(Iteration 42001 / 360000) loss: 374628.304478\n",
      "(Iteration 42101 / 360000) loss: 1476688.838844\n",
      "(Iteration 42201 / 360000) loss: -0.000000\n",
      "(Iteration 42301 / 360000) loss: -0.000000\n",
      "(Iteration 42401 / 360000) loss: 535522.651674\n",
      "(Iteration 42501 / 360000) loss: -0.000000\n",
      "(Iteration 42601 / 360000) loss: 1437125.894448\n",
      "(Iteration 42701 / 360000) loss: 1075210.207123\n",
      "(Iteration 42801 / 360000) loss: 903912.312634\n",
      "(Iteration 42901 / 360000) loss: 1456878.934089\n",
      "(Iteration 43001 / 360000) loss: 405004.342356\n",
      "(Iteration 43101 / 360000) loss: 1548400.099240\n",
      "(Epoch 12 / 100) train acc: 0.215000; val_acc: 0.232264\n",
      "(Iteration 43201 / 360000) loss: 818439.090795\n",
      "(Iteration 43301 / 360000) loss: 301404.370366\n",
      "(Iteration 43401 / 360000) loss: 1648893.044060\n",
      "(Iteration 43501 / 360000) loss: 350554.866549\n",
      "(Iteration 43601 / 360000) loss: 20244.448134\n",
      "(Iteration 43701 / 360000) loss: 153638.959561\n",
      "(Iteration 43801 / 360000) loss: 1101060.057269\n",
      "(Iteration 43901 / 360000) loss: 317477.024012\n",
      "(Iteration 44001 / 360000) loss: -0.000000\n",
      "(Iteration 44101 / 360000) loss: -0.000000\n",
      "(Iteration 44201 / 360000) loss: 447691.189418\n",
      "(Iteration 44301 / 360000) loss: 306811.028791\n",
      "(Iteration 44401 / 360000) loss: 618168.127928\n",
      "(Iteration 44501 / 360000) loss: 787118.711549\n",
      "(Iteration 44601 / 360000) loss: 1368028.529923\n",
      "(Iteration 44701 / 360000) loss: -0.000000\n",
      "(Iteration 44801 / 360000) loss: 543327.316263\n",
      "(Iteration 44901 / 360000) loss: 184146.454098\n",
      "(Iteration 45001 / 360000) loss: 473888.309349\n",
      "(Iteration 45101 / 360000) loss: 308241.433914\n",
      "(Iteration 45201 / 360000) loss: 276406.231548\n",
      "(Iteration 45301 / 360000) loss: 529674.167522\n",
      "(Iteration 45401 / 360000) loss: 298811.805087\n",
      "(Iteration 45501 / 360000) loss: 1150005.389099\n",
      "(Iteration 45601 / 360000) loss: 1386102.732019\n",
      "(Iteration 45701 / 360000) loss: -0.000000\n",
      "(Iteration 45801 / 360000) loss: 303248.868185\n",
      "(Iteration 45901 / 360000) loss: -0.000000\n",
      "(Iteration 46001 / 360000) loss: 1151753.108049\n",
      "(Iteration 46101 / 360000) loss: 514326.439491\n",
      "(Iteration 46201 / 360000) loss: 1967600.055766\n",
      "(Iteration 46301 / 360000) loss: 559393.698584\n",
      "(Iteration 46401 / 360000) loss: 868174.977268\n",
      "(Iteration 46501 / 360000) loss: 351166.113732\n",
      "(Iteration 46601 / 360000) loss: -0.000000\n",
      "(Iteration 46701 / 360000) loss: 467045.085845\n",
      "(Epoch 13 / 100) train acc: 0.278000; val_acc: 0.264358\n",
      "(Iteration 46801 / 360000) loss: 1822447.141418\n",
      "(Iteration 46901 / 360000) loss: -0.000000\n",
      "(Iteration 47001 / 360000) loss: 473957.847141\n",
      "(Iteration 47101 / 360000) loss: -0.000000\n",
      "(Iteration 47201 / 360000) loss: 707412.897004\n",
      "(Iteration 47301 / 360000) loss: 286213.068676\n",
      "(Iteration 47401 / 360000) loss: 1025442.329814\n",
      "(Iteration 47501 / 360000) loss: 508130.887622\n",
      "(Iteration 47601 / 360000) loss: 115153.482647\n",
      "(Iteration 47701 / 360000) loss: 428661.000876\n",
      "(Iteration 47801 / 360000) loss: 850031.616925\n",
      "(Iteration 47901 / 360000) loss: 346335.625893\n",
      "(Iteration 48001 / 360000) loss: 563864.130275\n",
      "(Iteration 48101 / 360000) loss: -0.000000\n",
      "(Iteration 48201 / 360000) loss: 712393.478165\n",
      "(Iteration 48301 / 360000) loss: 33511.996628\n",
      "(Iteration 48401 / 360000) loss: 886299.107145\n",
      "(Iteration 48501 / 360000) loss: -0.000000\n",
      "(Iteration 48601 / 360000) loss: -0.000000\n",
      "(Iteration 48701 / 360000) loss: -0.000000\n",
      "(Iteration 48801 / 360000) loss: 37370.078378\n",
      "(Iteration 48901 / 360000) loss: 308162.284092\n",
      "(Iteration 49001 / 360000) loss: 51241.345002\n",
      "(Iteration 49101 / 360000) loss: 358046.777088\n",
      "(Iteration 49201 / 360000) loss: -0.000000\n",
      "(Iteration 49301 / 360000) loss: -0.000000\n",
      "(Iteration 49401 / 360000) loss: 375890.084803\n",
      "(Iteration 49501 / 360000) loss: 505099.690398\n",
      "(Iteration 49601 / 360000) loss: 643254.842515\n",
      "(Iteration 49701 / 360000) loss: 358596.533853\n",
      "(Iteration 49801 / 360000) loss: 397224.108218\n",
      "(Iteration 49901 / 360000) loss: 2815925.272631\n",
      "(Iteration 50001 / 360000) loss: 283403.278075\n",
      "(Iteration 50101 / 360000) loss: -0.000000\n",
      "(Iteration 50201 / 360000) loss: 981499.408852\n",
      "(Iteration 50301 / 360000) loss: 538504.185595\n",
      "(Epoch 14 / 100) train acc: 0.271000; val_acc: 0.260135\n",
      "(Iteration 50401 / 360000) loss: 218844.499240\n",
      "(Iteration 50501 / 360000) loss: -0.000000\n",
      "(Iteration 50601 / 360000) loss: 230659.434961\n",
      "(Iteration 50701 / 360000) loss: -0.000000\n",
      "(Iteration 50801 / 360000) loss: 201029.558116\n",
      "(Iteration 50901 / 360000) loss: -0.000000\n",
      "(Iteration 51001 / 360000) loss: 1931350.507680\n",
      "(Iteration 51101 / 360000) loss: 24590.887469\n",
      "(Iteration 51201 / 360000) loss: 297113.874725\n",
      "(Iteration 51301 / 360000) loss: 37824.564543\n",
      "(Iteration 51401 / 360000) loss: -0.000000\n",
      "(Iteration 51501 / 360000) loss: 32993.693514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 51601 / 360000) loss: 206658.161248\n",
      "(Iteration 51701 / 360000) loss: 124260.154306\n",
      "(Iteration 51801 / 360000) loss: 391072.652965\n",
      "(Iteration 51901 / 360000) loss: 332483.499028\n",
      "(Iteration 52001 / 360000) loss: 206499.586543\n",
      "(Iteration 52101 / 360000) loss: 252696.364560\n",
      "(Iteration 52201 / 360000) loss: 723508.196687\n",
      "(Iteration 52301 / 360000) loss: 312524.207938\n",
      "(Iteration 52401 / 360000) loss: 226610.408712\n",
      "(Iteration 52501 / 360000) loss: -0.000000\n",
      "(Iteration 52601 / 360000) loss: 324829.753743\n",
      "(Iteration 52701 / 360000) loss: -0.000000\n",
      "(Iteration 52801 / 360000) loss: -0.000000\n",
      "(Iteration 52901 / 360000) loss: 583177.440152\n",
      "(Iteration 53001 / 360000) loss: 343768.400219\n",
      "(Iteration 53101 / 360000) loss: -0.000000\n",
      "(Iteration 53201 / 360000) loss: -0.000000\n",
      "(Iteration 53301 / 360000) loss: -0.000000\n",
      "(Iteration 53401 / 360000) loss: 200731.922639\n",
      "(Iteration 53501 / 360000) loss: 527180.550700\n",
      "(Iteration 53601 / 360000) loss: 330040.136345\n",
      "(Iteration 53701 / 360000) loss: 281778.584182\n",
      "(Iteration 53801 / 360000) loss: 392829.414582\n",
      "(Iteration 53901 / 360000) loss: 294271.753885\n",
      "(Epoch 15 / 100) train acc: 0.173000; val_acc: 0.186655\n",
      "(Iteration 54001 / 360000) loss: 120136.635101\n",
      "(Iteration 54101 / 360000) loss: 71524.901759\n",
      "(Iteration 54201 / 360000) loss: 428883.780695\n",
      "(Iteration 54301 / 360000) loss: 131399.683754\n",
      "(Iteration 54401 / 360000) loss: 136305.355288\n",
      "(Iteration 54501 / 360000) loss: -0.000000\n",
      "(Iteration 54601 / 360000) loss: 191976.161720\n",
      "(Iteration 54701 / 360000) loss: 67432.475381\n",
      "(Iteration 54801 / 360000) loss: -0.000000\n",
      "(Iteration 54901 / 360000) loss: -0.000000\n",
      "(Iteration 55001 / 360000) loss: 143978.598427\n",
      "(Iteration 55101 / 360000) loss: 354668.450973\n",
      "(Iteration 55201 / 360000) loss: 179862.568705\n",
      "(Iteration 55301 / 360000) loss: 221942.501605\n",
      "(Iteration 55401 / 360000) loss: -0.000000\n",
      "(Iteration 55501 / 360000) loss: -0.000000\n",
      "(Iteration 55601 / 360000) loss: 37951.274137\n",
      "(Iteration 55701 / 360000) loss: 6277.310782\n",
      "(Iteration 55801 / 360000) loss: 175301.718739\n",
      "(Iteration 55901 / 360000) loss: -0.000000\n",
      "(Iteration 56001 / 360000) loss: 265169.141311\n",
      "(Iteration 56101 / 360000) loss: 143777.633184\n",
      "(Iteration 56201 / 360000) loss: 615278.117637\n",
      "(Iteration 56301 / 360000) loss: 39163.057705\n",
      "(Iteration 56401 / 360000) loss: 217549.316231\n",
      "(Iteration 56501 / 360000) loss: -0.000000\n",
      "(Iteration 56601 / 360000) loss: 601186.847247\n",
      "(Iteration 56701 / 360000) loss: 113372.015577\n",
      "(Iteration 56801 / 360000) loss: 299953.248041\n",
      "(Iteration 56901 / 360000) loss: 95810.667402\n",
      "(Iteration 57001 / 360000) loss: -0.000000\n",
      "(Iteration 57101 / 360000) loss: 459383.279369\n",
      "(Iteration 57201 / 360000) loss: 108010.066191\n",
      "(Iteration 57301 / 360000) loss: -0.000000\n",
      "(Iteration 57401 / 360000) loss: -0.000000\n",
      "(Iteration 57501 / 360000) loss: 78535.360654\n",
      "(Epoch 16 / 100) train acc: 0.137000; val_acc: 0.135980\n",
      "(Iteration 57601 / 360000) loss: 325758.221715\n",
      "(Iteration 57701 / 360000) loss: 44175.778599\n",
      "(Iteration 57801 / 360000) loss: 33157.423518\n",
      "(Iteration 57901 / 360000) loss: 104121.209255\n",
      "(Iteration 58001 / 360000) loss: 297898.073707\n",
      "(Iteration 58101 / 360000) loss: 196431.400679\n",
      "(Iteration 58201 / 360000) loss: -0.000000\n",
      "(Iteration 58301 / 360000) loss: 287586.526117\n",
      "(Iteration 58401 / 360000) loss: 124365.085059\n",
      "(Iteration 58501 / 360000) loss: 379899.692351\n",
      "(Iteration 58601 / 360000) loss: -0.000000\n",
      "(Iteration 58701 / 360000) loss: -0.000000\n",
      "(Iteration 58801 / 360000) loss: 269400.973656\n",
      "(Iteration 58901 / 360000) loss: 50431.624123\n",
      "(Iteration 59001 / 360000) loss: -0.000000\n",
      "(Iteration 59101 / 360000) loss: -0.000000\n",
      "(Iteration 59201 / 360000) loss: 144559.159891\n",
      "(Iteration 59301 / 360000) loss: 413360.856109\n",
      "(Iteration 59401 / 360000) loss: -0.000000\n",
      "(Iteration 59501 / 360000) loss: -0.000000\n",
      "(Iteration 59601 / 360000) loss: 310161.602608\n",
      "(Iteration 59701 / 360000) loss: 211417.646801\n",
      "(Iteration 59801 / 360000) loss: 179468.260832\n",
      "(Iteration 59901 / 360000) loss: 16650.310400\n",
      "(Iteration 60001 / 360000) loss: -0.000000\n",
      "(Iteration 60101 / 360000) loss: -0.000000\n",
      "(Iteration 60201 / 360000) loss: -0.000000\n",
      "(Iteration 60301 / 360000) loss: 23985.729205\n",
      "(Iteration 60401 / 360000) loss: -0.000000\n",
      "(Iteration 60501 / 360000) loss: 208669.064615\n",
      "(Iteration 60601 / 360000) loss: 229880.216425\n",
      "(Iteration 60701 / 360000) loss: 21531.004401\n",
      "(Iteration 60801 / 360000) loss: 269384.021561\n",
      "(Iteration 60901 / 360000) loss: -0.000000\n",
      "(Iteration 61001 / 360000) loss: 133275.609926\n",
      "(Iteration 61101 / 360000) loss: 26204.880974\n",
      "(Epoch 17 / 100) train acc: 0.255000; val_acc: 0.243243\n",
      "(Iteration 61201 / 360000) loss: 376415.578590\n",
      "(Iteration 61301 / 360000) loss: 111939.598432\n",
      "(Iteration 61401 / 360000) loss: 208361.280011\n",
      "(Iteration 61501 / 360000) loss: 228376.191722\n",
      "(Iteration 61601 / 360000) loss: 22054.413677\n",
      "(Iteration 61701 / 360000) loss: -0.000000\n",
      "(Iteration 61801 / 360000) loss: 205351.749531\n",
      "(Iteration 61901 / 360000) loss: 26089.051028\n",
      "(Iteration 62001 / 360000) loss: 28470.096132\n",
      "(Iteration 62101 / 360000) loss: -0.000000\n",
      "(Iteration 62201 / 360000) loss: 17054.436856\n",
      "(Iteration 62301 / 360000) loss: 247110.660974\n",
      "(Iteration 62401 / 360000) loss: -0.000000\n",
      "(Iteration 62501 / 360000) loss: 37367.680381\n",
      "(Iteration 62601 / 360000) loss: -0.000000\n",
      "(Iteration 62701 / 360000) loss: -0.000000\n",
      "(Iteration 62801 / 360000) loss: 210241.100030\n",
      "(Iteration 62901 / 360000) loss: 232006.073709\n",
      "(Iteration 63001 / 360000) loss: 210301.842295\n",
      "(Iteration 63101 / 360000) loss: -0.000000\n",
      "(Iteration 63201 / 360000) loss: 1641.031429\n",
      "(Iteration 63301 / 360000) loss: 27444.349997\n",
      "(Iteration 63401 / 360000) loss: 70519.800608\n",
      "(Iteration 63501 / 360000) loss: -0.000000\n",
      "(Iteration 63601 / 360000) loss: 69349.178037\n",
      "(Iteration 63701 / 360000) loss: 145623.202103\n",
      "(Iteration 63801 / 360000) loss: 276766.345455\n",
      "(Iteration 63901 / 360000) loss: 26658.212163\n",
      "(Iteration 64001 / 360000) loss: 1195.097997\n",
      "(Iteration 64101 / 360000) loss: 105233.001715\n",
      "(Iteration 64201 / 360000) loss: -0.000000\n",
      "(Iteration 64301 / 360000) loss: 104386.026415\n",
      "(Iteration 64401 / 360000) loss: 65342.179171\n",
      "(Iteration 64501 / 360000) loss: -0.000000\n",
      "(Iteration 64601 / 360000) loss: -0.000000\n",
      "(Iteration 64701 / 360000) loss: 58773.982055\n",
      "(Epoch 18 / 100) train acc: 0.258000; val_acc: 0.236486\n",
      "(Iteration 64801 / 360000) loss: 242759.981468\n",
      "(Iteration 64901 / 360000) loss: 323265.386538\n",
      "(Iteration 65001 / 360000) loss: -0.000000\n",
      "(Iteration 65101 / 360000) loss: 58690.711417\n",
      "(Iteration 65201 / 360000) loss: -0.000000\n",
      "(Iteration 65301 / 360000) loss: 134570.695365\n",
      "(Iteration 65401 / 360000) loss: -0.000000\n",
      "(Iteration 65501 / 360000) loss: 58087.144318\n",
      "(Iteration 65601 / 360000) loss: -0.000000\n",
      "(Iteration 65701 / 360000) loss: -0.000000\n",
      "(Iteration 65801 / 360000) loss: -0.000000\n",
      "(Iteration 65901 / 360000) loss: -0.000000\n",
      "(Iteration 66001 / 360000) loss: -0.000000\n",
      "(Iteration 66101 / 360000) loss: -0.000000\n",
      "(Iteration 66201 / 360000) loss: 184276.957109\n",
      "(Iteration 66301 / 360000) loss: 63443.363636\n",
      "(Iteration 66401 / 360000) loss: -0.000000\n",
      "(Iteration 66501 / 360000) loss: 51784.882307\n",
      "(Iteration 66601 / 360000) loss: 66873.986521\n",
      "(Iteration 66701 / 360000) loss: -0.000000\n",
      "(Iteration 66801 / 360000) loss: 113306.354433\n",
      "(Iteration 66901 / 360000) loss: -0.000000\n",
      "(Iteration 67001 / 360000) loss: -0.000000\n",
      "(Iteration 67101 / 360000) loss: -0.000000\n",
      "(Iteration 67201 / 360000) loss: -0.000000\n",
      "(Iteration 67301 / 360000) loss: 217756.898098\n",
      "(Iteration 67401 / 360000) loss: -0.000000\n",
      "(Iteration 67501 / 360000) loss: 73102.961287\n",
      "(Iteration 67601 / 360000) loss: -0.000000\n",
      "(Iteration 67701 / 360000) loss: 7489.727281\n",
      "(Iteration 67801 / 360000) loss: -0.000000\n",
      "(Iteration 67901 / 360000) loss: -0.000000\n",
      "(Iteration 68001 / 360000) loss: 68242.777276\n",
      "(Iteration 68101 / 360000) loss: -0.000000\n",
      "(Iteration 68201 / 360000) loss: 96321.364077\n",
      "(Iteration 68301 / 360000) loss: 6275.313773\n",
      "(Epoch 19 / 100) train acc: 0.415000; val_acc: 0.376689\n",
      "(Iteration 68401 / 360000) loss: 26998.440866\n",
      "(Iteration 68501 / 360000) loss: 95613.128298\n",
      "(Iteration 68601 / 360000) loss: -0.000000\n",
      "(Iteration 68701 / 360000) loss: -0.000000\n",
      "(Iteration 68801 / 360000) loss: -0.000000\n",
      "(Iteration 68901 / 360000) loss: -0.000000\n",
      "(Iteration 69001 / 360000) loss: -0.000000\n",
      "(Iteration 69101 / 360000) loss: 129500.089135\n",
      "(Iteration 69201 / 360000) loss: 82795.255408\n",
      "(Iteration 69301 / 360000) loss: 98631.839814\n",
      "(Iteration 69401 / 360000) loss: -0.000000\n",
      "(Iteration 69501 / 360000) loss: -0.000000\n",
      "(Iteration 69601 / 360000) loss: 46140.382412\n",
      "(Iteration 69701 / 360000) loss: -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 69801 / 360000) loss: -0.000000\n",
      "(Iteration 69901 / 360000) loss: -0.000000\n",
      "(Iteration 70001 / 360000) loss: -0.000000\n",
      "(Iteration 70101 / 360000) loss: 3237.522759\n",
      "(Iteration 70201 / 360000) loss: -0.000000\n",
      "(Iteration 70301 / 360000) loss: 66892.741761\n",
      "(Iteration 70401 / 360000) loss: 43835.075003\n",
      "(Iteration 70501 / 360000) loss: -0.000000\n",
      "(Iteration 70601 / 360000) loss: -0.000000\n",
      "(Iteration 70701 / 360000) loss: -0.000000\n",
      "(Iteration 70801 / 360000) loss: 5205.406338\n",
      "(Iteration 70901 / 360000) loss: 93141.875568\n",
      "(Iteration 71001 / 360000) loss: -0.000000\n",
      "(Iteration 71101 / 360000) loss: 63023.048825\n",
      "(Iteration 71201 / 360000) loss: 20094.627122\n",
      "(Iteration 71301 / 360000) loss: 79940.678496\n",
      "(Iteration 71401 / 360000) loss: 204436.177948\n",
      "(Iteration 71501 / 360000) loss: -0.000000\n",
      "(Iteration 71601 / 360000) loss: -0.000000\n",
      "(Iteration 71701 / 360000) loss: -0.000000\n",
      "(Iteration 71801 / 360000) loss: -0.000000\n",
      "(Iteration 71901 / 360000) loss: 80576.118483\n",
      "(Epoch 20 / 100) train acc: 0.424000; val_acc: 0.395270\n",
      "(Iteration 72001 / 360000) loss: -0.000000\n",
      "(Iteration 72101 / 360000) loss: -0.000000\n",
      "(Iteration 72201 / 360000) loss: 18865.652265\n",
      "(Iteration 72301 / 360000) loss: -0.000000\n",
      "(Iteration 72401 / 360000) loss: 67914.482889\n",
      "(Iteration 72501 / 360000) loss: 594.597444\n",
      "(Iteration 72601 / 360000) loss: -0.000000\n",
      "(Iteration 72701 / 360000) loss: 23576.691147\n",
      "(Iteration 72801 / 360000) loss: -0.000000\n",
      "(Iteration 72901 / 360000) loss: 78406.075422\n",
      "(Iteration 73001 / 360000) loss: 24839.923560\n",
      "(Iteration 73101 / 360000) loss: -0.000000\n",
      "(Iteration 73201 / 360000) loss: -0.000000\n",
      "(Iteration 73301 / 360000) loss: -0.000000\n",
      "(Iteration 73401 / 360000) loss: -0.000000\n",
      "(Iteration 73501 / 360000) loss: -0.000000\n",
      "(Iteration 73601 / 360000) loss: 32687.755780\n",
      "(Iteration 73701 / 360000) loss: 32300.120551\n",
      "(Iteration 73801 / 360000) loss: -0.000000\n",
      "(Iteration 73901 / 360000) loss: -0.000000\n",
      "(Iteration 74001 / 360000) loss: 15549.087534\n",
      "(Iteration 74101 / 360000) loss: -0.000000\n",
      "(Iteration 74201 / 360000) loss: -0.000000\n",
      "(Iteration 74301 / 360000) loss: -0.000000\n",
      "(Iteration 74401 / 360000) loss: 61160.770456\n",
      "(Iteration 74501 / 360000) loss: -0.000000\n",
      "(Iteration 74601 / 360000) loss: -0.000000\n",
      "(Iteration 74701 / 360000) loss: -0.000000\n",
      "(Iteration 74801 / 360000) loss: -0.000000\n",
      "(Iteration 74901 / 360000) loss: 5077.788392\n",
      "(Iteration 75001 / 360000) loss: 11125.794980\n",
      "(Iteration 75101 / 360000) loss: 31134.804240\n",
      "(Iteration 75201 / 360000) loss: -0.000000\n",
      "(Iteration 75301 / 360000) loss: -0.000000\n",
      "(Iteration 75401 / 360000) loss: -0.000000\n",
      "(Iteration 75501 / 360000) loss: 47220.553033\n",
      "(Epoch 21 / 100) train acc: 0.135000; val_acc: 0.137669\n",
      "(Iteration 75601 / 360000) loss: 30847.091162\n",
      "(Iteration 75701 / 360000) loss: 92865.083137\n",
      "(Iteration 75801 / 360000) loss: -0.000000\n",
      "(Iteration 75901 / 360000) loss: -0.000000\n",
      "(Iteration 76001 / 360000) loss: -0.000000\n",
      "(Iteration 76101 / 360000) loss: 5394.876666\n",
      "(Iteration 76201 / 360000) loss: 38835.066294\n",
      "(Iteration 76301 / 360000) loss: -0.000000\n",
      "(Iteration 76401 / 360000) loss: -0.000000\n",
      "(Iteration 76501 / 360000) loss: 60528.538189\n",
      "(Iteration 76601 / 360000) loss: -0.000000\n",
      "(Iteration 76701 / 360000) loss: -0.000000\n",
      "(Iteration 76801 / 360000) loss: -0.000000\n",
      "(Iteration 76901 / 360000) loss: -0.000000\n",
      "(Iteration 77001 / 360000) loss: 3666.660781\n",
      "(Iteration 77101 / 360000) loss: -0.000000\n",
      "(Iteration 77201 / 360000) loss: -0.000000\n",
      "(Iteration 77301 / 360000) loss: 15169.039264\n",
      "(Iteration 77401 / 360000) loss: -0.000000\n",
      "(Iteration 77501 / 360000) loss: 17830.411842\n",
      "(Iteration 77601 / 360000) loss: 7883.495381\n",
      "(Iteration 77701 / 360000) loss: 21766.507649\n",
      "(Iteration 77801 / 360000) loss: -0.000000\n",
      "(Iteration 77901 / 360000) loss: -0.000000\n",
      "(Iteration 78001 / 360000) loss: -0.000000\n",
      "(Iteration 78101 / 360000) loss: 5890.529841\n",
      "(Iteration 78201 / 360000) loss: 61052.909716\n",
      "(Iteration 78301 / 360000) loss: -0.000000\n",
      "(Iteration 78401 / 360000) loss: 11787.954063\n",
      "(Iteration 78501 / 360000) loss: -0.000000\n",
      "(Iteration 78601 / 360000) loss: -0.000000\n",
      "(Iteration 78701 / 360000) loss: 11342.794087\n",
      "(Iteration 78801 / 360000) loss: 13000.128777\n",
      "(Iteration 78901 / 360000) loss: -0.000000\n",
      "(Iteration 79001 / 360000) loss: -0.000000\n",
      "(Iteration 79101 / 360000) loss: 22528.312926\n",
      "(Epoch 22 / 100) train acc: 0.440000; val_acc: 0.402027\n",
      "(Iteration 79201 / 360000) loss: 16254.006742\n",
      "(Iteration 79301 / 360000) loss: 14725.835125\n",
      "(Iteration 79401 / 360000) loss: -0.000000\n",
      "(Iteration 79501 / 360000) loss: 11178.152963\n",
      "(Iteration 79601 / 360000) loss: -0.000000\n",
      "(Iteration 79701 / 360000) loss: 10834.823070\n",
      "(Iteration 79801 / 360000) loss: 18279.320028\n",
      "(Iteration 79901 / 360000) loss: -0.000000\n",
      "(Iteration 80001 / 360000) loss: -0.000000\n",
      "(Iteration 80101 / 360000) loss: 34592.888734\n",
      "(Iteration 80201 / 360000) loss: 25437.282320\n",
      "(Iteration 80301 / 360000) loss: -0.000000\n",
      "(Iteration 80401 / 360000) loss: 12653.980806\n",
      "(Iteration 80501 / 360000) loss: -0.000000\n",
      "(Iteration 80601 / 360000) loss: -0.000000\n",
      "(Iteration 80701 / 360000) loss: -0.000000\n",
      "(Iteration 80801 / 360000) loss: -0.000000\n",
      "(Iteration 80901 / 360000) loss: -0.000000\n",
      "(Iteration 81001 / 360000) loss: 20264.600271\n",
      "(Iteration 81101 / 360000) loss: -0.000000\n",
      "(Iteration 81201 / 360000) loss: -0.000000\n",
      "(Iteration 81301 / 360000) loss: 31453.091561\n",
      "(Iteration 81401 / 360000) loss: -0.000000\n",
      "(Iteration 81501 / 360000) loss: 17380.802203\n",
      "(Iteration 81601 / 360000) loss: -0.000000\n",
      "(Iteration 81701 / 360000) loss: -0.000000\n",
      "(Iteration 81801 / 360000) loss: -0.000000\n",
      "(Iteration 81901 / 360000) loss: -0.000000\n",
      "(Iteration 82001 / 360000) loss: -0.000000\n",
      "(Iteration 82101 / 360000) loss: -0.000000\n",
      "(Iteration 82201 / 360000) loss: 2235.101698\n",
      "(Iteration 82301 / 360000) loss: -0.000000\n",
      "(Iteration 82401 / 360000) loss: 19531.925224\n",
      "(Iteration 82501 / 360000) loss: 11900.317751\n",
      "(Iteration 82601 / 360000) loss: -0.000000\n",
      "(Iteration 82701 / 360000) loss: 31053.431859\n",
      "(Epoch 23 / 100) train acc: 0.584000; val_acc: 0.521959\n",
      "(Iteration 82801 / 360000) loss: -0.000000\n",
      "(Iteration 82901 / 360000) loss: 14778.619728\n",
      "(Iteration 83001 / 360000) loss: 6437.039471\n",
      "(Iteration 83101 / 360000) loss: -0.000000\n",
      "(Iteration 83201 / 360000) loss: 22685.718810\n",
      "(Iteration 83301 / 360000) loss: -0.000000\n",
      "(Iteration 83401 / 360000) loss: 7535.862867\n",
      "(Iteration 83501 / 360000) loss: 66.049901\n",
      "(Iteration 83601 / 360000) loss: 135.737862\n",
      "(Iteration 83701 / 360000) loss: 11822.297031\n",
      "(Iteration 83801 / 360000) loss: -0.000000\n",
      "(Iteration 83901 / 360000) loss: -0.000000\n",
      "(Iteration 84001 / 360000) loss: -0.000000\n",
      "(Iteration 84101 / 360000) loss: 6157.186891\n",
      "(Iteration 84201 / 360000) loss: -0.000000\n",
      "(Iteration 84301 / 360000) loss: -0.000000\n",
      "(Iteration 84401 / 360000) loss: -0.000000\n",
      "(Iteration 84501 / 360000) loss: -0.000000\n",
      "(Iteration 84601 / 360000) loss: -0.000000\n",
      "(Iteration 84701 / 360000) loss: -0.000000\n",
      "(Iteration 84801 / 360000) loss: -0.000000\n",
      "(Iteration 84901 / 360000) loss: -0.000000\n",
      "(Iteration 85001 / 360000) loss: 24433.214710\n",
      "(Iteration 85101 / 360000) loss: -0.000000\n",
      "(Iteration 85201 / 360000) loss: -0.000000\n",
      "(Iteration 85301 / 360000) loss: -0.000000\n",
      "(Iteration 85401 / 360000) loss: -0.000000\n",
      "(Iteration 85501 / 360000) loss: -0.000000\n",
      "(Iteration 85601 / 360000) loss: -0.000000\n",
      "(Iteration 85701 / 360000) loss: -0.000000\n",
      "(Iteration 85801 / 360000) loss: -0.000000\n",
      "(Iteration 85901 / 360000) loss: 20307.131388\n",
      "(Iteration 86001 / 360000) loss: -0.000000\n",
      "(Iteration 86101 / 360000) loss: 9737.007372\n",
      "(Iteration 86201 / 360000) loss: 9364.814945\n",
      "(Iteration 86301 / 360000) loss: 9766.199737\n",
      "(Epoch 24 / 100) train acc: 0.632000; val_acc: 0.598818\n",
      "(Iteration 86401 / 360000) loss: -0.000000\n",
      "(Iteration 86501 / 360000) loss: -0.000000\n",
      "(Iteration 86601 / 360000) loss: -0.000000\n",
      "(Iteration 86701 / 360000) loss: -0.000000\n",
      "(Iteration 86801 / 360000) loss: -0.000000\n",
      "(Iteration 86901 / 360000) loss: -0.000000\n",
      "(Iteration 87001 / 360000) loss: 6776.882091\n",
      "(Iteration 87101 / 360000) loss: -0.000000\n",
      "(Iteration 87201 / 360000) loss: 197.582836\n",
      "(Iteration 87301 / 360000) loss: -0.000000\n",
      "(Iteration 87401 / 360000) loss: 648.538579\n",
      "(Iteration 87501 / 360000) loss: -0.000000\n",
      "(Iteration 87601 / 360000) loss: -0.000000\n",
      "(Iteration 87701 / 360000) loss: 11332.018136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 87801 / 360000) loss: -0.000000\n",
      "(Iteration 87901 / 360000) loss: -0.000000\n",
      "(Iteration 88001 / 360000) loss: -0.000000\n",
      "(Iteration 88101 / 360000) loss: -0.000000\n",
      "(Iteration 88201 / 360000) loss: 7633.447313\n",
      "(Iteration 88301 / 360000) loss: 2905.394222\n",
      "(Iteration 88401 / 360000) loss: -0.000000\n",
      "(Iteration 88501 / 360000) loss: 1588.926755\n",
      "(Iteration 88601 / 360000) loss: -0.000000\n",
      "(Iteration 88701 / 360000) loss: -0.000000\n",
      "(Iteration 88801 / 360000) loss: 1257.548307\n",
      "(Iteration 88901 / 360000) loss: 12793.835330\n",
      "(Iteration 89001 / 360000) loss: -0.000000\n",
      "(Iteration 89101 / 360000) loss: -0.000000\n",
      "(Iteration 89201 / 360000) loss: -0.000000\n",
      "(Iteration 89301 / 360000) loss: -0.000000\n",
      "(Iteration 89401 / 360000) loss: -0.000000\n",
      "(Iteration 89501 / 360000) loss: -0.000000\n",
      "(Iteration 89601 / 360000) loss: -0.000000\n",
      "(Iteration 89701 / 360000) loss: 10864.297002\n",
      "(Iteration 89801 / 360000) loss: -0.000000\n",
      "(Iteration 89901 / 360000) loss: -0.000000\n",
      "(Epoch 25 / 100) train acc: 0.575000; val_acc: 0.524493\n",
      "(Iteration 90001 / 360000) loss: -0.000000\n",
      "(Iteration 90101 / 360000) loss: -0.000000\n",
      "(Iteration 90201 / 360000) loss: -0.000000\n",
      "(Iteration 90301 / 360000) loss: -0.000000\n",
      "(Iteration 90401 / 360000) loss: 2931.847548\n",
      "(Iteration 90501 / 360000) loss: -0.000000\n",
      "(Iteration 90601 / 360000) loss: 5812.629662\n",
      "(Iteration 90701 / 360000) loss: 4353.186720\n",
      "(Iteration 90801 / 360000) loss: -0.000000\n",
      "(Iteration 90901 / 360000) loss: 9109.204139\n",
      "(Iteration 91001 / 360000) loss: -0.000000\n",
      "(Iteration 91101 / 360000) loss: 8086.025960\n",
      "(Iteration 91201 / 360000) loss: -0.000000\n",
      "(Iteration 91301 / 360000) loss: -0.000000\n",
      "(Iteration 91401 / 360000) loss: -0.000000\n",
      "(Iteration 91501 / 360000) loss: 11773.151720\n",
      "(Iteration 91601 / 360000) loss: -0.000000\n",
      "(Iteration 91701 / 360000) loss: -0.000000\n",
      "(Iteration 91801 / 360000) loss: -0.000000\n",
      "(Iteration 91901 / 360000) loss: 10387.959334\n",
      "(Iteration 92001 / 360000) loss: 5308.924316\n",
      "(Iteration 92101 / 360000) loss: -0.000000\n",
      "(Iteration 92201 / 360000) loss: 5484.185050\n",
      "(Iteration 92301 / 360000) loss: -0.000000\n",
      "(Iteration 92401 / 360000) loss: 1198.533103\n",
      "(Iteration 92501 / 360000) loss: -0.000000\n",
      "(Iteration 92601 / 360000) loss: -0.000000\n",
      "(Iteration 92701 / 360000) loss: 584.831472\n",
      "(Iteration 92801 / 360000) loss: -0.000000\n",
      "(Iteration 92901 / 360000) loss: -0.000000\n",
      "(Iteration 93001 / 360000) loss: -0.000000\n",
      "(Iteration 93101 / 360000) loss: -0.000000\n",
      "(Iteration 93201 / 360000) loss: -0.000000\n",
      "(Iteration 93301 / 360000) loss: -0.000000\n",
      "(Iteration 93401 / 360000) loss: -0.000000\n",
      "(Iteration 93501 / 360000) loss: -0.000000\n",
      "(Epoch 26 / 100) train acc: 0.713000; val_acc: 0.678209\n",
      "(Iteration 93601 / 360000) loss: -0.000000\n",
      "(Iteration 93701 / 360000) loss: -0.000000\n",
      "(Iteration 93801 / 360000) loss: -0.000000\n",
      "(Iteration 93901 / 360000) loss: -0.000000\n",
      "(Iteration 94001 / 360000) loss: -0.000000\n",
      "(Iteration 94101 / 360000) loss: 28.463689\n",
      "(Iteration 94201 / 360000) loss: -0.000000\n",
      "(Iteration 94301 / 360000) loss: -0.000000\n",
      "(Iteration 94401 / 360000) loss: 1782.509312\n",
      "(Iteration 94501 / 360000) loss: -0.000000\n",
      "(Iteration 94601 / 360000) loss: -0.000000\n",
      "(Iteration 94701 / 360000) loss: -0.000000\n",
      "(Iteration 94801 / 360000) loss: 3061.468540\n",
      "(Iteration 94901 / 360000) loss: -0.000000\n",
      "(Iteration 95001 / 360000) loss: -0.000000\n",
      "(Iteration 95101 / 360000) loss: -0.000000\n",
      "(Iteration 95201 / 360000) loss: -0.000000\n",
      "(Iteration 95301 / 360000) loss: 6909.328891\n",
      "(Iteration 95401 / 360000) loss: -0.000000\n",
      "(Iteration 95501 / 360000) loss: -0.000000\n",
      "(Iteration 95601 / 360000) loss: -0.000000\n",
      "(Iteration 95701 / 360000) loss: -0.000000\n",
      "(Iteration 95801 / 360000) loss: 2182.230075\n",
      "(Iteration 95901 / 360000) loss: 389.069743\n",
      "(Iteration 96001 / 360000) loss: -0.000000\n",
      "(Iteration 96101 / 360000) loss: -0.000000\n",
      "(Iteration 96201 / 360000) loss: 4355.282824\n",
      "(Iteration 96301 / 360000) loss: -0.000000\n",
      "(Iteration 96401 / 360000) loss: 4141.418122\n",
      "(Iteration 96501 / 360000) loss: 1806.874127\n",
      "(Iteration 96601 / 360000) loss: -0.000000\n",
      "(Iteration 96701 / 360000) loss: -0.000000\n",
      "(Iteration 96801 / 360000) loss: 15156.877951\n",
      "(Iteration 96901 / 360000) loss: -0.000000\n",
      "(Iteration 97001 / 360000) loss: -0.000000\n",
      "(Iteration 97101 / 360000) loss: -0.000000\n",
      "(Epoch 27 / 100) train acc: 0.719000; val_acc: 0.687500\n",
      "(Iteration 97201 / 360000) loss: -0.000000\n",
      "(Iteration 97301 / 360000) loss: 5200.096763\n",
      "(Iteration 97401 / 360000) loss: -0.000000\n",
      "(Iteration 97501 / 360000) loss: -0.000000\n",
      "(Iteration 97601 / 360000) loss: 3090.972155\n",
      "(Iteration 97701 / 360000) loss: -0.000000\n",
      "(Iteration 97801 / 360000) loss: 618.397976\n",
      "(Iteration 97901 / 360000) loss: -0.000000\n",
      "(Iteration 98001 / 360000) loss: -0.000000\n",
      "(Iteration 98101 / 360000) loss: -0.000000\n",
      "(Iteration 98201 / 360000) loss: 2333.010718\n",
      "(Iteration 98301 / 360000) loss: -0.000000\n",
      "(Iteration 98401 / 360000) loss: -0.000000\n",
      "(Iteration 98501 / 360000) loss: -0.000000\n",
      "(Iteration 98601 / 360000) loss: -0.000000\n",
      "(Iteration 98701 / 360000) loss: -0.000000\n",
      "(Iteration 98801 / 360000) loss: -0.000000\n",
      "(Iteration 98901 / 360000) loss: -0.000000\n",
      "(Iteration 99001 / 360000) loss: -0.000000\n",
      "(Iteration 99101 / 360000) loss: -0.000000\n",
      "(Iteration 99201 / 360000) loss: -0.000000\n",
      "(Iteration 99301 / 360000) loss: -0.000000\n",
      "(Iteration 99401 / 360000) loss: -0.000000\n",
      "(Iteration 99501 / 360000) loss: -0.000000\n",
      "(Iteration 99601 / 360000) loss: -0.000000\n",
      "(Iteration 99701 / 360000) loss: -0.000000\n",
      "(Iteration 99801 / 360000) loss: -0.000000\n",
      "(Iteration 99901 / 360000) loss: 2719.566004\n",
      "(Iteration 100001 / 360000) loss: -0.000000\n",
      "(Iteration 100101 / 360000) loss: 1663.091224\n",
      "(Iteration 100201 / 360000) loss: 2113.511826\n",
      "(Iteration 100301 / 360000) loss: 695.660207\n",
      "(Iteration 100401 / 360000) loss: 5107.369750\n",
      "(Iteration 100501 / 360000) loss: -0.000000\n",
      "(Iteration 100601 / 360000) loss: -0.000000\n",
      "(Iteration 100701 / 360000) loss: 2618.502362\n",
      "(Epoch 28 / 100) train acc: 0.848000; val_acc: 0.811655\n",
      "(Iteration 100801 / 360000) loss: 640.408752\n",
      "(Iteration 100901 / 360000) loss: -0.000000\n",
      "(Iteration 101001 / 360000) loss: -0.000000\n",
      "(Iteration 101101 / 360000) loss: -0.000000\n",
      "(Iteration 101201 / 360000) loss: -0.000000\n",
      "(Iteration 101301 / 360000) loss: -0.000000\n",
      "(Iteration 101401 / 360000) loss: -0.000000\n",
      "(Iteration 101501 / 360000) loss: -0.000000\n",
      "(Iteration 101601 / 360000) loss: -0.000000\n",
      "(Iteration 101701 / 360000) loss: -0.000000\n",
      "(Iteration 101801 / 360000) loss: -0.000000\n",
      "(Iteration 101901 / 360000) loss: -0.000000\n",
      "(Iteration 102001 / 360000) loss: -0.000000\n",
      "(Iteration 102101 / 360000) loss: -0.000000\n",
      "(Iteration 102201 / 360000) loss: 1294.182210\n",
      "(Iteration 102301 / 360000) loss: -0.000000\n",
      "(Iteration 102401 / 360000) loss: -0.000000\n",
      "(Iteration 102501 / 360000) loss: -0.000000\n",
      "(Iteration 102601 / 360000) loss: -0.000000\n",
      "(Iteration 102701 / 360000) loss: -0.000000\n",
      "(Iteration 102801 / 360000) loss: -0.000000\n",
      "(Iteration 102901 / 360000) loss: -0.000000\n",
      "(Iteration 103001 / 360000) loss: 1419.198015\n",
      "(Iteration 103101 / 360000) loss: -0.000000\n",
      "(Iteration 103201 / 360000) loss: -0.000000\n",
      "(Iteration 103301 / 360000) loss: -0.000000\n",
      "(Iteration 103401 / 360000) loss: 0.000000\n",
      "(Iteration 103501 / 360000) loss: -0.000000\n",
      "(Iteration 103601 / 360000) loss: -0.000000\n",
      "(Iteration 103701 / 360000) loss: -0.000000\n",
      "(Iteration 103801 / 360000) loss: -0.000000\n",
      "(Iteration 103901 / 360000) loss: 3001.605466\n",
      "(Iteration 104001 / 360000) loss: -0.000000\n",
      "(Iteration 104101 / 360000) loss: -0.000000\n",
      "(Iteration 104201 / 360000) loss: -0.000000\n",
      "(Iteration 104301 / 360000) loss: 965.072970\n",
      "(Epoch 29 / 100) train acc: 0.781000; val_acc: 0.751689\n",
      "(Iteration 104401 / 360000) loss: -0.000000\n",
      "(Iteration 104501 / 360000) loss: 4551.822617\n",
      "(Iteration 104601 / 360000) loss: -0.000000\n",
      "(Iteration 104701 / 360000) loss: 2228.273114\n",
      "(Iteration 104801 / 360000) loss: -0.000000\n",
      "(Iteration 104901 / 360000) loss: -0.000000\n",
      "(Iteration 105001 / 360000) loss: -0.000000\n",
      "(Iteration 105101 / 360000) loss: -0.000000\n",
      "(Iteration 105201 / 360000) loss: -0.000000\n",
      "(Iteration 105301 / 360000) loss: -0.000000\n",
      "(Iteration 105401 / 360000) loss: -0.000000\n",
      "(Iteration 105501 / 360000) loss: -0.000000\n",
      "(Iteration 105601 / 360000) loss: -0.000000\n",
      "(Iteration 105701 / 360000) loss: -0.000000\n",
      "(Iteration 105801 / 360000) loss: -0.000000\n",
      "(Iteration 105901 / 360000) loss: -0.000000\n",
      "(Iteration 106001 / 360000) loss: -0.000000\n",
      "(Iteration 106101 / 360000) loss: -0.000000\n",
      "(Iteration 106201 / 360000) loss: -0.000000\n",
      "(Iteration 106301 / 360000) loss: -0.000000\n",
      "(Iteration 106401 / 360000) loss: -0.000000\n",
      "(Iteration 106501 / 360000) loss: -0.000000\n",
      "(Iteration 106601 / 360000) loss: -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 106701 / 360000) loss: 243.794931\n",
      "(Iteration 106801 / 360000) loss: -0.000000\n",
      "(Iteration 106901 / 360000) loss: -0.000000\n",
      "(Iteration 107001 / 360000) loss: -0.000000\n",
      "(Iteration 107101 / 360000) loss: -0.000000\n",
      "(Iteration 107201 / 360000) loss: -0.000000\n",
      "(Iteration 107301 / 360000) loss: -0.000000\n",
      "(Iteration 107401 / 360000) loss: -0.000000\n",
      "(Iteration 107501 / 360000) loss: -0.000000\n",
      "(Iteration 107601 / 360000) loss: -0.000000\n",
      "(Iteration 107701 / 360000) loss: 3201.681406\n",
      "(Iteration 107801 / 360000) loss: -0.000000\n",
      "(Iteration 107901 / 360000) loss: -0.000000\n",
      "(Epoch 30 / 100) train acc: 0.868000; val_acc: 0.856419\n",
      "(Iteration 108001 / 360000) loss: -0.000000\n",
      "(Iteration 108101 / 360000) loss: -0.000000\n",
      "(Iteration 108201 / 360000) loss: -0.000000\n",
      "(Iteration 108301 / 360000) loss: -0.000000\n",
      "(Iteration 108401 / 360000) loss: -0.000000\n",
      "(Iteration 108501 / 360000) loss: -0.000000\n",
      "(Iteration 108601 / 360000) loss: -0.000000\n",
      "(Iteration 108701 / 360000) loss: -0.000000\n",
      "(Iteration 108801 / 360000) loss: -0.000000\n",
      "(Iteration 108901 / 360000) loss: -0.000000\n",
      "(Iteration 109001 / 360000) loss: -0.000000\n",
      "(Iteration 109101 / 360000) loss: -0.000000\n",
      "(Iteration 109201 / 360000) loss: -0.000000\n",
      "(Iteration 109301 / 360000) loss: -0.000000\n",
      "(Iteration 109401 / 360000) loss: -0.000000\n",
      "(Iteration 109501 / 360000) loss: -0.000000\n",
      "(Iteration 109601 / 360000) loss: -0.000000\n",
      "(Iteration 109701 / 360000) loss: -0.000000\n",
      "(Iteration 109801 / 360000) loss: -0.000000\n",
      "(Iteration 109901 / 360000) loss: -0.000000\n",
      "(Iteration 110001 / 360000) loss: -0.000000\n",
      "(Iteration 110101 / 360000) loss: -0.000000\n",
      "(Iteration 110201 / 360000) loss: -0.000000\n",
      "(Iteration 110301 / 360000) loss: -0.000000\n",
      "(Iteration 110401 / 360000) loss: 2233.708552\n",
      "(Iteration 110501 / 360000) loss: -0.000000\n",
      "(Iteration 110601 / 360000) loss: -0.000000\n",
      "(Iteration 110701 / 360000) loss: -0.000000\n",
      "(Iteration 110801 / 360000) loss: -0.000000\n",
      "(Iteration 110901 / 360000) loss: -0.000000\n",
      "(Iteration 111001 / 360000) loss: -0.000000\n",
      "(Iteration 111101 / 360000) loss: -0.000000\n",
      "(Iteration 111201 / 360000) loss: -0.000000\n",
      "(Iteration 111301 / 360000) loss: -0.000000\n",
      "(Iteration 111401 / 360000) loss: -0.000000\n",
      "(Iteration 111501 / 360000) loss: 314.499890\n",
      "(Epoch 31 / 100) train acc: 0.887000; val_acc: 0.835304\n",
      "(Iteration 111601 / 360000) loss: -0.000000\n",
      "(Iteration 111701 / 360000) loss: 250.239053\n",
      "(Iteration 111801 / 360000) loss: -0.000000\n",
      "(Iteration 111901 / 360000) loss: -0.000000\n",
      "(Iteration 112001 / 360000) loss: -0.000000\n",
      "(Iteration 112101 / 360000) loss: 889.724893\n",
      "(Iteration 112201 / 360000) loss: -0.000000\n",
      "(Iteration 112301 / 360000) loss: -0.000000\n",
      "(Iteration 112401 / 360000) loss: -0.000000\n",
      "(Iteration 112501 / 360000) loss: -0.000000\n",
      "(Iteration 112601 / 360000) loss: -0.000000\n",
      "(Iteration 112701 / 360000) loss: -0.000000\n",
      "(Iteration 112801 / 360000) loss: -0.000000\n",
      "(Iteration 112901 / 360000) loss: -0.000000\n",
      "(Iteration 113001 / 360000) loss: -0.000000\n",
      "(Iteration 113101 / 360000) loss: 3026.264454\n",
      "(Iteration 113201 / 360000) loss: -0.000000\n",
      "(Iteration 113301 / 360000) loss: -0.000000\n",
      "(Iteration 113401 / 360000) loss: -0.000000\n",
      "(Iteration 113501 / 360000) loss: -0.000000\n",
      "(Iteration 113601 / 360000) loss: -0.000000\n",
      "(Iteration 113701 / 360000) loss: -0.000000\n",
      "(Iteration 113801 / 360000) loss: -0.000000\n",
      "(Iteration 113901 / 360000) loss: -0.000000\n",
      "(Iteration 114001 / 360000) loss: -0.000000\n",
      "(Iteration 114101 / 360000) loss: -0.000000\n",
      "(Iteration 114201 / 360000) loss: -0.000000\n",
      "(Iteration 114301 / 360000) loss: -0.000000\n",
      "(Iteration 114401 / 360000) loss: 431.131842\n",
      "(Iteration 114501 / 360000) loss: -0.000000\n",
      "(Iteration 114601 / 360000) loss: 818.109764\n",
      "(Iteration 114701 / 360000) loss: -0.000000\n",
      "(Iteration 114801 / 360000) loss: -0.000000\n",
      "(Iteration 114901 / 360000) loss: -0.000000\n",
      "(Iteration 115001 / 360000) loss: -0.000000\n",
      "(Iteration 115101 / 360000) loss: 698.763375\n",
      "(Epoch 32 / 100) train acc: 0.888000; val_acc: 0.872466\n",
      "(Iteration 115201 / 360000) loss: -0.000000\n",
      "(Iteration 115301 / 360000) loss: -0.000000\n",
      "(Iteration 115401 / 360000) loss: -0.000000\n",
      "(Iteration 115501 / 360000) loss: -0.000000\n",
      "(Iteration 115601 / 360000) loss: -0.000000\n",
      "(Iteration 115701 / 360000) loss: -0.000000\n",
      "(Iteration 115801 / 360000) loss: -0.000000\n",
      "(Iteration 115901 / 360000) loss: -0.000000\n",
      "(Iteration 116001 / 360000) loss: -0.000000\n",
      "(Iteration 116101 / 360000) loss: -0.000000\n",
      "(Iteration 116201 / 360000) loss: 0.000070\n",
      "(Iteration 116301 / 360000) loss: -0.000000\n",
      "(Iteration 116401 / 360000) loss: -0.000000\n",
      "(Iteration 116501 / 360000) loss: -0.000000\n",
      "(Iteration 116601 / 360000) loss: -0.000000\n",
      "(Iteration 116701 / 360000) loss: -0.000000\n",
      "(Iteration 116801 / 360000) loss: -0.000000\n",
      "(Iteration 116901 / 360000) loss: 5284.990167\n",
      "(Iteration 117001 / 360000) loss: -0.000000\n",
      "(Iteration 117101 / 360000) loss: -0.000000\n",
      "(Iteration 117201 / 360000) loss: -0.000000\n",
      "(Iteration 117301 / 360000) loss: -0.000000\n",
      "(Iteration 117401 / 360000) loss: -0.000000\n",
      "(Iteration 117501 / 360000) loss: 1857.553765\n",
      "(Iteration 117601 / 360000) loss: -0.000000\n",
      "(Iteration 117701 / 360000) loss: -0.000000\n",
      "(Iteration 117801 / 360000) loss: -0.000000\n",
      "(Iteration 117901 / 360000) loss: -0.000000\n",
      "(Iteration 118001 / 360000) loss: -0.000000\n",
      "(Iteration 118101 / 360000) loss: 120.856037\n",
      "(Iteration 118201 / 360000) loss: -0.000000\n",
      "(Iteration 118301 / 360000) loss: -0.000000\n",
      "(Iteration 118401 / 360000) loss: -0.000000\n",
      "(Iteration 118501 / 360000) loss: 409.448529\n",
      "(Iteration 118601 / 360000) loss: -0.000000\n",
      "(Iteration 118701 / 360000) loss: -0.000000\n",
      "(Epoch 33 / 100) train acc: 0.919000; val_acc: 0.874155\n",
      "(Iteration 118801 / 360000) loss: -0.000000\n",
      "(Iteration 118901 / 360000) loss: -0.000000\n",
      "(Iteration 119001 / 360000) loss: 0.000000\n",
      "(Iteration 119101 / 360000) loss: -0.000000\n",
      "(Iteration 119201 / 360000) loss: 644.130786\n",
      "(Iteration 119301 / 360000) loss: 1334.779023\n",
      "(Iteration 119401 / 360000) loss: -0.000000\n",
      "(Iteration 119501 / 360000) loss: -0.000000\n",
      "(Iteration 119601 / 360000) loss: -0.000000\n",
      "(Iteration 119701 / 360000) loss: -0.000000\n",
      "(Iteration 119801 / 360000) loss: -0.000000\n",
      "(Iteration 119901 / 360000) loss: -0.000000\n",
      "(Iteration 120001 / 360000) loss: 593.727468\n",
      "(Iteration 120101 / 360000) loss: -0.000000\n",
      "(Iteration 120201 / 360000) loss: -0.000000\n",
      "(Iteration 120301 / 360000) loss: -0.000000\n",
      "(Iteration 120401 / 360000) loss: -0.000000\n",
      "(Iteration 120501 / 360000) loss: 213.260478\n",
      "(Iteration 120601 / 360000) loss: -0.000000\n",
      "(Iteration 120701 / 360000) loss: -0.000000\n",
      "(Iteration 120801 / 360000) loss: -0.000000\n",
      "(Iteration 120901 / 360000) loss: -0.000000\n",
      "(Iteration 121001 / 360000) loss: 5197.953977\n",
      "(Iteration 121101 / 360000) loss: 572.142588\n",
      "(Iteration 121201 / 360000) loss: -0.000000\n",
      "(Iteration 121301 / 360000) loss: -0.000000\n",
      "(Iteration 121401 / 360000) loss: -0.000000\n",
      "(Iteration 121501 / 360000) loss: 217.715986\n",
      "(Iteration 121601 / 360000) loss: -0.000000\n",
      "(Iteration 121701 / 360000) loss: -0.000000\n",
      "(Iteration 121801 / 360000) loss: -0.000000\n",
      "(Iteration 121901 / 360000) loss: -0.000000\n",
      "(Iteration 122001 / 360000) loss: -0.000000\n",
      "(Iteration 122101 / 360000) loss: -0.000000\n",
      "(Iteration 122201 / 360000) loss: 305.722270\n",
      "(Iteration 122301 / 360000) loss: -0.000000\n",
      "(Epoch 34 / 100) train acc: 0.917000; val_acc: 0.875000\n",
      "(Iteration 122401 / 360000) loss: -0.000000\n",
      "(Iteration 122501 / 360000) loss: -0.000000\n",
      "(Iteration 122601 / 360000) loss: -0.000000\n",
      "(Iteration 122701 / 360000) loss: -0.000000\n",
      "(Iteration 122801 / 360000) loss: -0.000000\n",
      "(Iteration 122901 / 360000) loss: 2151.497730\n",
      "(Iteration 123001 / 360000) loss: -0.000000\n",
      "(Iteration 123101 / 360000) loss: -0.000000\n",
      "(Iteration 123201 / 360000) loss: -0.000000\n",
      "(Iteration 123301 / 360000) loss: -0.000000\n",
      "(Iteration 123401 / 360000) loss: -0.000000\n",
      "(Iteration 123501 / 360000) loss: -0.000000\n",
      "(Iteration 123601 / 360000) loss: 1628.844723\n",
      "(Iteration 123701 / 360000) loss: 4010.366510\n",
      "(Iteration 123801 / 360000) loss: -0.000000\n",
      "(Iteration 123901 / 360000) loss: -0.000000\n",
      "(Iteration 124001 / 360000) loss: -0.000000\n",
      "(Iteration 124101 / 360000) loss: -0.000000\n",
      "(Iteration 124201 / 360000) loss: -0.000000\n",
      "(Iteration 124301 / 360000) loss: -0.000000\n",
      "(Iteration 124401 / 360000) loss: -0.000000\n",
      "(Iteration 124501 / 360000) loss: -0.000000\n",
      "(Iteration 124601 / 360000) loss: -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 124701 / 360000) loss: -0.000000\n",
      "(Iteration 124801 / 360000) loss: -0.000000\n",
      "(Iteration 124901 / 360000) loss: -0.000000\n",
      "(Iteration 125001 / 360000) loss: -0.000000\n",
      "(Iteration 125101 / 360000) loss: -0.000000\n",
      "(Iteration 125201 / 360000) loss: -0.000000\n",
      "(Iteration 125301 / 360000) loss: -0.000000\n",
      "(Iteration 125401 / 360000) loss: -0.000000\n",
      "(Iteration 125501 / 360000) loss: -0.000000\n",
      "(Iteration 125601 / 360000) loss: -0.000000\n",
      "(Iteration 125701 / 360000) loss: -0.000000\n",
      "(Iteration 125801 / 360000) loss: -0.000000\n",
      "(Iteration 125901 / 360000) loss: -0.000000\n",
      "(Epoch 35 / 100) train acc: 0.867000; val_acc: 0.816723\n",
      "(Iteration 126001 / 360000) loss: -0.000000\n",
      "(Iteration 126101 / 360000) loss: -0.000000\n",
      "(Iteration 126201 / 360000) loss: -0.000000\n",
      "(Iteration 126301 / 360000) loss: -0.000000\n",
      "(Iteration 126401 / 360000) loss: -0.000000\n",
      "(Iteration 126501 / 360000) loss: -0.000000\n",
      "(Iteration 126601 / 360000) loss: -0.000000\n",
      "(Iteration 126701 / 360000) loss: -0.000000\n",
      "(Iteration 126801 / 360000) loss: -0.000000\n",
      "(Iteration 126901 / 360000) loss: -0.000000\n",
      "(Iteration 127001 / 360000) loss: -0.000000\n",
      "(Iteration 127101 / 360000) loss: -0.000000\n",
      "(Iteration 127201 / 360000) loss: -0.000000\n",
      "(Iteration 127301 / 360000) loss: -0.000000\n",
      "(Iteration 127401 / 360000) loss: -0.000000\n",
      "(Iteration 127501 / 360000) loss: -0.000000\n",
      "(Iteration 127601 / 360000) loss: 142.041842\n",
      "(Iteration 127701 / 360000) loss: -0.000000\n",
      "(Iteration 127801 / 360000) loss: -0.000000\n",
      "(Iteration 127901 / 360000) loss: -0.000000\n",
      "(Iteration 128001 / 360000) loss: -0.000000\n",
      "(Iteration 128101 / 360000) loss: -0.000000\n",
      "(Iteration 128201 / 360000) loss: -0.000000\n",
      "(Iteration 128301 / 360000) loss: -0.000000\n",
      "(Iteration 128401 / 360000) loss: -0.000000\n",
      "(Iteration 128501 / 360000) loss: -0.000000\n",
      "(Iteration 128601 / 360000) loss: -0.000000\n",
      "(Iteration 128701 / 360000) loss: -0.000000\n",
      "(Iteration 128801 / 360000) loss: -0.000000\n",
      "(Iteration 128901 / 360000) loss: -0.000000\n",
      "(Iteration 129001 / 360000) loss: -0.000000\n",
      "(Iteration 129101 / 360000) loss: -0.000000\n",
      "(Iteration 129201 / 360000) loss: -0.000000\n",
      "(Iteration 129301 / 360000) loss: -0.000000\n",
      "(Iteration 129401 / 360000) loss: -0.000000\n",
      "(Iteration 129501 / 360000) loss: -0.000000\n",
      "(Epoch 36 / 100) train acc: 0.912000; val_acc: 0.856419\n",
      "(Iteration 129601 / 360000) loss: -0.000000\n",
      "(Iteration 129701 / 360000) loss: -0.000000\n",
      "(Iteration 129801 / 360000) loss: -0.000000\n",
      "(Iteration 129901 / 360000) loss: -0.000000\n",
      "(Iteration 130001 / 360000) loss: -0.000000\n",
      "(Iteration 130101 / 360000) loss: 9.988532\n",
      "(Iteration 130201 / 360000) loss: -0.000000\n",
      "(Iteration 130301 / 360000) loss: -0.000000\n",
      "(Iteration 130401 / 360000) loss: -0.000000\n",
      "(Iteration 130501 / 360000) loss: -0.000000\n",
      "(Iteration 130601 / 360000) loss: -0.000000\n",
      "(Iteration 130701 / 360000) loss: -0.000000\n",
      "(Iteration 130801 / 360000) loss: -0.000000\n",
      "(Iteration 130901 / 360000) loss: -0.000000\n",
      "(Iteration 131001 / 360000) loss: -0.000000\n",
      "(Iteration 131101 / 360000) loss: -0.000000\n",
      "(Iteration 131201 / 360000) loss: -0.000000\n",
      "(Iteration 131301 / 360000) loss: -0.000000\n",
      "(Iteration 131401 / 360000) loss: -0.000000\n",
      "(Iteration 131501 / 360000) loss: -0.000000\n",
      "(Iteration 131601 / 360000) loss: -0.000000\n",
      "(Iteration 131701 / 360000) loss: -0.000000\n",
      "(Iteration 131801 / 360000) loss: -0.000000\n",
      "(Iteration 131901 / 360000) loss: -0.000000\n",
      "(Iteration 132001 / 360000) loss: -0.000000\n",
      "(Iteration 132101 / 360000) loss: -0.000000\n",
      "(Iteration 132201 / 360000) loss: -0.000000\n",
      "(Iteration 132301 / 360000) loss: -0.000000\n",
      "(Iteration 132401 / 360000) loss: -0.000000\n",
      "(Iteration 132501 / 360000) loss: -0.000000\n",
      "(Iteration 132601 / 360000) loss: -0.000000\n",
      "(Iteration 132701 / 360000) loss: -0.000000\n",
      "(Iteration 132801 / 360000) loss: -0.000000\n",
      "(Iteration 132901 / 360000) loss: -0.000000\n",
      "(Iteration 133001 / 360000) loss: -0.000000\n",
      "(Iteration 133101 / 360000) loss: -0.000000\n",
      "(Epoch 37 / 100) train acc: 0.923000; val_acc: 0.889358\n",
      "(Iteration 133201 / 360000) loss: -0.000000\n",
      "(Iteration 133301 / 360000) loss: -0.000000\n",
      "(Iteration 133401 / 360000) loss: -0.000000\n",
      "(Iteration 133501 / 360000) loss: -0.000000\n",
      "(Iteration 133601 / 360000) loss: -0.000000\n",
      "(Iteration 133701 / 360000) loss: -0.000000\n",
      "(Iteration 133801 / 360000) loss: -0.000000\n",
      "(Iteration 133901 / 360000) loss: -0.000000\n",
      "(Iteration 134001 / 360000) loss: -0.000000\n",
      "(Iteration 134101 / 360000) loss: -0.000000\n",
      "(Iteration 134201 / 360000) loss: -0.000000\n",
      "(Iteration 134301 / 360000) loss: 134.180960\n",
      "(Iteration 134401 / 360000) loss: 259.682290\n",
      "(Iteration 134501 / 360000) loss: -0.000000\n",
      "(Iteration 134601 / 360000) loss: -0.000000\n",
      "(Iteration 134701 / 360000) loss: -0.000000\n",
      "(Iteration 134801 / 360000) loss: -0.000000\n",
      "(Iteration 134901 / 360000) loss: -0.000000\n",
      "(Iteration 135001 / 360000) loss: -0.000000\n",
      "(Iteration 135101 / 360000) loss: -0.000000\n",
      "(Iteration 135201 / 360000) loss: -0.000000\n",
      "(Iteration 135301 / 360000) loss: -0.000000\n",
      "(Iteration 135401 / 360000) loss: -0.000000\n",
      "(Iteration 135501 / 360000) loss: -0.000000\n",
      "(Iteration 135601 / 360000) loss: -0.000000\n",
      "(Iteration 135701 / 360000) loss: -0.000000\n",
      "(Iteration 135801 / 360000) loss: -0.000000\n",
      "(Iteration 135901 / 360000) loss: -0.000000\n",
      "(Iteration 136001 / 360000) loss: -0.000000\n",
      "(Iteration 136101 / 360000) loss: -0.000000\n",
      "(Iteration 136201 / 360000) loss: -0.000000\n",
      "(Iteration 136301 / 360000) loss: -0.000000\n",
      "(Iteration 136401 / 360000) loss: 655.478467\n",
      "(Iteration 136501 / 360000) loss: -0.000000\n",
      "(Iteration 136601 / 360000) loss: -0.000000\n",
      "(Iteration 136701 / 360000) loss: -0.000000\n",
      "(Epoch 38 / 100) train acc: 0.932000; val_acc: 0.875845\n",
      "(Iteration 136801 / 360000) loss: -0.000000\n",
      "(Iteration 136901 / 360000) loss: -0.000000\n",
      "(Iteration 137001 / 360000) loss: -0.000000\n",
      "(Iteration 137101 / 360000) loss: -0.000000\n",
      "(Iteration 137201 / 360000) loss: -0.000000\n",
      "(Iteration 137301 / 360000) loss: -0.000000\n",
      "(Iteration 137401 / 360000) loss: -0.000000\n",
      "(Iteration 137501 / 360000) loss: -0.000000\n",
      "(Iteration 137601 / 360000) loss: -0.000000\n",
      "(Iteration 137701 / 360000) loss: -0.000000\n",
      "(Iteration 137801 / 360000) loss: -0.000000\n",
      "(Iteration 137901 / 360000) loss: -0.000000\n",
      "(Iteration 138001 / 360000) loss: -0.000000\n",
      "(Iteration 138101 / 360000) loss: -0.000000\n",
      "(Iteration 138201 / 360000) loss: -0.000000\n",
      "(Iteration 138301 / 360000) loss: -0.000000\n",
      "(Iteration 138401 / 360000) loss: -0.000000\n",
      "(Iteration 138501 / 360000) loss: -0.000000\n",
      "(Iteration 138601 / 360000) loss: -0.000000\n",
      "(Iteration 138701 / 360000) loss: -0.000000\n",
      "(Iteration 138801 / 360000) loss: 1027.141760\n",
      "(Iteration 138901 / 360000) loss: -0.000000\n",
      "(Iteration 139001 / 360000) loss: -0.000000\n",
      "(Iteration 139101 / 360000) loss: 784.171252\n",
      "(Iteration 139201 / 360000) loss: -0.000000\n",
      "(Iteration 139301 / 360000) loss: -0.000000\n",
      "(Iteration 139401 / 360000) loss: -0.000000\n",
      "(Iteration 139501 / 360000) loss: -0.000000\n",
      "(Iteration 139601 / 360000) loss: -0.000000\n",
      "(Iteration 139701 / 360000) loss: -0.000000\n",
      "(Iteration 139801 / 360000) loss: -0.000000\n",
      "(Iteration 139901 / 360000) loss: -0.000000\n",
      "(Iteration 140001 / 360000) loss: -0.000000\n",
      "(Iteration 140101 / 360000) loss: -0.000000\n",
      "(Iteration 140201 / 360000) loss: 762.890255\n",
      "(Iteration 140301 / 360000) loss: -0.000000\n",
      "(Epoch 39 / 100) train acc: 0.907000; val_acc: 0.885135\n",
      "(Iteration 140401 / 360000) loss: -0.000000\n",
      "(Iteration 140501 / 360000) loss: -0.000000\n",
      "(Iteration 140601 / 360000) loss: -0.000000\n",
      "(Iteration 140701 / 360000) loss: 152.097629\n",
      "(Iteration 140801 / 360000) loss: -0.000000\n",
      "(Iteration 140901 / 360000) loss: -0.000000\n",
      "(Iteration 141001 / 360000) loss: 7.614051\n",
      "(Iteration 141101 / 360000) loss: -0.000000\n",
      "(Iteration 141201 / 360000) loss: -0.000000\n",
      "(Iteration 141301 / 360000) loss: -0.000000\n",
      "(Iteration 141401 / 360000) loss: -0.000000\n",
      "(Iteration 141501 / 360000) loss: -0.000000\n",
      "(Iteration 141601 / 360000) loss: -0.000000\n",
      "(Iteration 141701 / 360000) loss: -0.000000\n",
      "(Iteration 141801 / 360000) loss: -0.000000\n",
      "(Iteration 141901 / 360000) loss: 77.084626\n",
      "(Iteration 142001 / 360000) loss: 1552.293585\n",
      "(Iteration 142101 / 360000) loss: -0.000000\n",
      "(Iteration 142201 / 360000) loss: 5152.646209\n",
      "(Iteration 142301 / 360000) loss: -0.000000\n",
      "(Iteration 142401 / 360000) loss: 941.436824\n",
      "(Iteration 142501 / 360000) loss: -0.000000\n",
      "(Iteration 142601 / 360000) loss: -0.000000\n",
      "(Iteration 142701 / 360000) loss: -0.000000\n",
      "(Iteration 142801 / 360000) loss: -0.000000\n",
      "(Iteration 142901 / 360000) loss: -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 143001 / 360000) loss: -0.000000\n",
      "(Iteration 143101 / 360000) loss: -0.000000\n",
      "(Iteration 143201 / 360000) loss: 2499.405122\n",
      "(Iteration 143301 / 360000) loss: -0.000000\n",
      "(Iteration 143401 / 360000) loss: -0.000000\n",
      "(Iteration 143501 / 360000) loss: -0.000000\n",
      "(Iteration 143601 / 360000) loss: -0.000000\n",
      "(Iteration 143701 / 360000) loss: 1748.097571\n",
      "(Iteration 143801 / 360000) loss: -0.000000\n",
      "(Iteration 143901 / 360000) loss: -0.000000\n",
      "(Epoch 40 / 100) train acc: 0.927000; val_acc: 0.870777\n",
      "(Iteration 144001 / 360000) loss: -0.000000\n",
      "(Iteration 144101 / 360000) loss: -0.000000\n",
      "(Iteration 144201 / 360000) loss: -0.000000\n",
      "(Iteration 144301 / 360000) loss: -0.000000\n",
      "(Iteration 144401 / 360000) loss: 1157.870380\n",
      "(Iteration 144501 / 360000) loss: -0.000000\n",
      "(Iteration 144601 / 360000) loss: -0.000000\n",
      "(Iteration 144701 / 360000) loss: -0.000000\n",
      "(Iteration 144801 / 360000) loss: -0.000000\n",
      "(Iteration 144901 / 360000) loss: -0.000000\n",
      "(Iteration 145001 / 360000) loss: -0.000000\n",
      "(Iteration 145101 / 360000) loss: 2143.697990\n",
      "(Iteration 145201 / 360000) loss: 1129.779650\n",
      "(Iteration 145301 / 360000) loss: -0.000000\n",
      "(Iteration 145401 / 360000) loss: -0.000000\n",
      "(Iteration 145501 / 360000) loss: -0.000000\n",
      "(Iteration 145601 / 360000) loss: -0.000000\n",
      "(Iteration 145701 / 360000) loss: 368.894967\n",
      "(Iteration 145801 / 360000) loss: -0.000000\n",
      "(Iteration 145901 / 360000) loss: -0.000000\n",
      "(Iteration 146001 / 360000) loss: -0.000000\n",
      "(Iteration 146101 / 360000) loss: -0.000000\n",
      "(Iteration 146201 / 360000) loss: -0.000000\n",
      "(Iteration 146301 / 360000) loss: -0.000000\n",
      "(Iteration 146401 / 360000) loss: -0.000000\n",
      "(Iteration 146501 / 360000) loss: -0.000000\n",
      "(Iteration 146601 / 360000) loss: -0.000000\n",
      "(Iteration 146701 / 360000) loss: -0.000000\n",
      "(Iteration 146801 / 360000) loss: -0.000000\n",
      "(Iteration 146901 / 360000) loss: -0.000000\n",
      "(Iteration 147001 / 360000) loss: -0.000000\n",
      "(Iteration 147101 / 360000) loss: -0.000000\n",
      "(Iteration 147201 / 360000) loss: 381.335185\n",
      "(Iteration 147301 / 360000) loss: -0.000000\n",
      "(Iteration 147401 / 360000) loss: -0.000000\n",
      "(Iteration 147501 / 360000) loss: 291.188531\n",
      "(Epoch 41 / 100) train acc: 0.911000; val_acc: 0.879223\n",
      "(Iteration 147601 / 360000) loss: -0.000000\n",
      "(Iteration 147701 / 360000) loss: -0.000000\n",
      "(Iteration 147801 / 360000) loss: -0.000000\n",
      "(Iteration 147901 / 360000) loss: -0.000000\n",
      "(Iteration 148001 / 360000) loss: -0.000000\n",
      "(Iteration 148101 / 360000) loss: 314.141822\n",
      "(Iteration 148201 / 360000) loss: 204.206707\n",
      "(Iteration 148301 / 360000) loss: -0.000000\n",
      "(Iteration 148401 / 360000) loss: -0.000000\n",
      "(Iteration 148501 / 360000) loss: -0.000000\n",
      "(Iteration 148601 / 360000) loss: -0.000000\n",
      "(Iteration 148701 / 360000) loss: -0.000000\n",
      "(Iteration 148801 / 360000) loss: -0.000000\n",
      "(Iteration 148901 / 360000) loss: -0.000000\n",
      "(Iteration 149001 / 360000) loss: -0.000000\n",
      "(Iteration 149101 / 360000) loss: -0.000000\n",
      "(Iteration 149201 / 360000) loss: -0.000000\n",
      "(Iteration 149301 / 360000) loss: -0.000000\n",
      "(Iteration 149401 / 360000) loss: -0.000000\n",
      "(Iteration 149501 / 360000) loss: -0.000000\n",
      "(Iteration 149601 / 360000) loss: -0.000000\n",
      "(Iteration 149701 / 360000) loss: -0.000000\n",
      "(Iteration 149801 / 360000) loss: 253.309385\n",
      "(Iteration 149901 / 360000) loss: 860.099280\n",
      "(Iteration 150001 / 360000) loss: -0.000000\n",
      "(Iteration 150101 / 360000) loss: -0.000000\n",
      "(Iteration 150201 / 360000) loss: -0.000000\n",
      "(Iteration 150301 / 360000) loss: -0.000000\n",
      "(Iteration 150401 / 360000) loss: -0.000000\n",
      "(Iteration 150501 / 360000) loss: -0.000000\n",
      "(Iteration 150601 / 360000) loss: -0.000000\n",
      "(Iteration 150701 / 360000) loss: -0.000000\n",
      "(Iteration 150801 / 360000) loss: -0.000000\n",
      "(Iteration 150901 / 360000) loss: -0.000000\n",
      "(Iteration 151001 / 360000) loss: 3607.891838\n",
      "(Iteration 151101 / 360000) loss: -0.000000\n",
      "(Epoch 42 / 100) train acc: 0.927000; val_acc: 0.885980\n",
      "(Iteration 151201 / 360000) loss: -0.000000\n",
      "(Iteration 151301 / 360000) loss: -0.000000\n",
      "(Iteration 151401 / 360000) loss: -0.000000\n",
      "(Iteration 151501 / 360000) loss: -0.000000\n",
      "(Iteration 151601 / 360000) loss: -0.000000\n",
      "(Iteration 151701 / 360000) loss: -0.000000\n",
      "(Iteration 151801 / 360000) loss: -0.000000\n",
      "(Iteration 151901 / 360000) loss: -0.000000\n",
      "(Iteration 152001 / 360000) loss: -0.000000\n",
      "(Iteration 152101 / 360000) loss: -0.000000\n",
      "(Iteration 152201 / 360000) loss: -0.000000\n",
      "(Iteration 152301 / 360000) loss: -0.000000\n",
      "(Iteration 152401 / 360000) loss: 345.591892\n",
      "(Iteration 152501 / 360000) loss: 2276.107705\n",
      "(Iteration 152601 / 360000) loss: -0.000000\n",
      "(Iteration 152701 / 360000) loss: -0.000000\n",
      "(Iteration 152801 / 360000) loss: -0.000000\n",
      "(Iteration 152901 / 360000) loss: -0.000000\n",
      "(Iteration 153001 / 360000) loss: -0.000000\n",
      "(Iteration 153101 / 360000) loss: -0.000000\n",
      "(Iteration 153201 / 360000) loss: -0.000000\n",
      "(Iteration 153301 / 360000) loss: 328.970520\n",
      "(Iteration 153401 / 360000) loss: -0.000000\n",
      "(Iteration 153501 / 360000) loss: -0.000000\n",
      "(Iteration 153601 / 360000) loss: -0.000000\n",
      "(Iteration 153701 / 360000) loss: -0.000000\n",
      "(Iteration 153801 / 360000) loss: -0.000000\n",
      "(Iteration 153901 / 360000) loss: -0.000000\n",
      "(Iteration 154001 / 360000) loss: -0.000000\n",
      "(Iteration 154101 / 360000) loss: -0.000000\n",
      "(Iteration 154201 / 360000) loss: -0.000000\n",
      "(Iteration 154301 / 360000) loss: -0.000000\n",
      "(Iteration 154401 / 360000) loss: -0.000000\n",
      "(Iteration 154501 / 360000) loss: -0.000000\n",
      "(Iteration 154601 / 360000) loss: -0.000000\n",
      "(Iteration 154701 / 360000) loss: -0.000000\n",
      "(Epoch 43 / 100) train acc: 0.928000; val_acc: 0.884291\n",
      "(Iteration 154801 / 360000) loss: -0.000000\n",
      "(Iteration 154901 / 360000) loss: -0.000000\n",
      "(Iteration 155001 / 360000) loss: -0.000000\n",
      "(Iteration 155101 / 360000) loss: -0.000000\n",
      "(Iteration 155201 / 360000) loss: -0.000000\n",
      "(Iteration 155301 / 360000) loss: -0.000000\n",
      "(Iteration 155401 / 360000) loss: -0.000000\n",
      "(Iteration 155501 / 360000) loss: -0.000000\n",
      "(Iteration 155601 / 360000) loss: -0.000000\n",
      "(Iteration 155701 / 360000) loss: -0.000000\n",
      "(Iteration 155801 / 360000) loss: -0.000000\n",
      "(Iteration 155901 / 360000) loss: -0.000000\n",
      "(Iteration 156001 / 360000) loss: -0.000000\n",
      "(Iteration 156101 / 360000) loss: -0.000000\n",
      "(Iteration 156201 / 360000) loss: -0.000000\n",
      "(Iteration 156301 / 360000) loss: -0.000000\n",
      "(Iteration 156401 / 360000) loss: -0.000000\n",
      "(Iteration 156501 / 360000) loss: 1060.118069\n",
      "(Iteration 156601 / 360000) loss: -0.000000\n",
      "(Iteration 156701 / 360000) loss: -0.000000\n",
      "(Iteration 156801 / 360000) loss: -0.000000\n",
      "(Iteration 156901 / 360000) loss: -0.000000\n",
      "(Iteration 157001 / 360000) loss: -0.000000\n",
      "(Iteration 157101 / 360000) loss: 808.968329\n",
      "(Iteration 157201 / 360000) loss: -0.000000\n",
      "(Iteration 157301 / 360000) loss: -0.000000\n",
      "(Iteration 157401 / 360000) loss: -0.000000\n",
      "(Iteration 157501 / 360000) loss: -0.000000\n",
      "(Iteration 157601 / 360000) loss: -0.000000\n",
      "(Iteration 157701 / 360000) loss: -0.000000\n",
      "(Iteration 157801 / 360000) loss: -0.000000\n",
      "(Iteration 157901 / 360000) loss: -0.000000\n",
      "(Iteration 158001 / 360000) loss: -0.000000\n",
      "(Iteration 158101 / 360000) loss: -0.000000\n",
      "(Iteration 158201 / 360000) loss: -0.000000\n",
      "(Iteration 158301 / 360000) loss: -0.000000\n",
      "(Epoch 44 / 100) train acc: 0.917000; val_acc: 0.886824\n",
      "(Iteration 158401 / 360000) loss: -0.000000\n",
      "(Iteration 158501 / 360000) loss: -0.000000\n",
      "(Iteration 158601 / 360000) loss: -0.000000\n",
      "(Iteration 158701 / 360000) loss: 77.953027\n",
      "(Iteration 158801 / 360000) loss: -0.000000\n",
      "(Iteration 158901 / 360000) loss: -0.000000\n",
      "(Iteration 159001 / 360000) loss: -0.000000\n",
      "(Iteration 159101 / 360000) loss: -0.000000\n",
      "(Iteration 159201 / 360000) loss: 266.384110\n",
      "(Iteration 159301 / 360000) loss: -0.000000\n",
      "(Iteration 159401 / 360000) loss: -0.000000\n",
      "(Iteration 159501 / 360000) loss: -0.000000\n",
      "(Iteration 159601 / 360000) loss: -0.000000\n",
      "(Iteration 159701 / 360000) loss: -0.000000\n",
      "(Iteration 159801 / 360000) loss: -0.000000\n",
      "(Iteration 159901 / 360000) loss: -0.000000\n",
      "(Iteration 160001 / 360000) loss: -0.000000\n",
      "(Iteration 160101 / 360000) loss: -0.000000\n",
      "(Iteration 160201 / 360000) loss: -0.000000\n",
      "(Iteration 160301 / 360000) loss: -0.000000\n",
      "(Iteration 160401 / 360000) loss: -0.000000\n",
      "(Iteration 160501 / 360000) loss: -0.000000\n",
      "(Iteration 160601 / 360000) loss: -0.000000\n",
      "(Iteration 160701 / 360000) loss: -0.000000\n",
      "(Iteration 160801 / 360000) loss: -0.000000\n",
      "(Iteration 160901 / 360000) loss: -0.000000\n",
      "(Iteration 161001 / 360000) loss: -0.000000\n",
      "(Iteration 161101 / 360000) loss: -0.000000\n",
      "(Iteration 161201 / 360000) loss: -0.000000\n",
      "(Iteration 161301 / 360000) loss: -0.000000\n",
      "(Iteration 161401 / 360000) loss: -0.000000\n",
      "(Iteration 161501 / 360000) loss: -0.000000\n",
      "(Iteration 161601 / 360000) loss: -0.000000\n",
      "(Iteration 161701 / 360000) loss: -0.000000\n",
      "(Iteration 161801 / 360000) loss: -0.000000\n",
      "(Iteration 161901 / 360000) loss: -0.000000\n",
      "(Epoch 45 / 100) train acc: 0.919000; val_acc: 0.885980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 162001 / 360000) loss: 806.106328\n",
      "(Iteration 162101 / 360000) loss: -0.000000\n",
      "(Iteration 162201 / 360000) loss: -0.000000\n",
      "(Iteration 162301 / 360000) loss: -0.000000\n",
      "(Iteration 162401 / 360000) loss: -0.000000\n",
      "(Iteration 162501 / 360000) loss: -0.000000\n",
      "(Iteration 162601 / 360000) loss: -0.000000\n",
      "(Iteration 162701 / 360000) loss: -0.000000\n",
      "(Iteration 162801 / 360000) loss: -0.000000\n",
      "(Iteration 162901 / 360000) loss: -0.000000\n",
      "(Iteration 163001 / 360000) loss: -0.000000\n",
      "(Iteration 163101 / 360000) loss: -0.000000\n",
      "(Iteration 163201 / 360000) loss: -0.000000\n",
      "(Iteration 163301 / 360000) loss: -0.000000\n",
      "(Iteration 163401 / 360000) loss: -0.000000\n",
      "(Iteration 163501 / 360000) loss: -0.000000\n",
      "(Iteration 163601 / 360000) loss: -0.000000\n",
      "(Iteration 163701 / 360000) loss: 74.326646\n",
      "(Iteration 163801 / 360000) loss: -0.000000\n",
      "(Iteration 163901 / 360000) loss: -0.000000\n",
      "(Iteration 164001 / 360000) loss: -0.000000\n",
      "(Iteration 164101 / 360000) loss: -0.000000\n",
      "(Iteration 164201 / 360000) loss: 22.828774\n",
      "(Iteration 164301 / 360000) loss: 4302.734788\n",
      "(Iteration 164401 / 360000) loss: -0.000000\n",
      "(Iteration 164501 / 360000) loss: -0.000000\n",
      "(Iteration 164601 / 360000) loss: -0.000000\n",
      "(Iteration 164701 / 360000) loss: 676.614446\n",
      "(Iteration 164801 / 360000) loss: -0.000000\n",
      "(Iteration 164901 / 360000) loss: -0.000000\n",
      "(Iteration 165001 / 360000) loss: -0.000000\n",
      "(Iteration 165101 / 360000) loss: -0.000000\n",
      "(Iteration 165201 / 360000) loss: -0.000000\n",
      "(Iteration 165301 / 360000) loss: -0.000000\n",
      "(Iteration 165401 / 360000) loss: -0.000000\n",
      "(Iteration 165501 / 360000) loss: -0.000000\n",
      "(Epoch 46 / 100) train acc: 0.931000; val_acc: 0.880912\n",
      "(Iteration 165601 / 360000) loss: -0.000000\n",
      "(Iteration 165701 / 360000) loss: -0.000000\n",
      "(Iteration 165801 / 360000) loss: -0.000000\n",
      "(Iteration 165901 / 360000) loss: -0.000000\n",
      "(Iteration 166001 / 360000) loss: -0.000000\n",
      "(Iteration 166101 / 360000) loss: -0.000000\n",
      "(Iteration 166201 / 360000) loss: -0.000000\n",
      "(Iteration 166301 / 360000) loss: -0.000000\n",
      "(Iteration 166401 / 360000) loss: -0.000000\n",
      "(Iteration 166501 / 360000) loss: -0.000000\n",
      "(Iteration 166601 / 360000) loss: -0.000000\n",
      "(Iteration 166701 / 360000) loss: -0.000000\n",
      "(Iteration 166801 / 360000) loss: -0.000000\n",
      "(Iteration 166901 / 360000) loss: -0.000000\n",
      "(Iteration 167001 / 360000) loss: -0.000000\n",
      "(Iteration 167101 / 360000) loss: -0.000000\n",
      "(Iteration 167201 / 360000) loss: -0.000000\n",
      "(Iteration 167301 / 360000) loss: -0.000000\n",
      "(Iteration 167401 / 360000) loss: -0.000000\n",
      "(Iteration 167501 / 360000) loss: -0.000000\n",
      "(Iteration 167601 / 360000) loss: -0.000000\n",
      "(Iteration 167701 / 360000) loss: -0.000000\n",
      "(Iteration 167801 / 360000) loss: -0.000000\n",
      "(Iteration 167901 / 360000) loss: -0.000000\n",
      "(Iteration 168001 / 360000) loss: -0.000000\n",
      "(Iteration 168101 / 360000) loss: -0.000000\n",
      "(Iteration 168201 / 360000) loss: -0.000000\n",
      "(Iteration 168301 / 360000) loss: -0.000000\n",
      "(Iteration 168401 / 360000) loss: -0.000000\n",
      "(Iteration 168501 / 360000) loss: -0.000000\n",
      "(Iteration 168601 / 360000) loss: -0.000000\n",
      "(Iteration 168701 / 360000) loss: -0.000000\n",
      "(Iteration 168801 / 360000) loss: -0.000000\n",
      "(Iteration 168901 / 360000) loss: -0.000000\n",
      "(Iteration 169001 / 360000) loss: -0.000000\n",
      "(Iteration 169101 / 360000) loss: -0.000000\n",
      "(Epoch 47 / 100) train acc: 0.925000; val_acc: 0.884291\n",
      "(Iteration 169201 / 360000) loss: -0.000000\n",
      "(Iteration 169301 / 360000) loss: -0.000000\n",
      "(Iteration 169401 / 360000) loss: -0.000000\n",
      "(Iteration 169501 / 360000) loss: -0.000000\n",
      "(Iteration 169601 / 360000) loss: -0.000000\n",
      "(Iteration 169701 / 360000) loss: -0.000000\n",
      "(Iteration 169801 / 360000) loss: -0.000000\n",
      "(Iteration 169901 / 360000) loss: 215.599232\n",
      "(Iteration 170001 / 360000) loss: -0.000000\n",
      "(Iteration 170101 / 360000) loss: -0.000000\n",
      "(Iteration 170201 / 360000) loss: -0.000000\n",
      "(Iteration 170301 / 360000) loss: -0.000000\n",
      "(Iteration 170401 / 360000) loss: -0.000000\n",
      "(Iteration 170501 / 360000) loss: -0.000000\n",
      "(Iteration 170601 / 360000) loss: -0.000000\n",
      "(Iteration 170701 / 360000) loss: -0.000000\n",
      "(Iteration 170801 / 360000) loss: 1069.227421\n",
      "(Iteration 170901 / 360000) loss: -0.000000\n",
      "(Iteration 171001 / 360000) loss: -0.000000\n",
      "(Iteration 171101 / 360000) loss: -0.000000\n",
      "(Iteration 171201 / 360000) loss: -0.000000\n",
      "(Iteration 171301 / 360000) loss: -0.000000\n",
      "(Iteration 171401 / 360000) loss: -0.000000\n",
      "(Iteration 171501 / 360000) loss: -0.000000\n",
      "(Iteration 171601 / 360000) loss: 2411.789196\n",
      "(Iteration 171701 / 360000) loss: -0.000000\n",
      "(Iteration 171801 / 360000) loss: -0.000000\n",
      "(Iteration 171901 / 360000) loss: -0.000000\n",
      "(Iteration 172001 / 360000) loss: -0.000000\n",
      "(Iteration 172101 / 360000) loss: -0.000000\n",
      "(Iteration 172201 / 360000) loss: -0.000000\n",
      "(Iteration 172301 / 360000) loss: -0.000000\n",
      "(Iteration 172401 / 360000) loss: -0.000000\n",
      "(Iteration 172501 / 360000) loss: -0.000000\n",
      "(Iteration 172601 / 360000) loss: -0.000000\n",
      "(Iteration 172701 / 360000) loss: -0.000000\n",
      "(Epoch 48 / 100) train acc: 0.920000; val_acc: 0.885135\n",
      "(Iteration 172801 / 360000) loss: -0.000000\n",
      "(Iteration 172901 / 360000) loss: -0.000000\n",
      "(Iteration 173001 / 360000) loss: -0.000000\n",
      "(Iteration 173101 / 360000) loss: -0.000000\n",
      "(Iteration 173201 / 360000) loss: -0.000000\n",
      "(Iteration 173301 / 360000) loss: -0.000000\n",
      "(Iteration 173401 / 360000) loss: 499.946422\n",
      "(Iteration 173501 / 360000) loss: -0.000000\n",
      "(Iteration 173601 / 360000) loss: 145.775371\n",
      "(Iteration 173701 / 360000) loss: -0.000000\n",
      "(Iteration 173801 / 360000) loss: -0.000000\n",
      "(Iteration 173901 / 360000) loss: -0.000000\n",
      "(Iteration 174001 / 360000) loss: -0.000000\n",
      "(Iteration 174101 / 360000) loss: -0.000000\n",
      "(Iteration 174201 / 360000) loss: -0.000000\n",
      "(Iteration 174301 / 360000) loss: -0.000000\n",
      "(Iteration 174401 / 360000) loss: -0.000000\n",
      "(Iteration 174501 / 360000) loss: -0.000000\n",
      "(Iteration 174601 / 360000) loss: -0.000000\n",
      "(Iteration 174701 / 360000) loss: -0.000000\n",
      "(Iteration 174801 / 360000) loss: -0.000000\n",
      "(Iteration 174901 / 360000) loss: -0.000000\n",
      "(Iteration 175001 / 360000) loss: 566.834249\n",
      "(Iteration 175101 / 360000) loss: -0.000000\n",
      "(Iteration 175201 / 360000) loss: -0.000000\n",
      "(Iteration 175301 / 360000) loss: -0.000000\n",
      "(Iteration 175401 / 360000) loss: -0.000000\n",
      "(Iteration 175501 / 360000) loss: -0.000000\n",
      "(Iteration 175601 / 360000) loss: -0.000000\n",
      "(Iteration 175701 / 360000) loss: -0.000000\n",
      "(Iteration 175801 / 360000) loss: 16.476648\n",
      "(Iteration 175901 / 360000) loss: -0.000000\n",
      "(Iteration 176001 / 360000) loss: -0.000000\n",
      "(Iteration 176101 / 360000) loss: -0.000000\n",
      "(Iteration 176201 / 360000) loss: -0.000000\n",
      "(Iteration 176301 / 360000) loss: -0.000000\n",
      "(Epoch 49 / 100) train acc: 0.925000; val_acc: 0.884291\n",
      "(Iteration 176401 / 360000) loss: -0.000000\n",
      "(Iteration 176501 / 360000) loss: -0.000000\n",
      "(Iteration 176601 / 360000) loss: -0.000000\n",
      "(Iteration 176701 / 360000) loss: -0.000000\n",
      "(Iteration 176801 / 360000) loss: 2097.363045\n",
      "(Iteration 176901 / 360000) loss: -0.000000\n",
      "(Iteration 177001 / 360000) loss: -0.000000\n",
      "(Iteration 177101 / 360000) loss: -0.000000\n",
      "(Iteration 177201 / 360000) loss: -0.000000\n",
      "(Iteration 177301 / 360000) loss: -0.000000\n",
      "(Iteration 177401 / 360000) loss: -0.000000\n",
      "(Iteration 177501 / 360000) loss: -0.000000\n",
      "(Iteration 177601 / 360000) loss: -0.000000\n",
      "(Iteration 177701 / 360000) loss: -0.000000\n",
      "(Iteration 177801 / 360000) loss: -0.000000\n",
      "(Iteration 177901 / 360000) loss: -0.000000\n",
      "(Iteration 178001 / 360000) loss: -0.000000\n",
      "(Iteration 178101 / 360000) loss: -0.000000\n",
      "(Iteration 178201 / 360000) loss: -0.000000\n",
      "(Iteration 178301 / 360000) loss: -0.000000\n",
      "(Iteration 178401 / 360000) loss: -0.000000\n",
      "(Iteration 178501 / 360000) loss: 192.268308\n",
      "(Iteration 178601 / 360000) loss: -0.000000\n",
      "(Iteration 178701 / 360000) loss: -0.000000\n",
      "(Iteration 178801 / 360000) loss: -0.000000\n",
      "(Iteration 178901 / 360000) loss: -0.000000\n",
      "(Iteration 179001 / 360000) loss: -0.000000\n",
      "(Iteration 179101 / 360000) loss: -0.000000\n",
      "(Iteration 179201 / 360000) loss: -0.000000\n",
      "(Iteration 179301 / 360000) loss: -0.000000\n",
      "(Iteration 179401 / 360000) loss: -0.000000\n",
      "(Iteration 179501 / 360000) loss: -0.000000\n",
      "(Iteration 179601 / 360000) loss: -0.000000\n",
      "(Iteration 179701 / 360000) loss: -0.000000\n",
      "(Iteration 179801 / 360000) loss: -0.000000\n",
      "(Iteration 179901 / 360000) loss: -0.000000\n",
      "(Epoch 50 / 100) train acc: 0.915000; val_acc: 0.884291\n",
      "(Iteration 180001 / 360000) loss: -0.000000\n",
      "(Iteration 180101 / 360000) loss: -0.000000\n",
      "(Iteration 180201 / 360000) loss: -0.000000\n",
      "(Iteration 180301 / 360000) loss: -0.000000\n",
      "(Iteration 180401 / 360000) loss: -0.000000\n",
      "(Iteration 180501 / 360000) loss: -0.000000\n",
      "(Iteration 180601 / 360000) loss: -0.000000\n",
      "(Iteration 180701 / 360000) loss: -0.000000\n",
      "(Iteration 180801 / 360000) loss: -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 180901 / 360000) loss: -0.000000\n",
      "(Iteration 181001 / 360000) loss: -0.000000\n",
      "(Iteration 181101 / 360000) loss: -0.000000\n",
      "(Iteration 181201 / 360000) loss: -0.000000\n",
      "(Iteration 181301 / 360000) loss: -0.000000\n",
      "(Iteration 181401 / 360000) loss: -0.000000\n",
      "(Iteration 181501 / 360000) loss: -0.000000\n",
      "(Iteration 181601 / 360000) loss: -0.000000\n",
      "(Iteration 181701 / 360000) loss: -0.000000\n",
      "(Iteration 181801 / 360000) loss: -0.000000\n",
      "(Iteration 181901 / 360000) loss: -0.000000\n",
      "(Iteration 182001 / 360000) loss: -0.000000\n",
      "(Iteration 182101 / 360000) loss: -0.000000\n",
      "(Iteration 182201 / 360000) loss: -0.000000\n",
      "(Iteration 182301 / 360000) loss: -0.000000\n",
      "(Iteration 182401 / 360000) loss: -0.000000\n",
      "(Iteration 182501 / 360000) loss: -0.000000\n",
      "(Iteration 182601 / 360000) loss: -0.000000\n",
      "(Iteration 182701 / 360000) loss: -0.000000\n",
      "(Iteration 182801 / 360000) loss: -0.000000\n",
      "(Iteration 182901 / 360000) loss: -0.000000\n",
      "(Iteration 183001 / 360000) loss: -0.000000\n",
      "(Iteration 183101 / 360000) loss: -0.000000\n",
      "(Iteration 183201 / 360000) loss: -0.000000\n",
      "(Iteration 183301 / 360000) loss: -0.000000\n",
      "(Iteration 183401 / 360000) loss: -0.000000\n",
      "(Iteration 183501 / 360000) loss: -0.000000\n",
      "(Epoch 51 / 100) train acc: 0.920000; val_acc: 0.884291\n",
      "(Iteration 183601 / 360000) loss: -0.000000\n",
      "(Iteration 183701 / 360000) loss: -0.000000\n",
      "(Iteration 183801 / 360000) loss: -0.000000\n",
      "(Iteration 183901 / 360000) loss: -0.000000\n",
      "(Iteration 184001 / 360000) loss: -0.000000\n",
      "(Iteration 184101 / 360000) loss: -0.000000\n",
      "(Iteration 184201 / 360000) loss: 32.101367\n",
      "(Iteration 184301 / 360000) loss: -0.000000\n",
      "(Iteration 184401 / 360000) loss: -0.000000\n",
      "(Iteration 184501 / 360000) loss: -0.000000\n",
      "(Iteration 184601 / 360000) loss: -0.000000\n",
      "(Iteration 184701 / 360000) loss: -0.000000\n",
      "(Iteration 184801 / 360000) loss: -0.000000\n",
      "(Iteration 184901 / 360000) loss: -0.000000\n",
      "(Iteration 185001 / 360000) loss: -0.000000\n",
      "(Iteration 185101 / 360000) loss: -0.000000\n",
      "(Iteration 185201 / 360000) loss: -0.000000\n",
      "(Iteration 185301 / 360000) loss: -0.000000\n",
      "(Iteration 185401 / 360000) loss: -0.000000\n",
      "(Iteration 185501 / 360000) loss: -0.000000\n",
      "(Iteration 185601 / 360000) loss: -0.000000\n",
      "(Iteration 185701 / 360000) loss: -0.000000\n",
      "(Iteration 185801 / 360000) loss: -0.000000\n",
      "(Iteration 185901 / 360000) loss: -0.000000\n",
      "(Iteration 186001 / 360000) loss: -0.000000\n",
      "(Iteration 186101 / 360000) loss: -0.000000\n",
      "(Iteration 186201 / 360000) loss: -0.000000\n",
      "(Iteration 186301 / 360000) loss: -0.000000\n",
      "(Iteration 186401 / 360000) loss: -0.000000\n",
      "(Iteration 186501 / 360000) loss: -0.000000\n",
      "(Iteration 186601 / 360000) loss: -0.000000\n",
      "(Iteration 186701 / 360000) loss: 399.585540\n",
      "(Iteration 186801 / 360000) loss: -0.000000\n",
      "(Iteration 186901 / 360000) loss: -0.000000\n",
      "(Iteration 187001 / 360000) loss: -0.000000\n",
      "(Iteration 187101 / 360000) loss: -0.000000\n",
      "(Epoch 52 / 100) train acc: 0.923000; val_acc: 0.885135\n",
      "(Iteration 187201 / 360000) loss: 0.000000\n",
      "(Iteration 187301 / 360000) loss: -0.000000\n",
      "(Iteration 187401 / 360000) loss: -0.000000\n",
      "(Iteration 187501 / 360000) loss: -0.000000\n",
      "(Iteration 187601 / 360000) loss: 181.082811\n",
      "(Iteration 187701 / 360000) loss: -0.000000\n",
      "(Iteration 187801 / 360000) loss: -0.000000\n",
      "(Iteration 187901 / 360000) loss: -0.000000\n",
      "(Iteration 188001 / 360000) loss: -0.000000\n",
      "(Iteration 188101 / 360000) loss: -0.000000\n",
      "(Iteration 188201 / 360000) loss: -0.000000\n",
      "(Iteration 188301 / 360000) loss: -0.000000\n",
      "(Iteration 188401 / 360000) loss: -0.000000\n",
      "(Iteration 188501 / 360000) loss: -0.000000\n",
      "(Iteration 188601 / 360000) loss: -0.000000\n",
      "(Iteration 188701 / 360000) loss: -0.000000\n",
      "(Iteration 188801 / 360000) loss: -0.000000\n",
      "(Iteration 188901 / 360000) loss: -0.000000\n",
      "(Iteration 189001 / 360000) loss: -0.000000\n",
      "(Iteration 189101 / 360000) loss: -0.000000\n",
      "(Iteration 189201 / 360000) loss: -0.000000\n",
      "(Iteration 189301 / 360000) loss: -0.000000\n",
      "(Iteration 189401 / 360000) loss: -0.000000\n",
      "(Iteration 189501 / 360000) loss: -0.000000\n",
      "(Iteration 189601 / 360000) loss: -0.000000\n",
      "(Iteration 189701 / 360000) loss: -0.000000\n",
      "(Iteration 189801 / 360000) loss: -0.000000\n",
      "(Iteration 189901 / 360000) loss: -0.000000\n",
      "(Iteration 190001 / 360000) loss: -0.000000\n",
      "(Iteration 190101 / 360000) loss: -0.000000\n",
      "(Iteration 190201 / 360000) loss: -0.000000\n",
      "(Iteration 190301 / 360000) loss: -0.000000\n",
      "(Iteration 190401 / 360000) loss: -0.000000\n",
      "(Iteration 190501 / 360000) loss: -0.000000\n",
      "(Iteration 190601 / 360000) loss: -0.000000\n",
      "(Iteration 190701 / 360000) loss: 46.212461\n",
      "(Epoch 53 / 100) train acc: 0.933000; val_acc: 0.885135\n",
      "(Iteration 190801 / 360000) loss: -0.000000\n",
      "(Iteration 190901 / 360000) loss: -0.000000\n",
      "(Iteration 191001 / 360000) loss: -0.000000\n",
      "(Iteration 191101 / 360000) loss: -0.000000\n",
      "(Iteration 191201 / 360000) loss: -0.000000\n",
      "(Iteration 191301 / 360000) loss: -0.000000\n",
      "(Iteration 191401 / 360000) loss: -0.000000\n",
      "(Iteration 191501 / 360000) loss: -0.000000\n",
      "(Iteration 191601 / 360000) loss: -0.000000\n",
      "(Iteration 191701 / 360000) loss: -0.000000\n",
      "(Iteration 191801 / 360000) loss: -0.000000\n",
      "(Iteration 191901 / 360000) loss: -0.000000\n",
      "(Iteration 192001 / 360000) loss: -0.000000\n",
      "(Iteration 192101 / 360000) loss: -0.000000\n",
      "(Iteration 192201 / 360000) loss: -0.000000\n",
      "(Iteration 192301 / 360000) loss: -0.000000\n",
      "(Iteration 192401 / 360000) loss: -0.000000\n",
      "(Iteration 192501 / 360000) loss: -0.000000\n",
      "(Iteration 192601 / 360000) loss: -0.000000\n",
      "(Iteration 192701 / 360000) loss: -0.000000\n",
      "(Iteration 192801 / 360000) loss: -0.000000\n",
      "(Iteration 192901 / 360000) loss: -0.000000\n",
      "(Iteration 193001 / 360000) loss: -0.000000\n",
      "(Iteration 193101 / 360000) loss: -0.000000\n",
      "(Iteration 193201 / 360000) loss: -0.000000\n",
      "(Iteration 193301 / 360000) loss: -0.000000\n",
      "(Iteration 193401 / 360000) loss: -0.000000\n",
      "(Iteration 193501 / 360000) loss: 264.900025\n",
      "(Iteration 193601 / 360000) loss: 799.477672\n",
      "(Iteration 193701 / 360000) loss: -0.000000\n",
      "(Iteration 193801 / 360000) loss: -0.000000\n",
      "(Iteration 193901 / 360000) loss: -0.000000\n",
      "(Iteration 194001 / 360000) loss: -0.000000\n",
      "(Iteration 194101 / 360000) loss: -0.000000\n",
      "(Iteration 194201 / 360000) loss: -0.000000\n",
      "(Iteration 194301 / 360000) loss: -0.000000\n",
      "(Epoch 54 / 100) train acc: 0.924000; val_acc: 0.885135\n",
      "(Iteration 194401 / 360000) loss: -0.000000\n",
      "(Iteration 194501 / 360000) loss: -0.000000\n",
      "(Iteration 194601 / 360000) loss: -0.000000\n",
      "(Iteration 194701 / 360000) loss: 887.353439\n",
      "(Iteration 194801 / 360000) loss: 891.210993\n",
      "(Iteration 194901 / 360000) loss: -0.000000\n",
      "(Iteration 195001 / 360000) loss: -0.000000\n",
      "(Iteration 195101 / 360000) loss: -0.000000\n",
      "(Iteration 195201 / 360000) loss: 414.965559\n",
      "(Iteration 195301 / 360000) loss: -0.000000\n",
      "(Iteration 195401 / 360000) loss: -0.000000\n",
      "(Iteration 195501 / 360000) loss: -0.000000\n",
      "(Iteration 195601 / 360000) loss: -0.000000\n",
      "(Iteration 195701 / 360000) loss: -0.000000\n",
      "(Iteration 195801 / 360000) loss: -0.000000\n",
      "(Iteration 195901 / 360000) loss: -0.000000\n",
      "(Iteration 196001 / 360000) loss: -0.000000\n",
      "(Iteration 196101 / 360000) loss: -0.000000\n",
      "(Iteration 196201 / 360000) loss: -0.000000\n",
      "(Iteration 196301 / 360000) loss: -0.000000\n",
      "(Iteration 196401 / 360000) loss: -0.000000\n",
      "(Iteration 196501 / 360000) loss: -0.000000\n",
      "(Iteration 196601 / 360000) loss: -0.000000\n",
      "(Iteration 196701 / 360000) loss: -0.000000\n",
      "(Iteration 196801 / 360000) loss: -0.000000\n",
      "(Iteration 196901 / 360000) loss: -0.000000\n",
      "(Iteration 197001 / 360000) loss: -0.000000\n",
      "(Iteration 197101 / 360000) loss: -0.000000\n",
      "(Iteration 197201 / 360000) loss: -0.000000\n",
      "(Iteration 197301 / 360000) loss: -0.000000\n",
      "(Iteration 197401 / 360000) loss: -0.000000\n",
      "(Iteration 197501 / 360000) loss: -0.000000\n",
      "(Iteration 197601 / 360000) loss: -0.000000\n",
      "(Iteration 197701 / 360000) loss: -0.000000\n",
      "(Iteration 197801 / 360000) loss: -0.000000\n",
      "(Iteration 197901 / 360000) loss: -0.000000\n",
      "(Epoch 55 / 100) train acc: 0.943000; val_acc: 0.885135\n",
      "(Iteration 198001 / 360000) loss: -0.000000\n",
      "(Iteration 198101 / 360000) loss: -0.000000\n",
      "(Iteration 198201 / 360000) loss: -0.000000\n",
      "(Iteration 198301 / 360000) loss: -0.000000\n",
      "(Iteration 198401 / 360000) loss: -0.000000\n",
      "(Iteration 198501 / 360000) loss: -0.000000\n",
      "(Iteration 198601 / 360000) loss: -0.000000\n",
      "(Iteration 198701 / 360000) loss: -0.000000\n",
      "(Iteration 198801 / 360000) loss: -0.000000\n",
      "(Iteration 198901 / 360000) loss: -0.000000\n",
      "(Iteration 199001 / 360000) loss: -0.000000\n",
      "(Iteration 199101 / 360000) loss: -0.000000\n",
      "(Iteration 199201 / 360000) loss: -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 199301 / 360000) loss: 37.075438\n",
      "(Iteration 199401 / 360000) loss: -0.000000\n",
      "(Iteration 199501 / 360000) loss: -0.000000\n",
      "(Iteration 199601 / 360000) loss: -0.000000\n",
      "(Iteration 199701 / 360000) loss: -0.000000\n",
      "(Iteration 199801 / 360000) loss: -0.000000\n",
      "(Iteration 199901 / 360000) loss: 1658.237448\n",
      "(Iteration 200001 / 360000) loss: -0.000000\n",
      "(Iteration 200101 / 360000) loss: -0.000000\n",
      "(Iteration 200201 / 360000) loss: -0.000000\n",
      "(Iteration 200301 / 360000) loss: -0.000000\n",
      "(Iteration 200401 / 360000) loss: 439.116395\n",
      "(Iteration 200501 / 360000) loss: -0.000000\n",
      "(Iteration 200601 / 360000) loss: 15.267413\n",
      "(Iteration 200701 / 360000) loss: -0.000000\n",
      "(Iteration 200801 / 360000) loss: -0.000000\n",
      "(Iteration 200901 / 360000) loss: -0.000000\n",
      "(Iteration 201001 / 360000) loss: -0.000000\n",
      "(Iteration 201101 / 360000) loss: -0.000000\n",
      "(Iteration 201201 / 360000) loss: 731.083527\n",
      "(Iteration 201301 / 360000) loss: -0.000000\n",
      "(Iteration 201401 / 360000) loss: 0.439313\n",
      "(Iteration 201501 / 360000) loss: -0.000000\n",
      "(Epoch 56 / 100) train acc: 0.928000; val_acc: 0.885135\n",
      "(Iteration 201601 / 360000) loss: -0.000000\n",
      "(Iteration 201701 / 360000) loss: -0.000000\n",
      "(Iteration 201801 / 360000) loss: -0.000000\n",
      "(Iteration 201901 / 360000) loss: -0.000000\n",
      "(Iteration 202001 / 360000) loss: -0.000000\n",
      "(Iteration 202101 / 360000) loss: -0.000000\n",
      "(Iteration 202201 / 360000) loss: -0.000000\n",
      "(Iteration 202301 / 360000) loss: -0.000000\n",
      "(Iteration 202401 / 360000) loss: -0.000000\n",
      "(Iteration 202501 / 360000) loss: -0.000000\n",
      "(Iteration 202601 / 360000) loss: -0.000000\n",
      "(Iteration 202701 / 360000) loss: -0.000000\n",
      "(Iteration 202801 / 360000) loss: -0.000000\n",
      "(Iteration 202901 / 360000) loss: -0.000000\n",
      "(Iteration 203001 / 360000) loss: -0.000000\n",
      "(Iteration 203101 / 360000) loss: -0.000000\n",
      "(Iteration 203201 / 360000) loss: 1417.467971\n",
      "(Iteration 203301 / 360000) loss: -0.000000\n",
      "(Iteration 203401 / 360000) loss: -0.000000\n",
      "(Iteration 203501 / 360000) loss: -0.000000\n",
      "(Iteration 203601 / 360000) loss: -0.000000\n",
      "(Iteration 203701 / 360000) loss: 729.412579\n",
      "(Iteration 203801 / 360000) loss: -0.000000\n",
      "(Iteration 203901 / 360000) loss: -0.000000\n",
      "(Iteration 204001 / 360000) loss: -0.000000\n",
      "(Iteration 204101 / 360000) loss: -0.000000\n",
      "(Iteration 204201 / 360000) loss: -0.000000\n",
      "(Iteration 204301 / 360000) loss: -0.000000\n",
      "(Iteration 204401 / 360000) loss: -0.000000\n",
      "(Iteration 204501 / 360000) loss: -0.000000\n",
      "(Iteration 204601 / 360000) loss: -0.000000\n",
      "(Iteration 204701 / 360000) loss: -0.000000\n",
      "(Iteration 204801 / 360000) loss: -0.000000\n",
      "(Iteration 204901 / 360000) loss: -0.000000\n",
      "(Iteration 205001 / 360000) loss: -0.000000\n",
      "(Iteration 205101 / 360000) loss: -0.000000\n",
      "(Epoch 57 / 100) train acc: 0.920000; val_acc: 0.885135\n",
      "(Iteration 205201 / 360000) loss: -0.000000\n",
      "(Iteration 205301 / 360000) loss: -0.000000\n",
      "(Iteration 205401 / 360000) loss: -0.000000\n",
      "(Iteration 205501 / 360000) loss: -0.000000\n",
      "(Iteration 205601 / 360000) loss: -0.000000\n",
      "(Iteration 205701 / 360000) loss: -0.000000\n",
      "(Iteration 205801 / 360000) loss: -0.000000\n",
      "(Iteration 205901 / 360000) loss: -0.000000\n",
      "(Iteration 206001 / 360000) loss: -0.000000\n",
      "(Iteration 206101 / 360000) loss: -0.000000\n",
      "(Iteration 206201 / 360000) loss: -0.000000\n",
      "(Iteration 206301 / 360000) loss: -0.000000\n",
      "(Iteration 206401 / 360000) loss: -0.000000\n",
      "(Iteration 206501 / 360000) loss: -0.000000\n",
      "(Iteration 206601 / 360000) loss: -0.000000\n",
      "(Iteration 206701 / 360000) loss: -0.000000\n",
      "(Iteration 206801 / 360000) loss: -0.000000\n",
      "(Iteration 206901 / 360000) loss: -0.000000\n",
      "(Iteration 207001 / 360000) loss: -0.000000\n",
      "(Iteration 207101 / 360000) loss: 0.000000\n",
      "(Iteration 207201 / 360000) loss: -0.000000\n",
      "(Iteration 207301 / 360000) loss: -0.000000\n",
      "(Iteration 207401 / 360000) loss: -0.000000\n",
      "(Iteration 207501 / 360000) loss: -0.000000\n",
      "(Iteration 207601 / 360000) loss: -0.000000\n",
      "(Iteration 207701 / 360000) loss: -0.000000\n",
      "(Iteration 207801 / 360000) loss: -0.000000\n",
      "(Iteration 207901 / 360000) loss: -0.000000\n",
      "(Iteration 208001 / 360000) loss: -0.000000\n",
      "(Iteration 208101 / 360000) loss: -0.000000\n",
      "(Iteration 208201 / 360000) loss: -0.000000\n",
      "(Iteration 208301 / 360000) loss: -0.000000\n",
      "(Iteration 208401 / 360000) loss: -0.000000\n",
      "(Iteration 208501 / 360000) loss: -0.000000\n",
      "(Iteration 208601 / 360000) loss: -0.000000\n",
      "(Iteration 208701 / 360000) loss: -0.000000\n",
      "(Epoch 58 / 100) train acc: 0.935000; val_acc: 0.885135\n",
      "(Iteration 208801 / 360000) loss: 0.000000\n",
      "(Iteration 208901 / 360000) loss: -0.000000\n",
      "(Iteration 209001 / 360000) loss: 286.750643\n",
      "(Iteration 209101 / 360000) loss: -0.000000\n",
      "(Iteration 209201 / 360000) loss: -0.000000\n",
      "(Iteration 209301 / 360000) loss: 757.954113\n",
      "(Iteration 209401 / 360000) loss: -0.000000\n",
      "(Iteration 209501 / 360000) loss: -0.000000\n",
      "(Iteration 209601 / 360000) loss: -0.000000\n",
      "(Iteration 209701 / 360000) loss: -0.000000\n",
      "(Iteration 209801 / 360000) loss: -0.000000\n",
      "(Iteration 209901 / 360000) loss: 4681.418588\n",
      "(Iteration 210001 / 360000) loss: -0.000000\n",
      "(Iteration 210101 / 360000) loss: -0.000000\n",
      "(Iteration 210201 / 360000) loss: -0.000000\n",
      "(Iteration 210301 / 360000) loss: -0.000000\n",
      "(Iteration 210401 / 360000) loss: -0.000000\n",
      "(Iteration 210501 / 360000) loss: -0.000000\n",
      "(Iteration 210601 / 360000) loss: -0.000000\n",
      "(Iteration 210701 / 360000) loss: -0.000000\n",
      "(Iteration 210801 / 360000) loss: -0.000000\n",
      "(Iteration 210901 / 360000) loss: 873.934522\n",
      "(Iteration 211001 / 360000) loss: -0.000000\n",
      "(Iteration 211101 / 360000) loss: -0.000000\n",
      "(Iteration 211201 / 360000) loss: -0.000000\n",
      "(Iteration 211301 / 360000) loss: -0.000000\n",
      "(Iteration 211401 / 360000) loss: -0.000000\n",
      "(Iteration 211501 / 360000) loss: -0.000000\n",
      "(Iteration 211601 / 360000) loss: -0.000000\n",
      "(Iteration 211701 / 360000) loss: -0.000000\n",
      "(Iteration 211801 / 360000) loss: 851.045483\n",
      "(Iteration 211901 / 360000) loss: -0.000000\n",
      "(Iteration 212001 / 360000) loss: -0.000000\n",
      "(Iteration 212101 / 360000) loss: -0.000000\n",
      "(Iteration 212201 / 360000) loss: -0.000000\n",
      "(Iteration 212301 / 360000) loss: -0.000000\n",
      "(Epoch 59 / 100) train acc: 0.929000; val_acc: 0.885135\n",
      "(Iteration 212401 / 360000) loss: -0.000000\n",
      "(Iteration 212501 / 360000) loss: -0.000000\n",
      "(Iteration 212601 / 360000) loss: -0.000000\n",
      "(Iteration 212701 / 360000) loss: 1512.831695\n",
      "(Iteration 212801 / 360000) loss: -0.000000\n",
      "(Iteration 212901 / 360000) loss: -0.000000\n",
      "(Iteration 213001 / 360000) loss: -0.000000\n",
      "(Iteration 213101 / 360000) loss: -0.000000\n",
      "(Iteration 213201 / 360000) loss: -0.000000\n",
      "(Iteration 213301 / 360000) loss: 0.000000\n",
      "(Iteration 213401 / 360000) loss: -0.000000\n",
      "(Iteration 213501 / 360000) loss: 1993.349880\n",
      "(Iteration 213601 / 360000) loss: -0.000000\n",
      "(Iteration 213701 / 360000) loss: -0.000000\n",
      "(Iteration 213801 / 360000) loss: -0.000000\n",
      "(Iteration 213901 / 360000) loss: -0.000000\n",
      "(Iteration 214001 / 360000) loss: -0.000000\n",
      "(Iteration 214101 / 360000) loss: -0.000000\n",
      "(Iteration 214201 / 360000) loss: -0.000000\n",
      "(Iteration 214301 / 360000) loss: -0.000000\n",
      "(Iteration 214401 / 360000) loss: -0.000000\n",
      "(Iteration 214501 / 360000) loss: -0.000000\n",
      "(Iteration 214601 / 360000) loss: -0.000000\n",
      "(Iteration 214701 / 360000) loss: -0.000000\n",
      "(Iteration 214801 / 360000) loss: -0.000000\n",
      "(Iteration 214901 / 360000) loss: -0.000000\n",
      "(Iteration 215001 / 360000) loss: 1688.603322\n",
      "(Iteration 215101 / 360000) loss: -0.000000\n",
      "(Iteration 215201 / 360000) loss: -0.000000\n",
      "(Iteration 215301 / 360000) loss: 1593.145841\n",
      "(Iteration 215401 / 360000) loss: -0.000000\n",
      "(Iteration 215501 / 360000) loss: -0.000000\n",
      "(Iteration 215601 / 360000) loss: -0.000000\n",
      "(Iteration 215701 / 360000) loss: -0.000000\n",
      "(Iteration 215801 / 360000) loss: 184.277819\n",
      "(Iteration 215901 / 360000) loss: -0.000000\n",
      "(Epoch 60 / 100) train acc: 0.930000; val_acc: 0.885135\n",
      "(Iteration 216001 / 360000) loss: -0.000000\n",
      "(Iteration 216101 / 360000) loss: -0.000000\n",
      "(Iteration 216201 / 360000) loss: -0.000000\n",
      "(Iteration 216301 / 360000) loss: -0.000000\n",
      "(Iteration 216401 / 360000) loss: -0.000000\n",
      "(Iteration 216501 / 360000) loss: -0.000000\n",
      "(Iteration 216601 / 360000) loss: -0.000000\n",
      "(Iteration 216701 / 360000) loss: -0.000000\n",
      "(Iteration 216801 / 360000) loss: -0.000000\n",
      "(Iteration 216901 / 360000) loss: -0.000000\n",
      "(Iteration 217001 / 360000) loss: -0.000000\n",
      "(Iteration 217101 / 360000) loss: -0.000000\n",
      "(Iteration 217201 / 360000) loss: -0.000000\n",
      "(Iteration 217301 / 360000) loss: -0.000000\n",
      "(Iteration 217401 / 360000) loss: -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 217501 / 360000) loss: -0.000000\n",
      "(Iteration 217601 / 360000) loss: -0.000000\n",
      "(Iteration 217701 / 360000) loss: -0.000000\n",
      "(Iteration 217801 / 360000) loss: -0.000000\n",
      "(Iteration 217901 / 360000) loss: -0.000000\n",
      "(Iteration 218001 / 360000) loss: 1804.717676\n",
      "(Iteration 218101 / 360000) loss: -0.000000\n",
      "(Iteration 218201 / 360000) loss: -0.000000\n",
      "(Iteration 218301 / 360000) loss: 175.866170\n",
      "(Iteration 218401 / 360000) loss: -0.000000\n",
      "(Iteration 218501 / 360000) loss: -0.000000\n",
      "(Iteration 218601 / 360000) loss: -0.000000\n",
      "(Iteration 218701 / 360000) loss: -0.000000\n",
      "(Iteration 218801 / 360000) loss: -0.000000\n",
      "(Iteration 218901 / 360000) loss: -0.000000\n",
      "(Iteration 219001 / 360000) loss: -0.000000\n",
      "(Iteration 219101 / 360000) loss: -0.000000\n",
      "(Iteration 219201 / 360000) loss: -0.000000\n",
      "(Iteration 219301 / 360000) loss: -0.000000\n",
      "(Iteration 219401 / 360000) loss: 791.859826\n",
      "(Iteration 219501 / 360000) loss: -0.000000\n",
      "(Epoch 61 / 100) train acc: 0.927000; val_acc: 0.885135\n",
      "(Iteration 219601 / 360000) loss: -0.000000\n",
      "(Iteration 219701 / 360000) loss: -0.000000\n",
      "(Iteration 219801 / 360000) loss: 184.629122\n",
      "(Iteration 219901 / 360000) loss: -0.000000\n",
      "(Iteration 220001 / 360000) loss: -0.000000\n",
      "(Iteration 220101 / 360000) loss: -0.000000\n",
      "(Iteration 220201 / 360000) loss: -0.000000\n",
      "(Iteration 220301 / 360000) loss: -0.000000\n",
      "(Iteration 220401 / 360000) loss: -0.000000\n",
      "(Iteration 220501 / 360000) loss: -0.000000\n",
      "(Iteration 220601 / 360000) loss: -0.000000\n",
      "(Iteration 220701 / 360000) loss: 556.442213\n",
      "(Iteration 220801 / 360000) loss: -0.000000\n",
      "(Iteration 220901 / 360000) loss: -0.000000\n",
      "(Iteration 221001 / 360000) loss: -0.000000\n",
      "(Iteration 221101 / 360000) loss: -0.000000\n",
      "(Iteration 221201 / 360000) loss: -0.000000\n",
      "(Iteration 221301 / 360000) loss: -0.000000\n",
      "(Iteration 221401 / 360000) loss: -0.000000\n",
      "(Iteration 221501 / 360000) loss: 427.051015\n",
      "(Iteration 221601 / 360000) loss: -0.000000\n",
      "(Iteration 221701 / 360000) loss: -0.000000\n",
      "(Iteration 221801 / 360000) loss: -0.000000\n",
      "(Iteration 221901 / 360000) loss: -0.000000\n",
      "(Iteration 222001 / 360000) loss: -0.000000\n",
      "(Iteration 222101 / 360000) loss: -0.000000\n",
      "(Iteration 222201 / 360000) loss: -0.000000\n",
      "(Iteration 222301 / 360000) loss: -0.000000\n",
      "(Iteration 222401 / 360000) loss: -0.000000\n",
      "(Iteration 222501 / 360000) loss: -0.000000\n",
      "(Iteration 222601 / 360000) loss: 297.056185\n",
      "(Iteration 222701 / 360000) loss: 0.000000\n",
      "(Iteration 222801 / 360000) loss: -0.000000\n",
      "(Iteration 222901 / 360000) loss: -0.000000\n",
      "(Iteration 223001 / 360000) loss: -0.000000\n",
      "(Iteration 223101 / 360000) loss: -0.000000\n",
      "(Epoch 62 / 100) train acc: 0.930000; val_acc: 0.885135\n",
      "(Iteration 223201 / 360000) loss: -0.000000\n",
      "(Iteration 223301 / 360000) loss: 1116.093193\n",
      "(Iteration 223401 / 360000) loss: 39.914581\n",
      "(Iteration 223501 / 360000) loss: -0.000000\n",
      "(Iteration 223601 / 360000) loss: -0.000000\n",
      "(Iteration 223701 / 360000) loss: -0.000000\n",
      "(Iteration 223801 / 360000) loss: -0.000000\n",
      "(Iteration 223901 / 360000) loss: -0.000000\n",
      "(Iteration 224001 / 360000) loss: -0.000000\n",
      "(Iteration 224101 / 360000) loss: -0.000000\n",
      "(Iteration 224201 / 360000) loss: -0.000000\n",
      "(Iteration 224301 / 360000) loss: -0.000000\n",
      "(Iteration 224401 / 360000) loss: -0.000000\n",
      "(Iteration 224501 / 360000) loss: -0.000000\n",
      "(Iteration 224601 / 360000) loss: 1458.170443\n",
      "(Iteration 224701 / 360000) loss: -0.000000\n",
      "(Iteration 224801 / 360000) loss: -0.000000\n",
      "(Iteration 224901 / 360000) loss: -0.000000\n",
      "(Iteration 225001 / 360000) loss: -0.000000\n",
      "(Iteration 225101 / 360000) loss: -0.000000\n",
      "(Iteration 225201 / 360000) loss: -0.000000\n",
      "(Iteration 225301 / 360000) loss: -0.000000\n",
      "(Iteration 225401 / 360000) loss: -0.000000\n",
      "(Iteration 225501 / 360000) loss: -0.000000\n",
      "(Iteration 225601 / 360000) loss: 556.621237\n",
      "(Iteration 225701 / 360000) loss: -0.000000\n",
      "(Iteration 225801 / 360000) loss: -0.000000\n",
      "(Iteration 225901 / 360000) loss: -0.000000\n",
      "(Iteration 226001 / 360000) loss: -0.000000\n",
      "(Iteration 226101 / 360000) loss: -0.000000\n",
      "(Iteration 226201 / 360000) loss: -0.000000\n",
      "(Iteration 226301 / 360000) loss: -0.000000\n",
      "(Iteration 226401 / 360000) loss: -0.000000\n",
      "(Iteration 226501 / 360000) loss: -0.000000\n",
      "(Iteration 226601 / 360000) loss: -0.000000\n",
      "(Iteration 226701 / 360000) loss: -0.000000\n",
      "(Epoch 63 / 100) train acc: 0.915000; val_acc: 0.885135\n",
      "(Iteration 226801 / 360000) loss: -0.000000\n",
      "(Iteration 226901 / 360000) loss: -0.000000\n",
      "(Iteration 227001 / 360000) loss: -0.000000\n",
      "(Iteration 227101 / 360000) loss: -0.000000\n",
      "(Iteration 227201 / 360000) loss: -0.000000\n",
      "(Iteration 227301 / 360000) loss: -0.000000\n",
      "(Iteration 227401 / 360000) loss: -0.000000\n",
      "(Iteration 227501 / 360000) loss: -0.000000\n",
      "(Iteration 227601 / 360000) loss: -0.000000\n",
      "(Iteration 227701 / 360000) loss: -0.000000\n",
      "(Iteration 227801 / 360000) loss: -0.000000\n",
      "(Iteration 227901 / 360000) loss: -0.000000\n",
      "(Iteration 228001 / 360000) loss: 285.386167\n",
      "(Iteration 228101 / 360000) loss: -0.000000\n",
      "(Iteration 228201 / 360000) loss: -0.000000\n",
      "(Iteration 228301 / 360000) loss: -0.000000\n",
      "(Iteration 228401 / 360000) loss: -0.000000\n",
      "(Iteration 228501 / 360000) loss: 0.000001\n",
      "(Iteration 228601 / 360000) loss: -0.000000\n",
      "(Iteration 228701 / 360000) loss: -0.000000\n",
      "(Iteration 228801 / 360000) loss: -0.000000\n",
      "(Iteration 228901 / 360000) loss: -0.000000\n",
      "(Iteration 229001 / 360000) loss: -0.000000\n",
      "(Iteration 229101 / 360000) loss: -0.000000\n",
      "(Iteration 229201 / 360000) loss: -0.000000\n",
      "(Iteration 229301 / 360000) loss: -0.000000\n",
      "(Iteration 229401 / 360000) loss: 602.478097\n",
      "(Iteration 229501 / 360000) loss: -0.000000\n",
      "(Iteration 229601 / 360000) loss: -0.000000\n",
      "(Iteration 229701 / 360000) loss: -0.000000\n",
      "(Iteration 229801 / 360000) loss: -0.000000\n",
      "(Iteration 229901 / 360000) loss: -0.000000\n",
      "(Iteration 230001 / 360000) loss: -0.000000\n",
      "(Iteration 230101 / 360000) loss: 366.233799\n",
      "(Iteration 230201 / 360000) loss: -0.000000\n",
      "(Iteration 230301 / 360000) loss: -0.000000\n",
      "(Epoch 64 / 100) train acc: 0.916000; val_acc: 0.885135\n",
      "(Iteration 230401 / 360000) loss: -0.000000\n",
      "(Iteration 230501 / 360000) loss: -0.000000\n",
      "(Iteration 230601 / 360000) loss: 285.366475\n",
      "(Iteration 230701 / 360000) loss: -0.000000\n",
      "(Iteration 230801 / 360000) loss: -0.000000\n",
      "(Iteration 230901 / 360000) loss: -0.000000\n",
      "(Iteration 231001 / 360000) loss: -0.000000\n",
      "(Iteration 231101 / 360000) loss: -0.000000\n",
      "(Iteration 231201 / 360000) loss: -0.000000\n",
      "(Iteration 231301 / 360000) loss: -0.000000\n",
      "(Iteration 231401 / 360000) loss: -0.000000\n",
      "(Iteration 231501 / 360000) loss: -0.000000\n",
      "(Iteration 231601 / 360000) loss: -0.000000\n",
      "(Iteration 231701 / 360000) loss: -0.000000\n",
      "(Iteration 231801 / 360000) loss: -0.000000\n",
      "(Iteration 231901 / 360000) loss: -0.000000\n",
      "(Iteration 232001 / 360000) loss: -0.000000\n",
      "(Iteration 232101 / 360000) loss: -0.000000\n",
      "(Iteration 232201 / 360000) loss: -0.000000\n",
      "(Iteration 232301 / 360000) loss: -0.000000\n",
      "(Iteration 232401 / 360000) loss: -0.000000\n",
      "(Iteration 232501 / 360000) loss: -0.000000\n",
      "(Iteration 232601 / 360000) loss: -0.000000\n",
      "(Iteration 232701 / 360000) loss: -0.000000\n",
      "(Iteration 232801 / 360000) loss: -0.000000\n",
      "(Iteration 232901 / 360000) loss: -0.000000\n",
      "(Iteration 233001 / 360000) loss: -0.000000\n",
      "(Iteration 233101 / 360000) loss: -0.000000\n",
      "(Iteration 233201 / 360000) loss: -0.000000\n",
      "(Iteration 233301 / 360000) loss: -0.000000\n",
      "(Iteration 233401 / 360000) loss: -0.000000\n",
      "(Iteration 233501 / 360000) loss: -0.000000\n",
      "(Iteration 233601 / 360000) loss: -0.000000\n",
      "(Iteration 233701 / 360000) loss: -0.000000\n",
      "(Iteration 233801 / 360000) loss: -0.000000\n",
      "(Iteration 233901 / 360000) loss: -0.000000\n",
      "(Epoch 65 / 100) train acc: 0.941000; val_acc: 0.885135\n",
      "(Iteration 234001 / 360000) loss: -0.000000\n",
      "(Iteration 234101 / 360000) loss: -0.000000\n",
      "(Iteration 234201 / 360000) loss: -0.000000\n",
      "(Iteration 234301 / 360000) loss: -0.000000\n",
      "(Iteration 234401 / 360000) loss: -0.000000\n",
      "(Iteration 234501 / 360000) loss: -0.000000\n",
      "(Iteration 234601 / 360000) loss: -0.000000\n",
      "(Iteration 234701 / 360000) loss: -0.000000\n",
      "(Iteration 234801 / 360000) loss: 761.636641\n",
      "(Iteration 234901 / 360000) loss: -0.000000\n",
      "(Iteration 235001 / 360000) loss: -0.000000\n",
      "(Iteration 235101 / 360000) loss: -0.000000\n",
      "(Iteration 235201 / 360000) loss: -0.000000\n",
      "(Iteration 235301 / 360000) loss: -0.000000\n",
      "(Iteration 235401 / 360000) loss: -0.000000\n",
      "(Iteration 235501 / 360000) loss: -0.000000\n",
      "(Iteration 235601 / 360000) loss: -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 235701 / 360000) loss: -0.000000\n",
      "(Iteration 235801 / 360000) loss: -0.000000\n",
      "(Iteration 235901 / 360000) loss: -0.000000\n",
      "(Iteration 236001 / 360000) loss: 0.000000\n",
      "(Iteration 236101 / 360000) loss: -0.000000\n",
      "(Iteration 236201 / 360000) loss: -0.000000\n",
      "(Iteration 236301 / 360000) loss: -0.000000\n",
      "(Iteration 236401 / 360000) loss: -0.000000\n",
      "(Iteration 236501 / 360000) loss: -0.000000\n",
      "(Iteration 236601 / 360000) loss: -0.000000\n",
      "(Iteration 236701 / 360000) loss: -0.000000\n",
      "(Iteration 236801 / 360000) loss: -0.000000\n",
      "(Iteration 236901 / 360000) loss: -0.000000\n",
      "(Iteration 237001 / 360000) loss: -0.000000\n",
      "(Iteration 237101 / 360000) loss: -0.000000\n",
      "(Iteration 237201 / 360000) loss: -0.000000\n",
      "(Iteration 237301 / 360000) loss: -0.000000\n",
      "(Iteration 237401 / 360000) loss: -0.000000\n",
      "(Iteration 237501 / 360000) loss: -0.000000\n",
      "(Epoch 66 / 100) train acc: 0.922000; val_acc: 0.885135\n",
      "(Iteration 237601 / 360000) loss: -0.000000\n",
      "(Iteration 237701 / 360000) loss: -0.000000\n",
      "(Iteration 237801 / 360000) loss: -0.000000\n",
      "(Iteration 237901 / 360000) loss: -0.000000\n",
      "(Iteration 238001 / 360000) loss: -0.000000\n",
      "(Iteration 238101 / 360000) loss: -0.000000\n",
      "(Iteration 238201 / 360000) loss: -0.000000\n",
      "(Iteration 238301 / 360000) loss: -0.000000\n",
      "(Iteration 238401 / 360000) loss: -0.000000\n",
      "(Iteration 238501 / 360000) loss: -0.000000\n",
      "(Iteration 238601 / 360000) loss: -0.000000\n",
      "(Iteration 238701 / 360000) loss: 791.824680\n",
      "(Iteration 238801 / 360000) loss: -0.000000\n",
      "(Iteration 238901 / 360000) loss: -0.000000\n",
      "(Iteration 239001 / 360000) loss: -0.000000\n",
      "(Iteration 239101 / 360000) loss: 1411.278473\n",
      "(Iteration 239201 / 360000) loss: -0.000000\n",
      "(Iteration 239301 / 360000) loss: -0.000000\n",
      "(Iteration 239401 / 360000) loss: -0.000000\n",
      "(Iteration 239501 / 360000) loss: -0.000000\n",
      "(Iteration 239601 / 360000) loss: -0.000000\n",
      "(Iteration 239701 / 360000) loss: -0.000000\n",
      "(Iteration 239801 / 360000) loss: -0.000000\n",
      "(Iteration 239901 / 360000) loss: -0.000000\n",
      "(Iteration 240001 / 360000) loss: -0.000000\n",
      "(Iteration 240101 / 360000) loss: 107.597905\n",
      "(Iteration 240201 / 360000) loss: -0.000000\n",
      "(Iteration 240301 / 360000) loss: -0.000000\n",
      "(Iteration 240401 / 360000) loss: -0.000000\n",
      "(Iteration 240501 / 360000) loss: -0.000000\n",
      "(Iteration 240601 / 360000) loss: -0.000000\n",
      "(Iteration 240701 / 360000) loss: -0.000000\n",
      "(Iteration 240801 / 360000) loss: -0.000000\n",
      "(Iteration 240901 / 360000) loss: -0.000000\n",
      "(Iteration 241001 / 360000) loss: -0.000000\n",
      "(Iteration 241101 / 360000) loss: -0.000000\n",
      "(Epoch 67 / 100) train acc: 0.930000; val_acc: 0.885135\n",
      "(Iteration 241201 / 360000) loss: -0.000000\n",
      "(Iteration 241301 / 360000) loss: -0.000000\n",
      "(Iteration 241401 / 360000) loss: -0.000000\n",
      "(Iteration 241501 / 360000) loss: -0.000000\n",
      "(Iteration 241601 / 360000) loss: -0.000000\n",
      "(Iteration 241701 / 360000) loss: -0.000000\n",
      "(Iteration 241801 / 360000) loss: -0.000000\n",
      "(Iteration 241901 / 360000) loss: -0.000000\n",
      "(Iteration 242001 / 360000) loss: -0.000000\n",
      "(Iteration 242101 / 360000) loss: -0.000000\n",
      "(Iteration 242201 / 360000) loss: -0.000000\n",
      "(Iteration 242301 / 360000) loss: 1940.087776\n",
      "(Iteration 242401 / 360000) loss: -0.000000\n",
      "(Iteration 242501 / 360000) loss: -0.000000\n",
      "(Iteration 242601 / 360000) loss: -0.000000\n",
      "(Iteration 242701 / 360000) loss: -0.000000\n",
      "(Iteration 242801 / 360000) loss: -0.000000\n",
      "(Iteration 242901 / 360000) loss: -0.000000\n",
      "(Iteration 243001 / 360000) loss: -0.000000\n",
      "(Iteration 243101 / 360000) loss: -0.000000\n",
      "(Iteration 243201 / 360000) loss: -0.000000\n",
      "(Iteration 243301 / 360000) loss: -0.000000\n",
      "(Iteration 243401 / 360000) loss: -0.000000\n",
      "(Iteration 243501 / 360000) loss: -0.000000\n",
      "(Iteration 243601 / 360000) loss: -0.000000\n",
      "(Iteration 243701 / 360000) loss: -0.000000\n",
      "(Iteration 243801 / 360000) loss: -0.000000\n",
      "(Iteration 243901 / 360000) loss: -0.000000\n",
      "(Iteration 244001 / 360000) loss: -0.000000\n",
      "(Iteration 244101 / 360000) loss: -0.000000\n",
      "(Iteration 244201 / 360000) loss: -0.000000\n",
      "(Iteration 244301 / 360000) loss: -0.000000\n",
      "(Iteration 244401 / 360000) loss: -0.000000\n",
      "(Iteration 244501 / 360000) loss: -0.000000\n",
      "(Iteration 244601 / 360000) loss: -0.000000\n",
      "(Iteration 244701 / 360000) loss: -0.000000\n",
      "(Epoch 68 / 100) train acc: 0.915000; val_acc: 0.885135\n",
      "(Iteration 244801 / 360000) loss: -0.000000\n",
      "(Iteration 244901 / 360000) loss: -0.000000\n",
      "(Iteration 245001 / 360000) loss: -0.000000\n",
      "(Iteration 245101 / 360000) loss: -0.000000\n",
      "(Iteration 245201 / 360000) loss: -0.000000\n",
      "(Iteration 245301 / 360000) loss: -0.000000\n",
      "(Iteration 245401 / 360000) loss: -0.000000\n",
      "(Iteration 245501 / 360000) loss: -0.000000\n",
      "(Iteration 245601 / 360000) loss: -0.000000\n",
      "(Iteration 245701 / 360000) loss: -0.000000\n",
      "(Iteration 245801 / 360000) loss: -0.000000\n",
      "(Iteration 245901 / 360000) loss: -0.000000\n",
      "(Iteration 246001 / 360000) loss: -0.000000\n",
      "(Iteration 246101 / 360000) loss: -0.000000\n",
      "(Iteration 246201 / 360000) loss: -0.000000\n",
      "(Iteration 246301 / 360000) loss: -0.000000\n",
      "(Iteration 246401 / 360000) loss: -0.000000\n",
      "(Iteration 246501 / 360000) loss: -0.000000\n",
      "(Iteration 246601 / 360000) loss: -0.000000\n",
      "(Iteration 246701 / 360000) loss: -0.000000\n",
      "(Iteration 246801 / 360000) loss: -0.000000\n",
      "(Iteration 246901 / 360000) loss: -0.000000\n",
      "(Iteration 247001 / 360000) loss: -0.000000\n",
      "(Iteration 247101 / 360000) loss: -0.000000\n",
      "(Iteration 247201 / 360000) loss: 1994.040524\n",
      "(Iteration 247301 / 360000) loss: -0.000000\n",
      "(Iteration 247401 / 360000) loss: -0.000000\n",
      "(Iteration 247501 / 360000) loss: 126.286770\n",
      "(Iteration 247601 / 360000) loss: -0.000000\n",
      "(Iteration 247701 / 360000) loss: -0.000000\n",
      "(Iteration 247801 / 360000) loss: 141.922690\n",
      "(Iteration 247901 / 360000) loss: -0.000000\n",
      "(Iteration 248001 / 360000) loss: -0.000000\n",
      "(Iteration 248101 / 360000) loss: -0.000000\n",
      "(Iteration 248201 / 360000) loss: -0.000000\n",
      "(Iteration 248301 / 360000) loss: -0.000000\n",
      "(Epoch 69 / 100) train acc: 0.931000; val_acc: 0.885135\n",
      "(Iteration 248401 / 360000) loss: -0.000000\n",
      "(Iteration 248501 / 360000) loss: -0.000000\n",
      "(Iteration 248601 / 360000) loss: -0.000000\n",
      "(Iteration 248701 / 360000) loss: -0.000000\n",
      "(Iteration 248801 / 360000) loss: -0.000000\n",
      "(Iteration 248901 / 360000) loss: -0.000000\n",
      "(Iteration 249001 / 360000) loss: -0.000000\n",
      "(Iteration 249101 / 360000) loss: -0.000000\n",
      "(Iteration 249201 / 360000) loss: -0.000000\n",
      "(Iteration 249301 / 360000) loss: -0.000000\n",
      "(Iteration 249401 / 360000) loss: -0.000000\n",
      "(Iteration 249501 / 360000) loss: -0.000000\n",
      "(Iteration 249601 / 360000) loss: 1114.860424\n",
      "(Iteration 249701 / 360000) loss: -0.000000\n",
      "(Iteration 249801 / 360000) loss: -0.000000\n",
      "(Iteration 249901 / 360000) loss: -0.000000\n",
      "(Iteration 250001 / 360000) loss: -0.000000\n",
      "(Iteration 250101 / 360000) loss: -0.000000\n",
      "(Iteration 250201 / 360000) loss: -0.000000\n",
      "(Iteration 250301 / 360000) loss: -0.000000\n",
      "(Iteration 250401 / 360000) loss: -0.000000\n",
      "(Iteration 250501 / 360000) loss: -0.000000\n",
      "(Iteration 250601 / 360000) loss: -0.000000\n",
      "(Iteration 250701 / 360000) loss: -0.000000\n",
      "(Iteration 250801 / 360000) loss: -0.000000\n",
      "(Iteration 250901 / 360000) loss: -0.000000\n",
      "(Iteration 251001 / 360000) loss: -0.000000\n",
      "(Iteration 251101 / 360000) loss: -0.000000\n",
      "(Iteration 251201 / 360000) loss: -0.000000\n",
      "(Iteration 251301 / 360000) loss: -0.000000\n",
      "(Iteration 251401 / 360000) loss: -0.000000\n",
      "(Iteration 251501 / 360000) loss: -0.000000\n",
      "(Iteration 251601 / 360000) loss: 280.065119\n",
      "(Iteration 251701 / 360000) loss: -0.000000\n",
      "(Iteration 251801 / 360000) loss: -0.000000\n",
      "(Iteration 251901 / 360000) loss: -0.000000\n",
      "(Epoch 70 / 100) train acc: 0.921000; val_acc: 0.885135\n",
      "(Iteration 252001 / 360000) loss: -0.000000\n",
      "(Iteration 252101 / 360000) loss: -0.000000\n",
      "(Iteration 252201 / 360000) loss: -0.000000\n",
      "(Iteration 252301 / 360000) loss: 12.282562\n",
      "(Iteration 252401 / 360000) loss: -0.000000\n",
      "(Iteration 252501 / 360000) loss: -0.000000\n",
      "(Iteration 252601 / 360000) loss: -0.000000\n",
      "(Iteration 252701 / 360000) loss: -0.000000\n",
      "(Iteration 252801 / 360000) loss: -0.000000\n",
      "(Iteration 252901 / 360000) loss: -0.000000\n",
      "(Iteration 253001 / 360000) loss: -0.000000\n",
      "(Iteration 253101 / 360000) loss: -0.000000\n",
      "(Iteration 253201 / 360000) loss: -0.000000\n",
      "(Iteration 253301 / 360000) loss: -0.000000\n",
      "(Iteration 253401 / 360000) loss: -0.000000\n",
      "(Iteration 253501 / 360000) loss: 1533.495915\n",
      "(Iteration 253601 / 360000) loss: -0.000000\n",
      "(Iteration 253701 / 360000) loss: -0.000000\n",
      "(Iteration 253801 / 360000) loss: -0.000000\n",
      "(Iteration 253901 / 360000) loss: -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 254001 / 360000) loss: 357.010339\n",
      "(Iteration 254101 / 360000) loss: -0.000000\n",
      "(Iteration 254201 / 360000) loss: -0.000000\n",
      "(Iteration 254301 / 360000) loss: -0.000000\n",
      "(Iteration 254401 / 360000) loss: 1.562382\n",
      "(Iteration 254501 / 360000) loss: 262.091445\n",
      "(Iteration 254601 / 360000) loss: -0.000000\n",
      "(Iteration 254701 / 360000) loss: -0.000000\n",
      "(Iteration 254801 / 360000) loss: -0.000000\n",
      "(Iteration 254901 / 360000) loss: -0.000000\n",
      "(Iteration 255001 / 360000) loss: -0.000000\n",
      "(Iteration 255101 / 360000) loss: -0.000000\n",
      "(Iteration 255201 / 360000) loss: -0.000000\n",
      "(Iteration 255301 / 360000) loss: -0.000000\n",
      "(Iteration 255401 / 360000) loss: -0.000000\n",
      "(Iteration 255501 / 360000) loss: -0.000000\n",
      "(Epoch 71 / 100) train acc: 0.934000; val_acc: 0.885135\n",
      "(Iteration 255601 / 360000) loss: -0.000000\n",
      "(Iteration 255701 / 360000) loss: -0.000000\n",
      "(Iteration 255801 / 360000) loss: -0.000000\n",
      "(Iteration 255901 / 360000) loss: -0.000000\n",
      "(Iteration 256001 / 360000) loss: -0.000000\n",
      "(Iteration 256101 / 360000) loss: -0.000000\n",
      "(Iteration 256201 / 360000) loss: -0.000000\n",
      "(Iteration 256301 / 360000) loss: -0.000000\n",
      "(Iteration 256401 / 360000) loss: -0.000000\n",
      "(Iteration 256501 / 360000) loss: -0.000000\n",
      "(Iteration 256601 / 360000) loss: -0.000000\n",
      "(Iteration 256701 / 360000) loss: -0.000000\n",
      "(Iteration 256801 / 360000) loss: -0.000000\n",
      "(Iteration 256901 / 360000) loss: -0.000000\n",
      "(Iteration 257001 / 360000) loss: -0.000000\n",
      "(Iteration 257101 / 360000) loss: -0.000000\n",
      "(Iteration 257201 / 360000) loss: -0.000000\n",
      "(Iteration 257301 / 360000) loss: -0.000000\n",
      "(Iteration 257401 / 360000) loss: -0.000000\n",
      "(Iteration 257501 / 360000) loss: -0.000000\n",
      "(Iteration 257601 / 360000) loss: -0.000000\n",
      "(Iteration 257701 / 360000) loss: -0.000000\n",
      "(Iteration 257801 / 360000) loss: -0.000000\n",
      "(Iteration 257901 / 360000) loss: -0.000000\n",
      "(Iteration 258001 / 360000) loss: -0.000000\n",
      "(Iteration 258101 / 360000) loss: -0.000000\n",
      "(Iteration 258201 / 360000) loss: -0.000000\n",
      "(Iteration 258301 / 360000) loss: -0.000000\n",
      "(Iteration 258401 / 360000) loss: -0.000000\n",
      "(Iteration 258501 / 360000) loss: -0.000000\n",
      "(Iteration 258601 / 360000) loss: -0.000000\n",
      "(Iteration 258701 / 360000) loss: -0.000000\n",
      "(Iteration 258801 / 360000) loss: -0.000000\n",
      "(Iteration 258901 / 360000) loss: -0.000000\n",
      "(Iteration 259001 / 360000) loss: -0.000000\n",
      "(Iteration 259101 / 360000) loss: -0.000000\n",
      "(Epoch 72 / 100) train acc: 0.926000; val_acc: 0.885135\n",
      "(Iteration 259201 / 360000) loss: -0.000000\n",
      "(Iteration 259301 / 360000) loss: -0.000000\n",
      "(Iteration 259401 / 360000) loss: -0.000000\n",
      "(Iteration 259501 / 360000) loss: -0.000000\n",
      "(Iteration 259601 / 360000) loss: -0.000000\n",
      "(Iteration 259701 / 360000) loss: -0.000000\n",
      "(Iteration 259801 / 360000) loss: -0.000000\n",
      "(Iteration 259901 / 360000) loss: -0.000000\n",
      "(Iteration 260001 / 360000) loss: -0.000000\n",
      "(Iteration 260101 / 360000) loss: 69.301907\n",
      "(Iteration 260201 / 360000) loss: -0.000000\n",
      "(Iteration 260301 / 360000) loss: -0.000000\n",
      "(Iteration 260401 / 360000) loss: -0.000000\n",
      "(Iteration 260501 / 360000) loss: -0.000000\n",
      "(Iteration 260601 / 360000) loss: -0.000000\n",
      "(Iteration 260701 / 360000) loss: -0.000000\n",
      "(Iteration 260801 / 360000) loss: -0.000000\n",
      "(Iteration 260901 / 360000) loss: -0.000000\n",
      "(Iteration 261001 / 360000) loss: -0.000000\n",
      "(Iteration 261101 / 360000) loss: -0.000000\n",
      "(Iteration 261201 / 360000) loss: -0.000000\n",
      "(Iteration 261301 / 360000) loss: -0.000000\n",
      "(Iteration 261401 / 360000) loss: 107.515016\n",
      "(Iteration 261501 / 360000) loss: -0.000000\n",
      "(Iteration 261601 / 360000) loss: -0.000000\n",
      "(Iteration 261701 / 360000) loss: -0.000000\n",
      "(Iteration 261801 / 360000) loss: 502.742080\n",
      "(Iteration 261901 / 360000) loss: -0.000000\n",
      "(Iteration 262001 / 360000) loss: -0.000000\n",
      "(Iteration 262101 / 360000) loss: -0.000000\n",
      "(Iteration 262201 / 360000) loss: 983.037750\n",
      "(Iteration 262301 / 360000) loss: -0.000000\n",
      "(Iteration 262401 / 360000) loss: -0.000000\n",
      "(Iteration 262501 / 360000) loss: -0.000000\n",
      "(Iteration 262601 / 360000) loss: -0.000000\n",
      "(Iteration 262701 / 360000) loss: -0.000000\n",
      "(Epoch 73 / 100) train acc: 0.925000; val_acc: 0.885135\n",
      "(Iteration 262801 / 360000) loss: -0.000000\n",
      "(Iteration 262901 / 360000) loss: 216.365341\n",
      "(Iteration 263001 / 360000) loss: -0.000000\n",
      "(Iteration 263101 / 360000) loss: -0.000000\n",
      "(Iteration 263201 / 360000) loss: -0.000000\n",
      "(Iteration 263301 / 360000) loss: -0.000000\n",
      "(Iteration 263401 / 360000) loss: -0.000000\n",
      "(Iteration 263501 / 360000) loss: -0.000000\n",
      "(Iteration 263601 / 360000) loss: -0.000000\n",
      "(Iteration 263701 / 360000) loss: -0.000000\n",
      "(Iteration 263801 / 360000) loss: -0.000000\n",
      "(Iteration 263901 / 360000) loss: 759.717296\n",
      "(Iteration 264001 / 360000) loss: -0.000000\n",
      "(Iteration 264101 / 360000) loss: 970.733797\n",
      "(Iteration 264201 / 360000) loss: -0.000000\n",
      "(Iteration 264301 / 360000) loss: -0.000000\n",
      "(Iteration 264401 / 360000) loss: -0.000000\n",
      "(Iteration 264501 / 360000) loss: -0.000000\n",
      "(Iteration 264601 / 360000) loss: -0.000000\n",
      "(Iteration 264701 / 360000) loss: -0.000000\n",
      "(Iteration 264801 / 360000) loss: -0.000000\n",
      "(Iteration 264901 / 360000) loss: -0.000000\n",
      "(Iteration 265001 / 360000) loss: -0.000000\n",
      "(Iteration 265101 / 360000) loss: -0.000000\n",
      "(Iteration 265201 / 360000) loss: -0.000000\n",
      "(Iteration 265301 / 360000) loss: -0.000000\n",
      "(Iteration 265401 / 360000) loss: -0.000000\n",
      "(Iteration 265501 / 360000) loss: -0.000000\n",
      "(Iteration 265601 / 360000) loss: -0.000000\n",
      "(Iteration 265701 / 360000) loss: -0.000000\n",
      "(Iteration 265801 / 360000) loss: -0.000000\n",
      "(Iteration 265901 / 360000) loss: -0.000000\n",
      "(Iteration 266001 / 360000) loss: -0.000000\n",
      "(Iteration 266101 / 360000) loss: -0.000000\n",
      "(Iteration 266201 / 360000) loss: -0.000000\n",
      "(Iteration 266301 / 360000) loss: -0.000000\n",
      "(Epoch 74 / 100) train acc: 0.922000; val_acc: 0.885135\n",
      "(Iteration 266401 / 360000) loss: -0.000000\n",
      "(Iteration 266501 / 360000) loss: -0.000000\n",
      "(Iteration 266601 / 360000) loss: -0.000000\n",
      "(Iteration 266701 / 360000) loss: -0.000000\n",
      "(Iteration 266801 / 360000) loss: -0.000000\n",
      "(Iteration 266901 / 360000) loss: -0.000000\n",
      "(Iteration 267001 / 360000) loss: -0.000000\n",
      "(Iteration 267101 / 360000) loss: -0.000000\n",
      "(Iteration 267201 / 360000) loss: -0.000000\n",
      "(Iteration 267301 / 360000) loss: -0.000000\n",
      "(Iteration 267401 / 360000) loss: -0.000000\n",
      "(Iteration 267501 / 360000) loss: -0.000000\n",
      "(Iteration 267601 / 360000) loss: -0.000000\n",
      "(Iteration 267701 / 360000) loss: -0.000000\n",
      "(Iteration 267801 / 360000) loss: -0.000000\n",
      "(Iteration 267901 / 360000) loss: -0.000000\n",
      "(Iteration 268001 / 360000) loss: -0.000000\n",
      "(Iteration 268101 / 360000) loss: -0.000000\n",
      "(Iteration 268201 / 360000) loss: -0.000000\n",
      "(Iteration 268301 / 360000) loss: -0.000000\n",
      "(Iteration 268401 / 360000) loss: 611.229884\n",
      "(Iteration 268501 / 360000) loss: -0.000000\n",
      "(Iteration 268601 / 360000) loss: -0.000000\n",
      "(Iteration 268701 / 360000) loss: -0.000000\n",
      "(Iteration 268801 / 360000) loss: -0.000000\n",
      "(Iteration 268901 / 360000) loss: -0.000000\n",
      "(Iteration 269001 / 360000) loss: -0.000000\n",
      "(Iteration 269101 / 360000) loss: -0.000000\n",
      "(Iteration 269201 / 360000) loss: -0.000000\n",
      "(Iteration 269301 / 360000) loss: -0.000000\n",
      "(Iteration 269401 / 360000) loss: -0.000000\n",
      "(Iteration 269501 / 360000) loss: -0.000000\n",
      "(Iteration 269601 / 360000) loss: -0.000000\n",
      "(Iteration 269701 / 360000) loss: -0.000000\n",
      "(Iteration 269801 / 360000) loss: -0.000000\n",
      "(Iteration 269901 / 360000) loss: -0.000000\n",
      "(Epoch 75 / 100) train acc: 0.912000; val_acc: 0.885135\n",
      "(Iteration 270001 / 360000) loss: -0.000000\n",
      "(Iteration 270101 / 360000) loss: 3797.030737\n",
      "(Iteration 270201 / 360000) loss: -0.000000\n",
      "(Iteration 270301 / 360000) loss: -0.000000\n",
      "(Iteration 270401 / 360000) loss: -0.000000\n",
      "(Iteration 270501 / 360000) loss: -0.000000\n",
      "(Iteration 270601 / 360000) loss: -0.000000\n",
      "(Iteration 270701 / 360000) loss: -0.000000\n",
      "(Iteration 270801 / 360000) loss: -0.000000\n",
      "(Iteration 270901 / 360000) loss: -0.000000\n",
      "(Iteration 271001 / 360000) loss: -0.000000\n",
      "(Iteration 271101 / 360000) loss: -0.000000\n",
      "(Iteration 271201 / 360000) loss: -0.000000\n",
      "(Iteration 271301 / 360000) loss: -0.000000\n",
      "(Iteration 271401 / 360000) loss: 71.150932\n",
      "(Iteration 271501 / 360000) loss: -0.000000\n",
      "(Iteration 271601 / 360000) loss: -0.000000\n",
      "(Iteration 271701 / 360000) loss: -0.000000\n",
      "(Iteration 271801 / 360000) loss: -0.000000\n",
      "(Iteration 271901 / 360000) loss: -0.000000\n",
      "(Iteration 272001 / 360000) loss: -0.000000\n",
      "(Iteration 272101 / 360000) loss: -0.000000\n",
      "(Iteration 272201 / 360000) loss: -0.000000\n",
      "(Iteration 272301 / 360000) loss: -0.000000\n",
      "(Iteration 272401 / 360000) loss: -0.000000\n",
      "(Iteration 272501 / 360000) loss: -0.000000\n",
      "(Iteration 272601 / 360000) loss: -0.000000\n",
      "(Iteration 272701 / 360000) loss: -0.000000\n",
      "(Iteration 272801 / 360000) loss: -0.000000\n",
      "(Iteration 272901 / 360000) loss: -0.000000\n",
      "(Iteration 273001 / 360000) loss: -0.000000\n",
      "(Iteration 273101 / 360000) loss: -0.000000\n",
      "(Iteration 273201 / 360000) loss: -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 273301 / 360000) loss: -0.000000\n",
      "(Iteration 273401 / 360000) loss: -0.000000\n",
      "(Iteration 273501 / 360000) loss: -0.000000\n",
      "(Epoch 76 / 100) train acc: 0.947000; val_acc: 0.885135\n",
      "(Iteration 273601 / 360000) loss: -0.000000\n",
      "(Iteration 273701 / 360000) loss: -0.000000\n",
      "(Iteration 273801 / 360000) loss: -0.000000\n",
      "(Iteration 273901 / 360000) loss: -0.000000\n",
      "(Iteration 274001 / 360000) loss: -0.000000\n",
      "(Iteration 274101 / 360000) loss: -0.000000\n",
      "(Iteration 274201 / 360000) loss: -0.000000\n",
      "(Iteration 274301 / 360000) loss: -0.000000\n",
      "(Iteration 274401 / 360000) loss: -0.000000\n",
      "(Iteration 274501 / 360000) loss: -0.000000\n",
      "(Iteration 274601 / 360000) loss: -0.000000\n",
      "(Iteration 274701 / 360000) loss: -0.000000\n",
      "(Iteration 274801 / 360000) loss: -0.000000\n",
      "(Iteration 274901 / 360000) loss: -0.000000\n",
      "(Iteration 275001 / 360000) loss: -0.000000\n",
      "(Iteration 275101 / 360000) loss: -0.000000\n",
      "(Iteration 275201 / 360000) loss: 2192.378911\n",
      "(Iteration 275301 / 360000) loss: -0.000000\n",
      "(Iteration 275401 / 360000) loss: 0.000002\n",
      "(Iteration 275501 / 360000) loss: -0.000000\n",
      "(Iteration 275601 / 360000) loss: -0.000000\n",
      "(Iteration 275701 / 360000) loss: -0.000000\n",
      "(Iteration 275801 / 360000) loss: -0.000000\n",
      "(Iteration 275901 / 360000) loss: -0.000000\n",
      "(Iteration 276001 / 360000) loss: -0.000000\n",
      "(Iteration 276101 / 360000) loss: -0.000000\n",
      "(Iteration 276201 / 360000) loss: 238.270320\n",
      "(Iteration 276301 / 360000) loss: -0.000000\n",
      "(Iteration 276401 / 360000) loss: -0.000000\n",
      "(Iteration 276501 / 360000) loss: -0.000000\n",
      "(Iteration 276601 / 360000) loss: -0.000000\n",
      "(Iteration 276701 / 360000) loss: -0.000000\n",
      "(Iteration 276801 / 360000) loss: -0.000000\n",
      "(Iteration 276901 / 360000) loss: -0.000000\n",
      "(Iteration 277001 / 360000) loss: -0.000000\n",
      "(Iteration 277101 / 360000) loss: -0.000000\n",
      "(Epoch 77 / 100) train acc: 0.929000; val_acc: 0.885135\n",
      "(Iteration 277201 / 360000) loss: -0.000000\n",
      "(Iteration 277301 / 360000) loss: -0.000000\n",
      "(Iteration 277401 / 360000) loss: -0.000000\n",
      "(Iteration 277501 / 360000) loss: -0.000000\n",
      "(Iteration 277601 / 360000) loss: -0.000000\n",
      "(Iteration 277701 / 360000) loss: -0.000000\n",
      "(Iteration 277801 / 360000) loss: -0.000000\n",
      "(Iteration 277901 / 360000) loss: -0.000000\n",
      "(Iteration 278001 / 360000) loss: 1687.481779\n",
      "(Iteration 278101 / 360000) loss: -0.000000\n",
      "(Iteration 278201 / 360000) loss: -0.000000\n",
      "(Iteration 278301 / 360000) loss: -0.000000\n",
      "(Iteration 278401 / 360000) loss: -0.000000\n",
      "(Iteration 278501 / 360000) loss: -0.000000\n",
      "(Iteration 278601 / 360000) loss: -0.000000\n",
      "(Iteration 278701 / 360000) loss: -0.000000\n",
      "(Iteration 278801 / 360000) loss: -0.000000\n",
      "(Iteration 278901 / 360000) loss: -0.000000\n",
      "(Iteration 279001 / 360000) loss: -0.000000\n",
      "(Iteration 279101 / 360000) loss: -0.000000\n",
      "(Iteration 279201 / 360000) loss: -0.000000\n",
      "(Iteration 279301 / 360000) loss: -0.000000\n",
      "(Iteration 279401 / 360000) loss: -0.000000\n",
      "(Iteration 279501 / 360000) loss: -0.000000\n",
      "(Iteration 279601 / 360000) loss: -0.000000\n",
      "(Iteration 279701 / 360000) loss: -0.000000\n",
      "(Iteration 279801 / 360000) loss: 1098.065032\n",
      "(Iteration 279901 / 360000) loss: -0.000000\n",
      "(Iteration 280001 / 360000) loss: -0.000000\n",
      "(Iteration 280101 / 360000) loss: -0.000000\n",
      "(Iteration 280201 / 360000) loss: -0.000000\n",
      "(Iteration 280301 / 360000) loss: -0.000000\n",
      "(Iteration 280401 / 360000) loss: -0.000000\n",
      "(Iteration 280501 / 360000) loss: -0.000000\n",
      "(Iteration 280601 / 360000) loss: 1524.127106\n",
      "(Iteration 280701 / 360000) loss: -0.000000\n",
      "(Epoch 78 / 100) train acc: 0.932000; val_acc: 0.885135\n",
      "(Iteration 280801 / 360000) loss: -0.000000\n",
      "(Iteration 280901 / 360000) loss: -0.000000\n",
      "(Iteration 281001 / 360000) loss: -0.000000\n",
      "(Iteration 281101 / 360000) loss: -0.000000\n",
      "(Iteration 281201 / 360000) loss: -0.000000\n",
      "(Iteration 281301 / 360000) loss: -0.000000\n",
      "(Iteration 281401 / 360000) loss: -0.000000\n",
      "(Iteration 281501 / 360000) loss: -0.000000\n",
      "(Iteration 281601 / 360000) loss: -0.000000\n",
      "(Iteration 281701 / 360000) loss: -0.000000\n",
      "(Iteration 281801 / 360000) loss: -0.000000\n",
      "(Iteration 281901 / 360000) loss: -0.000000\n",
      "(Iteration 282001 / 360000) loss: -0.000000\n",
      "(Iteration 282101 / 360000) loss: -0.000000\n",
      "(Iteration 282201 / 360000) loss: -0.000000\n",
      "(Iteration 282301 / 360000) loss: -0.000000\n",
      "(Iteration 282401 / 360000) loss: 41.297296\n",
      "(Iteration 282501 / 360000) loss: -0.000000\n",
      "(Iteration 282601 / 360000) loss: -0.000000\n",
      "(Iteration 282701 / 360000) loss: -0.000000\n",
      "(Iteration 282801 / 360000) loss: -0.000000\n",
      "(Iteration 282901 / 360000) loss: -0.000000\n",
      "(Iteration 283001 / 360000) loss: 0.000000\n",
      "(Iteration 283101 / 360000) loss: -0.000000\n",
      "(Iteration 283201 / 360000) loss: -0.000000\n",
      "(Iteration 283301 / 360000) loss: -0.000000\n",
      "(Iteration 283401 / 360000) loss: -0.000000\n",
      "(Iteration 283501 / 360000) loss: 868.799239\n",
      "(Iteration 283601 / 360000) loss: -0.000000\n",
      "(Iteration 283701 / 360000) loss: -0.000000\n",
      "(Iteration 283801 / 360000) loss: -0.000000\n",
      "(Iteration 283901 / 360000) loss: -0.000000\n",
      "(Iteration 284001 / 360000) loss: -0.000000\n",
      "(Iteration 284101 / 360000) loss: -0.000000\n",
      "(Iteration 284201 / 360000) loss: -0.000000\n",
      "(Iteration 284301 / 360000) loss: -0.000000\n",
      "(Epoch 79 / 100) train acc: 0.934000; val_acc: 0.885135\n",
      "(Iteration 284401 / 360000) loss: -0.000000\n",
      "(Iteration 284501 / 360000) loss: -0.000000\n",
      "(Iteration 284601 / 360000) loss: -0.000000\n",
      "(Iteration 284701 / 360000) loss: -0.000000\n",
      "(Iteration 284801 / 360000) loss: -0.000000\n",
      "(Iteration 284901 / 360000) loss: -0.000000\n",
      "(Iteration 285001 / 360000) loss: 122.940398\n",
      "(Iteration 285101 / 360000) loss: -0.000000\n",
      "(Iteration 285201 / 360000) loss: -0.000000\n",
      "(Iteration 285301 / 360000) loss: -0.000000\n",
      "(Iteration 285401 / 360000) loss: -0.000000\n",
      "(Iteration 285501 / 360000) loss: -0.000000\n",
      "(Iteration 285601 / 360000) loss: -0.000000\n",
      "(Iteration 285701 / 360000) loss: -0.000000\n",
      "(Iteration 285801 / 360000) loss: -0.000000\n",
      "(Iteration 285901 / 360000) loss: -0.000000\n",
      "(Iteration 286001 / 360000) loss: -0.000000\n",
      "(Iteration 286101 / 360000) loss: -0.000000\n",
      "(Iteration 286201 / 360000) loss: -0.000000\n",
      "(Iteration 286301 / 360000) loss: -0.000000\n",
      "(Iteration 286401 / 360000) loss: -0.000000\n",
      "(Iteration 286501 / 360000) loss: -0.000000\n",
      "(Iteration 286601 / 360000) loss: -0.000000\n",
      "(Iteration 286701 / 360000) loss: -0.000000\n",
      "(Iteration 286801 / 360000) loss: -0.000000\n",
      "(Iteration 286901 / 360000) loss: -0.000000\n",
      "(Iteration 287001 / 360000) loss: -0.000000\n",
      "(Iteration 287101 / 360000) loss: -0.000000\n",
      "(Iteration 287201 / 360000) loss: -0.000000\n",
      "(Iteration 287301 / 360000) loss: -0.000000\n",
      "(Iteration 287401 / 360000) loss: -0.000000\n",
      "(Iteration 287501 / 360000) loss: -0.000000\n",
      "(Iteration 287601 / 360000) loss: -0.000000\n",
      "(Iteration 287701 / 360000) loss: -0.000000\n",
      "(Iteration 287801 / 360000) loss: -0.000000\n",
      "(Iteration 287901 / 360000) loss: -0.000000\n",
      "(Epoch 80 / 100) train acc: 0.907000; val_acc: 0.885135\n",
      "(Iteration 288001 / 360000) loss: -0.000000\n",
      "(Iteration 288101 / 360000) loss: -0.000000\n",
      "(Iteration 288201 / 360000) loss: 1804.403260\n",
      "(Iteration 288301 / 360000) loss: -0.000000\n",
      "(Iteration 288401 / 360000) loss: -0.000000\n",
      "(Iteration 288501 / 360000) loss: -0.000000\n",
      "(Iteration 288601 / 360000) loss: 2598.529080\n",
      "(Iteration 288701 / 360000) loss: -0.000000\n",
      "(Iteration 288801 / 360000) loss: -0.000000\n",
      "(Iteration 288901 / 360000) loss: -0.000000\n",
      "(Iteration 289001 / 360000) loss: -0.000000\n",
      "(Iteration 289101 / 360000) loss: -0.000000\n",
      "(Iteration 289201 / 360000) loss: -0.000000\n",
      "(Iteration 289301 / 360000) loss: -0.000000\n",
      "(Iteration 289401 / 360000) loss: -0.000000\n",
      "(Iteration 289501 / 360000) loss: -0.000000\n",
      "(Iteration 289601 / 360000) loss: -0.000000\n",
      "(Iteration 289701 / 360000) loss: -0.000000\n",
      "(Iteration 289801 / 360000) loss: -0.000000\n",
      "(Iteration 289901 / 360000) loss: 1202.361915\n",
      "(Iteration 290001 / 360000) loss: -0.000000\n",
      "(Iteration 290101 / 360000) loss: -0.000000\n",
      "(Iteration 290201 / 360000) loss: -0.000000\n",
      "(Iteration 290301 / 360000) loss: 2079.799025\n",
      "(Iteration 290401 / 360000) loss: -0.000000\n",
      "(Iteration 290501 / 360000) loss: -0.000000\n",
      "(Iteration 290601 / 360000) loss: -0.000000\n",
      "(Iteration 290701 / 360000) loss: 4905.953938\n",
      "(Iteration 290801 / 360000) loss: -0.000000\n",
      "(Iteration 290901 / 360000) loss: 2204.440680\n",
      "(Iteration 291001 / 360000) loss: -0.000000\n",
      "(Iteration 291101 / 360000) loss: -0.000000\n",
      "(Iteration 291201 / 360000) loss: -0.000000\n",
      "(Iteration 291301 / 360000) loss: -0.000000\n",
      "(Iteration 291401 / 360000) loss: 0.000000\n",
      "(Iteration 291501 / 360000) loss: -0.000000\n",
      "(Epoch 81 / 100) train acc: 0.919000; val_acc: 0.885135\n",
      "(Iteration 291601 / 360000) loss: -0.000000\n",
      "(Iteration 291701 / 360000) loss: -0.000000\n",
      "(Iteration 291801 / 360000) loss: -0.000000\n",
      "(Iteration 291901 / 360000) loss: 2480.959575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 292001 / 360000) loss: -0.000000\n",
      "(Iteration 292101 / 360000) loss: -0.000000\n",
      "(Iteration 292201 / 360000) loss: -0.000000\n",
      "(Iteration 292301 / 360000) loss: -0.000000\n",
      "(Iteration 292401 / 360000) loss: -0.000000\n",
      "(Iteration 292501 / 360000) loss: -0.000000\n",
      "(Iteration 292601 / 360000) loss: -0.000000\n",
      "(Iteration 292701 / 360000) loss: -0.000000\n",
      "(Iteration 292801 / 360000) loss: -0.000000\n",
      "(Iteration 292901 / 360000) loss: -0.000000\n",
      "(Iteration 293001 / 360000) loss: -0.000000\n",
      "(Iteration 293101 / 360000) loss: -0.000000\n",
      "(Iteration 293201 / 360000) loss: -0.000000\n",
      "(Iteration 293301 / 360000) loss: -0.000000\n",
      "(Iteration 293401 / 360000) loss: -0.000000\n",
      "(Iteration 293501 / 360000) loss: -0.000000\n",
      "(Iteration 293601 / 360000) loss: -0.000000\n",
      "(Iteration 293701 / 360000) loss: 81.490455\n",
      "(Iteration 293801 / 360000) loss: -0.000000\n",
      "(Iteration 293901 / 360000) loss: 343.351670\n",
      "(Iteration 294001 / 360000) loss: -0.000000\n",
      "(Iteration 294101 / 360000) loss: -0.000000\n",
      "(Iteration 294201 / 360000) loss: 238.507838\n",
      "(Iteration 294301 / 360000) loss: -0.000000\n",
      "(Iteration 294401 / 360000) loss: -0.000000\n",
      "(Iteration 294501 / 360000) loss: -0.000000\n",
      "(Iteration 294601 / 360000) loss: -0.000000\n",
      "(Iteration 294701 / 360000) loss: -0.000000\n",
      "(Iteration 294801 / 360000) loss: -0.000000\n",
      "(Iteration 294901 / 360000) loss: -0.000000\n",
      "(Iteration 295001 / 360000) loss: -0.000000\n",
      "(Iteration 295101 / 360000) loss: -0.000000\n",
      "(Epoch 82 / 100) train acc: 0.916000; val_acc: 0.885135\n",
      "(Iteration 295201 / 360000) loss: -0.000000\n",
      "(Iteration 295301 / 360000) loss: -0.000000\n",
      "(Iteration 295401 / 360000) loss: -0.000000\n",
      "(Iteration 295501 / 360000) loss: -0.000000\n",
      "(Iteration 295601 / 360000) loss: -0.000000\n",
      "(Iteration 295701 / 360000) loss: -0.000000\n",
      "(Iteration 295801 / 360000) loss: -0.000000\n",
      "(Iteration 295901 / 360000) loss: -0.000000\n",
      "(Iteration 296001 / 360000) loss: -0.000000\n",
      "(Iteration 296101 / 360000) loss: -0.000000\n",
      "(Iteration 296201 / 360000) loss: -0.000000\n",
      "(Iteration 296301 / 360000) loss: -0.000000\n",
      "(Iteration 296401 / 360000) loss: -0.000000\n",
      "(Iteration 296501 / 360000) loss: -0.000000\n",
      "(Iteration 296601 / 360000) loss: 163.259226\n",
      "(Iteration 296701 / 360000) loss: -0.000000\n",
      "(Iteration 296801 / 360000) loss: -0.000000\n",
      "(Iteration 296901 / 360000) loss: -0.000000\n",
      "(Iteration 297001 / 360000) loss: -0.000000\n",
      "(Iteration 297101 / 360000) loss: -0.000000\n",
      "(Iteration 297201 / 360000) loss: -0.000000\n",
      "(Iteration 297301 / 360000) loss: -0.000000\n",
      "(Iteration 297401 / 360000) loss: 226.884384\n",
      "(Iteration 297501 / 360000) loss: -0.000000\n",
      "(Iteration 297601 / 360000) loss: -0.000000\n",
      "(Iteration 297701 / 360000) loss: -0.000000\n",
      "(Iteration 297801 / 360000) loss: -0.000000\n",
      "(Iteration 297901 / 360000) loss: -0.000000\n",
      "(Iteration 298001 / 360000) loss: -0.000000\n",
      "(Iteration 298101 / 360000) loss: -0.000000\n",
      "(Iteration 298201 / 360000) loss: -0.000000\n",
      "(Iteration 298301 / 360000) loss: -0.000000\n",
      "(Iteration 298401 / 360000) loss: -0.000000\n",
      "(Iteration 298501 / 360000) loss: 988.717977\n",
      "(Iteration 298601 / 360000) loss: -0.000000\n",
      "(Iteration 298701 / 360000) loss: 1098.065998\n",
      "(Epoch 83 / 100) train acc: 0.922000; val_acc: 0.885135\n",
      "(Iteration 298801 / 360000) loss: -0.000000\n",
      "(Iteration 298901 / 360000) loss: -0.000000\n",
      "(Iteration 299001 / 360000) loss: -0.000000\n",
      "(Iteration 299101 / 360000) loss: -0.000000\n",
      "(Iteration 299201 / 360000) loss: -0.000000\n",
      "(Iteration 299301 / 360000) loss: -0.000000\n",
      "(Iteration 299401 / 360000) loss: -0.000000\n",
      "(Iteration 299501 / 360000) loss: -0.000000\n",
      "(Iteration 299601 / 360000) loss: -0.000000\n",
      "(Iteration 299701 / 360000) loss: -0.000000\n",
      "(Iteration 299801 / 360000) loss: -0.000000\n",
      "(Iteration 299901 / 360000) loss: -0.000000\n",
      "(Iteration 300001 / 360000) loss: -0.000000\n",
      "(Iteration 300101 / 360000) loss: -0.000000\n",
      "(Iteration 300201 / 360000) loss: -0.000000\n",
      "(Iteration 300301 / 360000) loss: -0.000000\n",
      "(Iteration 300401 / 360000) loss: -0.000000\n",
      "(Iteration 300501 / 360000) loss: -0.000000\n",
      "(Iteration 300601 / 360000) loss: -0.000000\n",
      "(Iteration 300701 / 360000) loss: -0.000000\n",
      "(Iteration 300801 / 360000) loss: -0.000000\n",
      "(Iteration 300901 / 360000) loss: -0.000000\n",
      "(Iteration 301001 / 360000) loss: -0.000000\n",
      "(Iteration 301101 / 360000) loss: -0.000000\n",
      "(Iteration 301201 / 360000) loss: -0.000000\n",
      "(Iteration 301301 / 360000) loss: 2543.930418\n",
      "(Iteration 301401 / 360000) loss: -0.000000\n",
      "(Iteration 301501 / 360000) loss: -0.000000\n",
      "(Iteration 301601 / 360000) loss: 824.064706\n",
      "(Iteration 301701 / 360000) loss: -0.000000\n",
      "(Iteration 301801 / 360000) loss: -0.000000\n",
      "(Iteration 301901 / 360000) loss: -0.000000\n",
      "(Iteration 302001 / 360000) loss: 1062.208425\n",
      "(Iteration 302101 / 360000) loss: -0.000000\n",
      "(Iteration 302201 / 360000) loss: -0.000000\n",
      "(Iteration 302301 / 360000) loss: -0.000000\n",
      "(Epoch 84 / 100) train acc: 0.915000; val_acc: 0.885135\n",
      "(Iteration 302401 / 360000) loss: 2079.798195\n",
      "(Iteration 302501 / 360000) loss: -0.000000\n",
      "(Iteration 302601 / 360000) loss: -0.000000\n",
      "(Iteration 302701 / 360000) loss: -0.000000\n",
      "(Iteration 302801 / 360000) loss: 1326.438681\n",
      "(Iteration 302901 / 360000) loss: -0.000000\n",
      "(Iteration 303001 / 360000) loss: -0.000000\n",
      "(Iteration 303101 / 360000) loss: -0.000000\n",
      "(Iteration 303201 / 360000) loss: -0.000000\n",
      "(Iteration 303301 / 360000) loss: -0.000000\n",
      "(Iteration 303401 / 360000) loss: -0.000000\n",
      "(Iteration 303501 / 360000) loss: -0.000000\n",
      "(Iteration 303601 / 360000) loss: -0.000000\n",
      "(Iteration 303701 / 360000) loss: -0.000000\n",
      "(Iteration 303801 / 360000) loss: -0.000000\n",
      "(Iteration 303901 / 360000) loss: -0.000000\n",
      "(Iteration 304001 / 360000) loss: -0.000000\n",
      "(Iteration 304101 / 360000) loss: -0.000000\n",
      "(Iteration 304201 / 360000) loss: -0.000000\n",
      "(Iteration 304301 / 360000) loss: -0.000000\n",
      "(Iteration 304401 / 360000) loss: -0.000000\n",
      "(Iteration 304501 / 360000) loss: -0.000000\n",
      "(Iteration 304601 / 360000) loss: -0.000000\n",
      "(Iteration 304701 / 360000) loss: -0.000000\n",
      "(Iteration 304801 / 360000) loss: -0.000000\n",
      "(Iteration 304901 / 360000) loss: -0.000000\n",
      "(Iteration 305001 / 360000) loss: -0.000000\n",
      "(Iteration 305101 / 360000) loss: -0.000000\n",
      "(Iteration 305201 / 360000) loss: -0.000000\n",
      "(Iteration 305301 / 360000) loss: -0.000000\n",
      "(Iteration 305401 / 360000) loss: -0.000000\n",
      "(Iteration 305501 / 360000) loss: -0.000000\n",
      "(Iteration 305601 / 360000) loss: -0.000000\n",
      "(Iteration 305701 / 360000) loss: -0.000000\n",
      "(Iteration 305801 / 360000) loss: -0.000000\n",
      "(Iteration 305901 / 360000) loss: -0.000000\n",
      "(Epoch 85 / 100) train acc: 0.937000; val_acc: 0.885135\n",
      "(Iteration 306001 / 360000) loss: -0.000000\n",
      "(Iteration 306101 / 360000) loss: 1202.362180\n",
      "(Iteration 306201 / 360000) loss: -0.000000\n",
      "(Iteration 306301 / 360000) loss: 1533.486693\n",
      "(Iteration 306401 / 360000) loss: -0.000000\n",
      "(Iteration 306501 / 360000) loss: -0.000000\n",
      "(Iteration 306601 / 360000) loss: -0.000000\n",
      "(Iteration 306701 / 360000) loss: -0.000000\n",
      "(Iteration 306801 / 360000) loss: -0.000000\n",
      "(Iteration 306901 / 360000) loss: -0.000000\n",
      "(Iteration 307001 / 360000) loss: -0.000000\n",
      "(Iteration 307101 / 360000) loss: -0.000000\n",
      "(Iteration 307201 / 360000) loss: -0.000000\n",
      "(Iteration 307301 / 360000) loss: -0.000000\n",
      "(Iteration 307401 / 360000) loss: -0.000000\n",
      "(Iteration 307501 / 360000) loss: -0.000000\n",
      "(Iteration 307601 / 360000) loss: -0.000000\n",
      "(Iteration 307701 / 360000) loss: -0.000000\n",
      "(Iteration 307801 / 360000) loss: -0.000000\n",
      "(Iteration 307901 / 360000) loss: 2543.930421\n",
      "(Iteration 308001 / 360000) loss: -0.000000\n",
      "(Iteration 308101 / 360000) loss: -0.000000\n",
      "(Iteration 308201 / 360000) loss: -0.000000\n",
      "(Iteration 308301 / 360000) loss: -0.000000\n",
      "(Iteration 308401 / 360000) loss: -0.000000\n",
      "(Iteration 308501 / 360000) loss: -0.000000\n",
      "(Iteration 308601 / 360000) loss: -0.000000\n",
      "(Iteration 308701 / 360000) loss: 1224.333471\n",
      "(Iteration 308801 / 360000) loss: -0.000000\n",
      "(Iteration 308901 / 360000) loss: -0.000000\n",
      "(Iteration 309001 / 360000) loss: 299.497117\n",
      "(Iteration 309101 / 360000) loss: -0.000000\n",
      "(Iteration 309201 / 360000) loss: -0.000000\n",
      "(Iteration 309301 / 360000) loss: -0.000000\n",
      "(Iteration 309401 / 360000) loss: -0.000000\n",
      "(Iteration 309501 / 360000) loss: -0.000000\n",
      "(Epoch 86 / 100) train acc: 0.926000; val_acc: 0.885135\n",
      "(Iteration 309601 / 360000) loss: -0.000000\n",
      "(Iteration 309701 / 360000) loss: -0.000000\n",
      "(Iteration 309801 / 360000) loss: -0.000000\n",
      "(Iteration 309901 / 360000) loss: -0.000000\n",
      "(Iteration 310001 / 360000) loss: -0.000000\n",
      "(Iteration 310101 / 360000) loss: -0.000000\n",
      "(Iteration 310201 / 360000) loss: -0.000000\n",
      "(Iteration 310301 / 360000) loss: -0.000000\n",
      "(Iteration 310401 / 360000) loss: -0.000000\n",
      "(Iteration 310501 / 360000) loss: -0.000000\n",
      "(Iteration 310601 / 360000) loss: -0.000000\n",
      "(Iteration 310701 / 360000) loss: -0.000000\n",
      "(Iteration 310801 / 360000) loss: -0.000000\n",
      "(Iteration 310901 / 360000) loss: -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 311001 / 360000) loss: -0.000000\n",
      "(Iteration 311101 / 360000) loss: -0.000000\n",
      "(Iteration 311201 / 360000) loss: -0.000000\n",
      "(Iteration 311301 / 360000) loss: -0.000000\n",
      "(Iteration 311401 / 360000) loss: -0.000000\n",
      "(Iteration 311501 / 360000) loss: -0.000000\n",
      "(Iteration 311601 / 360000) loss: -0.000000\n",
      "(Iteration 311701 / 360000) loss: -0.000000\n",
      "(Iteration 311801 / 360000) loss: -0.000000\n",
      "(Iteration 311901 / 360000) loss: -0.000000\n",
      "(Iteration 312001 / 360000) loss: -0.000000\n",
      "(Iteration 312101 / 360000) loss: -0.000000\n",
      "(Iteration 312201 / 360000) loss: -0.000000\n",
      "(Iteration 312301 / 360000) loss: -0.000000\n",
      "(Iteration 312401 / 360000) loss: -0.000000\n",
      "(Iteration 312501 / 360000) loss: -0.000000\n",
      "(Iteration 312601 / 360000) loss: -0.000000\n",
      "(Iteration 312701 / 360000) loss: -0.000000\n",
      "(Iteration 312801 / 360000) loss: -0.000000\n",
      "(Iteration 312901 / 360000) loss: -0.000000\n",
      "(Iteration 313001 / 360000) loss: -0.000000\n",
      "(Iteration 313101 / 360000) loss: -0.000000\n",
      "(Epoch 87 / 100) train acc: 0.930000; val_acc: 0.885135\n",
      "(Iteration 313201 / 360000) loss: -0.000000\n",
      "(Iteration 313301 / 360000) loss: -0.000000\n",
      "(Iteration 313401 / 360000) loss: -0.000000\n",
      "(Iteration 313501 / 360000) loss: -0.000000\n",
      "(Iteration 313601 / 360000) loss: -0.000000\n",
      "(Iteration 313701 / 360000) loss: 3796.234002\n",
      "(Iteration 313801 / 360000) loss: -0.000000\n",
      "(Iteration 313901 / 360000) loss: -0.000000\n",
      "(Iteration 314001 / 360000) loss: -0.000000\n",
      "(Iteration 314101 / 360000) loss: -0.000000\n",
      "(Iteration 314201 / 360000) loss: -0.000000\n",
      "(Iteration 314301 / 360000) loss: -0.000000\n",
      "(Iteration 314401 / 360000) loss: -0.000000\n",
      "(Iteration 314501 / 360000) loss: -0.000000\n",
      "(Iteration 314601 / 360000) loss: -0.000000\n",
      "(Iteration 314701 / 360000) loss: 761.422991\n",
      "(Iteration 314801 / 360000) loss: -0.000000\n",
      "(Iteration 314901 / 360000) loss: -0.000000\n",
      "(Iteration 315001 / 360000) loss: 891.405456\n",
      "(Iteration 315101 / 360000) loss: -0.000000\n",
      "(Iteration 315201 / 360000) loss: -0.000000\n",
      "(Iteration 315301 / 360000) loss: -0.000000\n",
      "(Iteration 315401 / 360000) loss: -0.000000\n",
      "(Iteration 315501 / 360000) loss: -0.000000\n",
      "(Iteration 315601 / 360000) loss: -0.000000\n",
      "(Iteration 315701 / 360000) loss: -0.000000\n",
      "(Iteration 315801 / 360000) loss: -0.000000\n",
      "(Iteration 315901 / 360000) loss: -0.000000\n",
      "(Iteration 316001 / 360000) loss: -0.000000\n",
      "(Iteration 316101 / 360000) loss: -0.000000\n",
      "(Iteration 316201 / 360000) loss: -0.000000\n",
      "(Iteration 316301 / 360000) loss: -0.000000\n",
      "(Iteration 316401 / 360000) loss: -0.000000\n",
      "(Iteration 316501 / 360000) loss: -0.000000\n",
      "(Iteration 316601 / 360000) loss: -0.000000\n",
      "(Iteration 316701 / 360000) loss: 85.926458\n",
      "(Epoch 88 / 100) train acc: 0.915000; val_acc: 0.885135\n",
      "(Iteration 316801 / 360000) loss: -0.000000\n",
      "(Iteration 316901 / 360000) loss: -0.000000\n",
      "(Iteration 317001 / 360000) loss: -0.000000\n",
      "(Iteration 317101 / 360000) loss: -0.000000\n",
      "(Iteration 317201 / 360000) loss: -0.000000\n",
      "(Iteration 317301 / 360000) loss: -0.000000\n",
      "(Iteration 317401 / 360000) loss: -0.000000\n",
      "(Iteration 317501 / 360000) loss: -0.000000\n",
      "(Iteration 317601 / 360000) loss: -0.000000\n",
      "(Iteration 317701 / 360000) loss: -0.000000\n",
      "(Iteration 317801 / 360000) loss: -0.000000\n",
      "(Iteration 317901 / 360000) loss: -0.000000\n",
      "(Iteration 318001 / 360000) loss: 389.670060\n",
      "(Iteration 318101 / 360000) loss: -0.000000\n",
      "(Iteration 318201 / 360000) loss: -0.000000\n",
      "(Iteration 318301 / 360000) loss: -0.000000\n",
      "(Iteration 318401 / 360000) loss: 2079.798164\n",
      "(Iteration 318501 / 360000) loss: 1687.480070\n",
      "(Iteration 318601 / 360000) loss: -0.000000\n",
      "(Iteration 318701 / 360000) loss: -0.000000\n",
      "(Iteration 318801 / 360000) loss: -0.000000\n",
      "(Iteration 318901 / 360000) loss: -0.000000\n",
      "(Iteration 319001 / 360000) loss: -0.000000\n",
      "(Iteration 319101 / 360000) loss: -0.000000\n",
      "(Iteration 319201 / 360000) loss: -0.000000\n",
      "(Iteration 319301 / 360000) loss: -0.000000\n",
      "(Iteration 319401 / 360000) loss: -0.000000\n",
      "(Iteration 319501 / 360000) loss: -0.000000\n",
      "(Iteration 319601 / 360000) loss: -0.000000\n",
      "(Iteration 319701 / 360000) loss: -0.000000\n",
      "(Iteration 319801 / 360000) loss: -0.000000\n",
      "(Iteration 319901 / 360000) loss: -0.000000\n",
      "(Iteration 320001 / 360000) loss: -0.000000\n",
      "(Iteration 320101 / 360000) loss: -0.000000\n",
      "(Iteration 320201 / 360000) loss: -0.000000\n",
      "(Iteration 320301 / 360000) loss: -0.000000\n",
      "(Epoch 89 / 100) train acc: 0.919000; val_acc: 0.885135\n",
      "(Iteration 320401 / 360000) loss: -0.000000\n",
      "(Iteration 320501 / 360000) loss: -0.000000\n",
      "(Iteration 320601 / 360000) loss: -0.000000\n",
      "(Iteration 320701 / 360000) loss: -0.000000\n",
      "(Iteration 320801 / 360000) loss: -0.000000\n",
      "(Iteration 320901 / 360000) loss: -0.000000\n",
      "(Iteration 321001 / 360000) loss: -0.000000\n",
      "(Iteration 321101 / 360000) loss: -0.000000\n",
      "(Iteration 321201 / 360000) loss: -0.000000\n",
      "(Iteration 321301 / 360000) loss: -0.000000\n",
      "(Iteration 321401 / 360000) loss: -0.000000\n",
      "(Iteration 321501 / 360000) loss: -0.000000\n",
      "(Iteration 321601 / 360000) loss: -0.000000\n",
      "(Iteration 321701 / 360000) loss: -0.000000\n",
      "(Iteration 321801 / 360000) loss: -0.000000\n",
      "(Iteration 321901 / 360000) loss: -0.000000\n",
      "(Iteration 322001 / 360000) loss: -0.000000\n",
      "(Iteration 322101 / 360000) loss: -0.000000\n",
      "(Iteration 322201 / 360000) loss: -0.000000\n",
      "(Iteration 322301 / 360000) loss: -0.000000\n",
      "(Iteration 322401 / 360000) loss: 340.506737\n",
      "(Iteration 322501 / 360000) loss: -0.000000\n",
      "(Iteration 322601 / 360000) loss: -0.000000\n",
      "(Iteration 322701 / 360000) loss: -0.000000\n",
      "(Iteration 322801 / 360000) loss: -0.000000\n",
      "(Iteration 322901 / 360000) loss: -0.000000\n",
      "(Iteration 323001 / 360000) loss: -0.000000\n",
      "(Iteration 323101 / 360000) loss: -0.000000\n",
      "(Iteration 323201 / 360000) loss: -0.000000\n",
      "(Iteration 323301 / 360000) loss: 311.368752\n",
      "(Iteration 323401 / 360000) loss: -0.000000\n",
      "(Iteration 323501 / 360000) loss: -0.000000\n",
      "(Iteration 323601 / 360000) loss: -0.000000\n",
      "(Iteration 323701 / 360000) loss: -0.000000\n",
      "(Iteration 323801 / 360000) loss: -0.000000\n",
      "(Iteration 323901 / 360000) loss: -0.000000\n",
      "(Epoch 90 / 100) train acc: 0.924000; val_acc: 0.885135\n",
      "(Iteration 324001 / 360000) loss: -0.000000\n",
      "(Iteration 324101 / 360000) loss: -0.000000\n",
      "(Iteration 324201 / 360000) loss: -0.000000\n",
      "(Iteration 324301 / 360000) loss: -0.000000\n",
      "(Iteration 324401 / 360000) loss: -0.000000\n",
      "(Iteration 324501 / 360000) loss: -0.000000\n",
      "(Iteration 324601 / 360000) loss: -0.000000\n",
      "(Iteration 324701 / 360000) loss: -0.000000\n",
      "(Iteration 324801 / 360000) loss: -0.000000\n",
      "(Iteration 324901 / 360000) loss: -0.000000\n",
      "(Iteration 325001 / 360000) loss: -0.000000\n",
      "(Iteration 325101 / 360000) loss: -0.000000\n",
      "(Iteration 325201 / 360000) loss: -0.000000\n",
      "(Iteration 325301 / 360000) loss: -0.000000\n",
      "(Iteration 325401 / 360000) loss: -0.000000\n",
      "(Iteration 325501 / 360000) loss: -0.000000\n",
      "(Iteration 325601 / 360000) loss: -0.000000\n",
      "(Iteration 325701 / 360000) loss: -0.000000\n",
      "(Iteration 325801 / 360000) loss: -0.000000\n",
      "(Iteration 325901 / 360000) loss: -0.000000\n",
      "(Iteration 326001 / 360000) loss: -0.000000\n",
      "(Iteration 326101 / 360000) loss: -0.000000\n",
      "(Iteration 326201 / 360000) loss: -0.000000\n",
      "(Iteration 326301 / 360000) loss: -0.000000\n",
      "(Iteration 326401 / 360000) loss: -0.000000\n",
      "(Iteration 326501 / 360000) loss: -0.000000\n",
      "(Iteration 326601 / 360000) loss: -0.000000\n",
      "(Iteration 326701 / 360000) loss: -0.000000\n",
      "(Iteration 326801 / 360000) loss: -0.000000\n",
      "(Iteration 326901 / 360000) loss: -0.000000\n",
      "(Iteration 327001 / 360000) loss: 1662.794165\n",
      "(Iteration 327101 / 360000) loss: -0.000000\n",
      "(Iteration 327201 / 360000) loss: -0.000000\n",
      "(Iteration 327301 / 360000) loss: -0.000000\n",
      "(Iteration 327401 / 360000) loss: -0.000000\n",
      "(Iteration 327501 / 360000) loss: -0.000000\n",
      "(Epoch 91 / 100) train acc: 0.914000; val_acc: 0.885135\n",
      "(Iteration 327601 / 360000) loss: -0.000000\n",
      "(Iteration 327701 / 360000) loss: -0.000000\n",
      "(Iteration 327801 / 360000) loss: -0.000000\n",
      "(Iteration 327901 / 360000) loss: -0.000000\n",
      "(Iteration 328001 / 360000) loss: 141.889727\n",
      "(Iteration 328101 / 360000) loss: -0.000000\n",
      "(Iteration 328201 / 360000) loss: -0.000000\n",
      "(Iteration 328301 / 360000) loss: -0.000000\n",
      "(Iteration 328401 / 360000) loss: -0.000000\n",
      "(Iteration 328501 / 360000) loss: -0.000000\n",
      "(Iteration 328601 / 360000) loss: -0.000000\n",
      "(Iteration 328701 / 360000) loss: -0.000000\n",
      "(Iteration 328801 / 360000) loss: -0.000000\n",
      "(Iteration 328901 / 360000) loss: -0.000000\n",
      "(Iteration 329001 / 360000) loss: -0.000000\n",
      "(Iteration 329101 / 360000) loss: -0.000000\n",
      "(Iteration 329201 / 360000) loss: -0.000000\n",
      "(Iteration 329301 / 360000) loss: -0.000000\n",
      "(Iteration 329401 / 360000) loss: -0.000000\n",
      "(Iteration 329501 / 360000) loss: -0.000000\n",
      "(Iteration 329601 / 360000) loss: -0.000000\n",
      "(Iteration 329701 / 360000) loss: -0.000000\n",
      "(Iteration 329801 / 360000) loss: -0.000000\n",
      "(Iteration 329901 / 360000) loss: -0.000000\n",
      "(Iteration 330001 / 360000) loss: -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 330101 / 360000) loss: -0.000000\n",
      "(Iteration 330201 / 360000) loss: 208.660902\n",
      "(Iteration 330301 / 360000) loss: -0.000000\n",
      "(Iteration 330401 / 360000) loss: -0.000000\n",
      "(Iteration 330501 / 360000) loss: -0.000000\n",
      "(Iteration 330601 / 360000) loss: -0.000000\n",
      "(Iteration 330701 / 360000) loss: 1.861295\n",
      "(Iteration 330801 / 360000) loss: 896.264093\n",
      "(Iteration 330901 / 360000) loss: -0.000000\n",
      "(Iteration 331001 / 360000) loss: -0.000000\n",
      "(Iteration 331101 / 360000) loss: -0.000000\n",
      "(Epoch 92 / 100) train acc: 0.938000; val_acc: 0.885135\n",
      "(Iteration 331201 / 360000) loss: -0.000000\n",
      "(Iteration 331301 / 360000) loss: -0.000000\n",
      "(Iteration 331401 / 360000) loss: -0.000000\n",
      "(Iteration 331501 / 360000) loss: -0.000000\n",
      "(Iteration 331601 / 360000) loss: -0.000000\n",
      "(Iteration 331701 / 360000) loss: -0.000000\n",
      "(Iteration 331801 / 360000) loss: 69.301491\n",
      "(Iteration 331901 / 360000) loss: -0.000000\n",
      "(Iteration 332001 / 360000) loss: -0.000000\n",
      "(Iteration 332101 / 360000) loss: -0.000000\n",
      "(Iteration 332201 / 360000) loss: -0.000000\n",
      "(Iteration 332301 / 360000) loss: -0.000000\n",
      "(Iteration 332401 / 360000) loss: -0.000000\n",
      "(Iteration 332501 / 360000) loss: -0.000000\n",
      "(Iteration 332601 / 360000) loss: -0.000000\n",
      "(Iteration 332701 / 360000) loss: -0.000000\n",
      "(Iteration 332801 / 360000) loss: -0.000000\n",
      "(Iteration 332901 / 360000) loss: -0.000000\n",
      "(Iteration 333001 / 360000) loss: -0.000000\n",
      "(Iteration 333101 / 360000) loss: -0.000000\n",
      "(Iteration 333201 / 360000) loss: -0.000000\n",
      "(Iteration 333301 / 360000) loss: -0.000000\n",
      "(Iteration 333401 / 360000) loss: -0.000000\n",
      "(Iteration 333501 / 360000) loss: -0.000000\n",
      "(Iteration 333601 / 360000) loss: -0.000000\n",
      "(Iteration 333701 / 360000) loss: -0.000000\n",
      "(Iteration 333801 / 360000) loss: -0.000000\n",
      "(Iteration 333901 / 360000) loss: -0.000000\n",
      "(Iteration 334001 / 360000) loss: -0.000000\n",
      "(Iteration 334101 / 360000) loss: -0.000000\n",
      "(Iteration 334201 / 360000) loss: -0.000000\n",
      "(Iteration 334301 / 360000) loss: -0.000000\n",
      "(Iteration 334401 / 360000) loss: -0.000000\n",
      "(Iteration 334501 / 360000) loss: -0.000000\n",
      "(Iteration 334601 / 360000) loss: -0.000000\n",
      "(Iteration 334701 / 360000) loss: -0.000000\n",
      "(Epoch 93 / 100) train acc: 0.922000; val_acc: 0.885135\n",
      "(Iteration 334801 / 360000) loss: -0.000000\n",
      "(Iteration 334901 / 360000) loss: -0.000000\n",
      "(Iteration 335001 / 360000) loss: 562.299808\n",
      "(Iteration 335101 / 360000) loss: -0.000000\n",
      "(Iteration 335201 / 360000) loss: 16.409397\n",
      "(Iteration 335301 / 360000) loss: -0.000000\n",
      "(Iteration 335401 / 360000) loss: -0.000000\n",
      "(Iteration 335501 / 360000) loss: -0.000000\n",
      "(Iteration 335601 / 360000) loss: -0.000000\n",
      "(Iteration 335701 / 360000) loss: -0.000000\n",
      "(Iteration 335801 / 360000) loss: -0.000000\n",
      "(Iteration 335901 / 360000) loss: -0.000000\n",
      "(Iteration 336001 / 360000) loss: -0.000000\n",
      "(Iteration 336101 / 360000) loss: -0.000000\n",
      "(Iteration 336201 / 360000) loss: -0.000000\n",
      "(Iteration 336301 / 360000) loss: -0.000000\n",
      "(Iteration 336401 / 360000) loss: -0.000000\n",
      "(Iteration 336501 / 360000) loss: -0.000000\n",
      "(Iteration 336601 / 360000) loss: -0.000000\n",
      "(Iteration 336701 / 360000) loss: -0.000000\n",
      "(Iteration 336801 / 360000) loss: -0.000000\n",
      "(Iteration 336901 / 360000) loss: -0.000000\n",
      "(Iteration 337001 / 360000) loss: -0.000000\n",
      "(Iteration 337101 / 360000) loss: -0.000000\n",
      "(Iteration 337201 / 360000) loss: -0.000000\n",
      "(Iteration 337301 / 360000) loss: -0.000000\n",
      "(Iteration 337401 / 360000) loss: -0.000000\n",
      "(Iteration 337501 / 360000) loss: -0.000000\n",
      "(Iteration 337601 / 360000) loss: -0.000000\n",
      "(Iteration 337701 / 360000) loss: -0.000000\n",
      "(Iteration 337801 / 360000) loss: -0.000000\n",
      "(Iteration 337901 / 360000) loss: -0.000000\n",
      "(Iteration 338001 / 360000) loss: -0.000000\n",
      "(Iteration 338101 / 360000) loss: 2347.171532\n",
      "(Iteration 338201 / 360000) loss: -0.000000\n",
      "(Iteration 338301 / 360000) loss: -0.000000\n",
      "(Epoch 94 / 100) train acc: 0.916000; val_acc: 0.885135\n",
      "(Iteration 338401 / 360000) loss: -0.000000\n",
      "(Iteration 338501 / 360000) loss: -0.000000\n",
      "(Iteration 338601 / 360000) loss: -0.000000\n",
      "(Iteration 338701 / 360000) loss: -0.000000\n",
      "(Iteration 338801 / 360000) loss: -0.000000\n",
      "(Iteration 338901 / 360000) loss: -0.000000\n",
      "(Iteration 339001 / 360000) loss: -0.000000\n",
      "(Iteration 339101 / 360000) loss: -0.000000\n",
      "(Iteration 339201 / 360000) loss: -0.000000\n",
      "(Iteration 339301 / 360000) loss: -0.000000\n",
      "(Iteration 339401 / 360000) loss: -0.000000\n",
      "(Iteration 339501 / 360000) loss: -0.000000\n",
      "(Iteration 339601 / 360000) loss: -0.000000\n",
      "(Iteration 339701 / 360000) loss: -0.000000\n",
      "(Iteration 339801 / 360000) loss: -0.000000\n",
      "(Iteration 339901 / 360000) loss: 163.259116\n",
      "(Iteration 340001 / 360000) loss: -0.000000\n",
      "(Iteration 340101 / 360000) loss: -0.000000\n",
      "(Iteration 340201 / 360000) loss: 0.000000\n",
      "(Iteration 340301 / 360000) loss: -0.000000\n",
      "(Iteration 340401 / 360000) loss: -0.000000\n",
      "(Iteration 340501 / 360000) loss: 1375.344377\n",
      "(Iteration 340601 / 360000) loss: -0.000000\n",
      "(Iteration 340701 / 360000) loss: 1940.054040\n",
      "(Iteration 340801 / 360000) loss: -0.000000\n",
      "(Iteration 340901 / 360000) loss: 466.586437\n",
      "(Iteration 341001 / 360000) loss: -0.000000\n",
      "(Iteration 341101 / 360000) loss: -0.000000\n",
      "(Iteration 341201 / 360000) loss: 163.259116\n",
      "(Iteration 341301 / 360000) loss: -0.000000\n",
      "(Iteration 341401 / 360000) loss: -0.000000\n",
      "(Iteration 341501 / 360000) loss: 0.000000\n",
      "(Iteration 341601 / 360000) loss: -0.000000\n",
      "(Iteration 341701 / 360000) loss: -0.000000\n",
      "(Iteration 341801 / 360000) loss: -0.000000\n",
      "(Iteration 341901 / 360000) loss: 1458.087172\n",
      "(Epoch 95 / 100) train acc: 0.911000; val_acc: 0.885135\n",
      "(Iteration 342001 / 360000) loss: -0.000000\n",
      "(Iteration 342101 / 360000) loss: -0.000000\n",
      "(Iteration 342201 / 360000) loss: -0.000000\n",
      "(Iteration 342301 / 360000) loss: -0.000000\n",
      "(Iteration 342401 / 360000) loss: -0.000000\n",
      "(Iteration 342501 / 360000) loss: -0.000000\n",
      "(Iteration 342601 / 360000) loss: -0.000000\n",
      "(Iteration 342701 / 360000) loss: -0.000000\n",
      "(Iteration 342801 / 360000) loss: -0.000000\n",
      "(Iteration 342901 / 360000) loss: -0.000000\n",
      "(Iteration 343001 / 360000) loss: -0.000000\n",
      "(Iteration 343101 / 360000) loss: -0.000000\n",
      "(Iteration 343201 / 360000) loss: -0.000000\n",
      "(Iteration 343301 / 360000) loss: -0.000000\n",
      "(Iteration 343401 / 360000) loss: -0.000000\n",
      "(Iteration 343501 / 360000) loss: -0.000000\n",
      "(Iteration 343601 / 360000) loss: -0.000000\n",
      "(Iteration 343701 / 360000) loss: -0.000000\n",
      "(Iteration 343801 / 360000) loss: -0.000000\n",
      "(Iteration 343901 / 360000) loss: -0.000000\n",
      "(Iteration 344001 / 360000) loss: -0.000000\n",
      "(Iteration 344101 / 360000) loss: -0.000000\n",
      "(Iteration 344201 / 360000) loss: -0.000000\n",
      "(Iteration 344301 / 360000) loss: -0.000000\n",
      "(Iteration 344401 / 360000) loss: -0.000000\n",
      "(Iteration 344501 / 360000) loss: -0.000000\n",
      "(Iteration 344601 / 360000) loss: 100.283937\n",
      "(Iteration 344701 / 360000) loss: -0.000000\n",
      "(Iteration 344801 / 360000) loss: -0.000000\n",
      "(Iteration 344901 / 360000) loss: -0.000000\n",
      "(Iteration 345001 / 360000) loss: -0.000000\n",
      "(Iteration 345101 / 360000) loss: -0.000000\n",
      "(Iteration 345201 / 360000) loss: -0.000000\n",
      "(Iteration 345301 / 360000) loss: -0.000000\n",
      "(Iteration 345401 / 360000) loss: -0.000000\n",
      "(Iteration 345501 / 360000) loss: -0.000000\n",
      "(Epoch 96 / 100) train acc: 0.917000; val_acc: 0.885135\n",
      "(Iteration 345601 / 360000) loss: -0.000000\n",
      "(Iteration 345701 / 360000) loss: 1432.407486\n",
      "(Iteration 345801 / 360000) loss: -0.000000\n",
      "(Iteration 345901 / 360000) loss: -0.000000\n",
      "(Iteration 346001 / 360000) loss: -0.000000\n",
      "(Iteration 346101 / 360000) loss: -0.000000\n",
      "(Iteration 346201 / 360000) loss: -0.000000\n",
      "(Iteration 346301 / 360000) loss: -0.000000\n",
      "(Iteration 346401 / 360000) loss: -0.000000\n",
      "(Iteration 346501 / 360000) loss: -0.000000\n",
      "(Iteration 346601 / 360000) loss: -0.000000\n",
      "(Iteration 346701 / 360000) loss: -0.000000\n",
      "(Iteration 346801 / 360000) loss: -0.000000\n",
      "(Iteration 346901 / 360000) loss: -0.000000\n",
      "(Iteration 347001 / 360000) loss: -0.000000\n",
      "(Iteration 347101 / 360000) loss: -0.000000\n",
      "(Iteration 347201 / 360000) loss: -0.000000\n",
      "(Iteration 347301 / 360000) loss: -0.000000\n",
      "(Iteration 347401 / 360000) loss: -0.000000\n",
      "(Iteration 347501 / 360000) loss: -0.000000\n",
      "(Iteration 347601 / 360000) loss: -0.000000\n",
      "(Iteration 347701 / 360000) loss: -0.000000\n",
      "(Iteration 347801 / 360000) loss: -0.000000\n",
      "(Iteration 347901 / 360000) loss: -0.000000\n",
      "(Iteration 348001 / 360000) loss: -0.000000\n",
      "(Iteration 348101 / 360000) loss: -0.000000\n",
      "(Iteration 348201 / 360000) loss: -0.000000\n",
      "(Iteration 348301 / 360000) loss: -0.000000\n",
      "(Iteration 348401 / 360000) loss: -0.000000\n",
      "(Iteration 348501 / 360000) loss: -0.000000\n",
      "(Iteration 348601 / 360000) loss: -0.000000\n",
      "(Iteration 348701 / 360000) loss: -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 348801 / 360000) loss: -0.000000\n",
      "(Iteration 348901 / 360000) loss: -0.000000\n",
      "(Iteration 349001 / 360000) loss: -0.000000\n",
      "(Iteration 349101 / 360000) loss: -0.000000\n",
      "(Epoch 97 / 100) train acc: 0.925000; val_acc: 0.885135\n",
      "(Iteration 349201 / 360000) loss: -0.000000\n",
      "(Iteration 349301 / 360000) loss: 122.937831\n",
      "(Iteration 349401 / 360000) loss: -0.000000\n",
      "(Iteration 349501 / 360000) loss: -0.000000\n",
      "(Iteration 349601 / 360000) loss: 16.409388\n",
      "(Iteration 349701 / 360000) loss: -0.000000\n",
      "(Iteration 349801 / 360000) loss: -0.000000\n",
      "(Iteration 349901 / 360000) loss: -0.000000\n",
      "(Iteration 350001 / 360000) loss: -0.000000\n",
      "(Iteration 350101 / 360000) loss: -0.000000\n",
      "(Iteration 350201 / 360000) loss: 52.656957\n",
      "(Iteration 350301 / 360000) loss: -0.000000\n",
      "(Iteration 350401 / 360000) loss: 4372.105142\n",
      "(Iteration 350501 / 360000) loss: -0.000000\n",
      "(Iteration 350601 / 360000) loss: -0.000000\n",
      "(Iteration 350701 / 360000) loss: 178.137489\n",
      "(Iteration 350801 / 360000) loss: -0.000000\n",
      "(Iteration 350901 / 360000) loss: -0.000000\n",
      "(Iteration 351001 / 360000) loss: -0.000000\n",
      "(Iteration 351101 / 360000) loss: -0.000000\n",
      "(Iteration 351201 / 360000) loss: -0.000000\n",
      "(Iteration 351301 / 360000) loss: -0.000000\n",
      "(Iteration 351401 / 360000) loss: -0.000000\n",
      "(Iteration 351501 / 360000) loss: -0.000000\n",
      "(Iteration 351601 / 360000) loss: -0.000000\n",
      "(Iteration 351701 / 360000) loss: -0.000000\n",
      "(Iteration 351801 / 360000) loss: -0.000000\n",
      "(Iteration 351901 / 360000) loss: -0.000000\n",
      "(Iteration 352001 / 360000) loss: -0.000000\n",
      "(Iteration 352101 / 360000) loss: -0.000000\n",
      "(Iteration 352201 / 360000) loss: -0.000000\n",
      "(Iteration 352301 / 360000) loss: -0.000000\n",
      "(Iteration 352401 / 360000) loss: -0.000000\n",
      "(Iteration 352501 / 360000) loss: 398.156507\n",
      "(Iteration 352601 / 360000) loss: -0.000000\n",
      "(Iteration 352701 / 360000) loss: -0.000000\n",
      "(Epoch 98 / 100) train acc: 0.920000; val_acc: 0.885135\n",
      "(Iteration 352801 / 360000) loss: 238.268576\n",
      "(Iteration 352901 / 360000) loss: -0.000000\n",
      "(Iteration 353001 / 360000) loss: -0.000000\n",
      "(Iteration 353101 / 360000) loss: -0.000000\n",
      "(Iteration 353201 / 360000) loss: -0.000000\n",
      "(Iteration 353301 / 360000) loss: -0.000000\n",
      "(Iteration 353401 / 360000) loss: -0.000000\n",
      "(Iteration 353501 / 360000) loss: -0.000000\n",
      "(Iteration 353601 / 360000) loss: -0.000000\n",
      "(Iteration 353701 / 360000) loss: -0.000000\n",
      "(Iteration 353801 / 360000) loss: -0.000000\n",
      "(Iteration 353901 / 360000) loss: -0.000000\n",
      "(Iteration 354001 / 360000) loss: -0.000000\n",
      "(Iteration 354101 / 360000) loss: -0.000000\n",
      "(Iteration 354201 / 360000) loss: -0.000000\n",
      "(Iteration 354301 / 360000) loss: -0.000000\n",
      "(Iteration 354401 / 360000) loss: -0.000000\n",
      "(Iteration 354501 / 360000) loss: 3578.684638\n",
      "(Iteration 354601 / 360000) loss: -0.000000\n",
      "(Iteration 354701 / 360000) loss: -0.000000\n",
      "(Iteration 354801 / 360000) loss: -0.000000\n",
      "(Iteration 354901 / 360000) loss: -0.000000\n",
      "(Iteration 355001 / 360000) loss: -0.000000\n",
      "(Iteration 355101 / 360000) loss: -0.000000\n",
      "(Iteration 355201 / 360000) loss: -0.000000\n",
      "(Iteration 355301 / 360000) loss: -0.000000\n",
      "(Iteration 355401 / 360000) loss: -0.000000\n",
      "(Iteration 355501 / 360000) loss: -0.000000\n",
      "(Iteration 355601 / 360000) loss: -0.000000\n",
      "(Iteration 355701 / 360000) loss: -0.000000\n",
      "(Iteration 355801 / 360000) loss: 0.000000\n",
      "(Iteration 355901 / 360000) loss: -0.000000\n",
      "(Iteration 356001 / 360000) loss: -0.000000\n",
      "(Iteration 356101 / 360000) loss: -0.000000\n",
      "(Iteration 356201 / 360000) loss: 3797.029683\n",
      "(Iteration 356301 / 360000) loss: -0.000000\n",
      "(Epoch 99 / 100) train acc: 0.924000; val_acc: 0.885135\n",
      "(Iteration 356401 / 360000) loss: -0.000000\n",
      "(Iteration 356501 / 360000) loss: -0.000000\n",
      "(Iteration 356601 / 360000) loss: -0.000000\n",
      "(Iteration 356701 / 360000) loss: -0.000000\n",
      "(Iteration 356801 / 360000) loss: -0.000000\n",
      "(Iteration 356901 / 360000) loss: -0.000000\n",
      "(Iteration 357001 / 360000) loss: -0.000000\n",
      "(Iteration 357101 / 360000) loss: -0.000000\n",
      "(Iteration 357201 / 360000) loss: 0.000000\n",
      "(Iteration 357301 / 360000) loss: -0.000000\n",
      "(Iteration 357401 / 360000) loss: -0.000000\n",
      "(Iteration 357501 / 360000) loss: -0.000000\n",
      "(Iteration 357601 / 360000) loss: -0.000000\n",
      "(Iteration 357701 / 360000) loss: -0.000000\n",
      "(Iteration 357801 / 360000) loss: -0.000000\n",
      "(Iteration 357901 / 360000) loss: -0.000000\n",
      "(Iteration 358001 / 360000) loss: -0.000000\n",
      "(Iteration 358101 / 360000) loss: 807.317375\n",
      "(Iteration 358201 / 360000) loss: -0.000000\n",
      "(Iteration 358301 / 360000) loss: -0.000000\n",
      "(Iteration 358401 / 360000) loss: -0.000000\n",
      "(Iteration 358501 / 360000) loss: -0.000000\n",
      "(Iteration 358601 / 360000) loss: -0.000000\n",
      "(Iteration 358701 / 360000) loss: -0.000000\n",
      "(Iteration 358801 / 360000) loss: -0.000000\n",
      "(Iteration 358901 / 360000) loss: -0.000000\n",
      "(Iteration 359001 / 360000) loss: -0.000000\n",
      "(Iteration 359101 / 360000) loss: -0.000000\n",
      "(Iteration 359201 / 360000) loss: -0.000000\n",
      "(Iteration 359301 / 360000) loss: -0.000000\n",
      "(Iteration 359401 / 360000) loss: -0.000000\n",
      "(Iteration 359501 / 360000) loss: 2400.075178\n",
      "(Iteration 359601 / 360000) loss: -0.000000\n",
      "(Iteration 359701 / 360000) loss: -0.000000\n",
      "(Iteration 359801 / 360000) loss: -0.000000\n",
      "(Iteration 359901 / 360000) loss: -0.000000\n",
      "(Epoch 100 / 100) train acc: 0.931000; val_acc: 0.885135\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "      'X_train': feat_train,\n",
    "      'y_train': label_train,\n",
    "      'X_val': feat_val,\n",
    "      'y_val': label_val}\n",
    "\n",
    "# TODO: fill out the hyperparamets\n",
    "hyperparams = {'lr_decay': .7,\n",
    "               'num_epochs': 100,\n",
    "               'batch_size': 1,\n",
    "               'learning_rate': 2\n",
    "              }\n",
    "\n",
    "# TODO: fill out the number of units in your hidden layers\n",
    "hidden_dim = [] # this should be a list of units for each hiddent layer\n",
    "\n",
    "model = FullyConnectedNet(input_dim=75,\n",
    "                          hidden_dim=hidden_dim)\n",
    "solver = Solver(model, data,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': hyperparams['learning_rate'],\n",
    "                },\n",
    "                lr_decay=hyperparams['lr_decay'],\n",
    "                num_epochs=hyperparams['num_epochs'], \n",
    "                batch_size=hyperparams['batch_size'],\n",
    "                print_every=100)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
